## 20250219Grok-3-Scales-Up-Mobile-Apps-Generated-To-Order-Musk-Moves-On-OpenAI-Officials-Reverse-Course-on-AI-Regulation

[Grok 3 Scales Up, Mobile Apps Generated To Order, Musk Moves On OpenAI, Officials Reverse Course on AI Regulation](https://www.deeplearning.ai/the-batch/issue-289/)

Dear friends,

Last month，a drone from Skyfire AI was credited with saving a police officer's life after a dramatic 2 a.m. traffic stop. Many statistics show that AI impacts billions of lives，but sometimes a story still hits me emotionally. Let me share what happened.

上个月，Skyfire AI 的一架无人机，在凌晨 2 点的一次戏剧性的交通临检中，被认为救了一名警官。大量数据表明，AI 正在影响着数十亿人的生活，但有时候，一个小故事依然能深深触动我。让我来分享一下事情的经过。

Skyfire AI，an AI Fund portfolio company led by CEO Don Mathis，operates a public safety program in which drones function as first responders to 911 calls. Particularly when a police department is personnel-constrained，drones can save officers' time while enhancing their situational awareness. For example，many burglar alarms are false alarms，maybe set off by moisture or an animal. Rather than sending a patrol officer to drive over to discover this，a drone can get there faster and determine if an officer is required at all. If the alarm is real，the drone can help officers understand the situation，the locations of any perpetrators，and how best to respond.

Skyfire AI，一家由 CEO Don Mathis 领导的 AI Fund 投资公司，运营着一个公共安全项目，其中无人机作为对 911 呼叫的第一响应者。特别是当警力不足时，无人机可以节省警官的时间，同时提高他们的情况意识（situational awareness）。例如，许多防盗警报都是误报，可能由湿气或动物触发。无需派遣巡逻警官赶往现场调查，无人机可以更快到达并判断是否需要警官介入。如果警报属实，无人机可以帮助警官了解现场情况、犯罪者的位置，并提供最佳应对方案。

In January，a Skyfire AI drone was returning to base after responding to a false alarm when the police dispatcher asked us to reroute it to help locate a patrol officer. The officer had radioed a few minutes earlier that he had pulled over a suspicious vehicle and had not been heard from since. The officer had stopped where two major highways intersect in a complex cloverleaf，and dispatch was unsure exactly where they were located.

1 月，一架 Skyfire AI 无人机在响应一起误报后正返回基地，这时警方调度员请求我们改变它的航向，协助定位一名巡逻警官。几分钟前，这位警官曾通过无线电报告，他拦下了一辆可疑车辆，但之后就失去了联系。这位警官停车的地点位于两条主要高速公路交汇处，是一个复杂的苜蓿叶型立交桥，调度员无法确定警官和车辆的具体位置。

From the air，the drone rapidly located the officer and the driver of the vehicle he had pulled over，who it turned out had escaped from a local detention facility. Neither would have been visible from the road — they were fighting in a drainage ditch below the highway. Because of the complexity of the cloverleaf's geometry，the watch officer（who coordinates police activities for the shift）later estimated it would have taken 5-7 minutes for an officer in a patrol car to find  them.

从空中，无人机迅速锁定了警官和他所拦截车辆的驾驶员。此人是从当地拘留所逃脱的。从路面上根本无法看到他们 —— 他们正在高速公路下方的排水沟中搏斗。由于苜蓿叶型立交桥复杂的几何结构，值班警官（负责协调当班的警务工作）事后估计，巡逻车上的警员需要花费 5 到 7 分钟才能找到他们。

From the aerial footage，it appeared that the officer still had his radio，but  was losing the fight and unable to reach it to call for help. Further，it looked like the assailant might gain control of his service weapon and use it against him. This was a dire and dangerous situation.

从航拍画面显示，警官虽然带着无线电，但明显处于下风，无力求助。更糟糕的是，袭击者似乎有可能夺走他的配枪，反过来攻击他。情况已经十万火急，非常危急。

Fortunately，because the drone had pinpointed the location of the officer and his assailant，dispatch was able to direct additional units to assist. The first arrived not in 5-7 minutes but in 45 seconds. Four more units arrived within minutes.

幸运的是，由于无人机精确定位了警官和袭击者的位置，调度中心得以迅速调派更多警力支援。第一批支援力量并非在 5-7 分钟后到达，而是在 45 秒内就赶到了现场。随后几分钟内，又有四支警力陆续抵达。

The officers were able to take control of the situation and apprehend the driver，resulting in an arrest and，more important，a safe outcome for the officer. Subsequently，the watch officer said we'd probably saved the officer's life.

警官们成功控制住局面并逮捕了司机，最终实施了逮捕，更重要的是，确保了警官的人身安全。随后，值班警官表示，我们的行动很可能挽救了该警官的生命。

Democratic nations still have a lot of work to do on drone technology，and we must build this technology with guardrails to make sure we enhance civil liberties and human rights. But I am encouraged by the progress we're making. In the aftermath of Hurricane Helene last year，Skyfire AI's drones supported search-and-rescue operations under the direction of the North Carolina Office of Emergency Management，responding to specific requests to help locate missing persons and direct rescue assets（e.g.，helicopters and boats）to their location，and was credited with saving 13 lives.

在无人机技术领域，民主国家仍有许多工作要做。我们必须为这项技术构建安全保障，确保其在发展的同时，能够促进公民自由和人权。不过，我对于我们正在取得的进展感到振奋。例如，去年「海伦」飓风过后，Skyfire AI 公司的无人机在北卡罗来纳州应急管理办公室的指挥下，参与了搜救行动。它们响应特定需求，协助定位失踪人员，并将救援力量（例如直升机和船只）引导至相应地点，为成功挽救 13 条生命做出了贡献。

It's not every day that AI directly saves someone's life. But as our technology advances，I think there will be more and more stories like these.

Keep building!

AI 直接拯救生命的情况并不常见。但随着技术的不断发展，我相信未来会出现更多类似的案例。

继续努力！

### News

#### Grok 3 Scales Up

Grok 3 的规模升级

xAI's new model family suggests that devoting more computation to training remains a viable path to building more capable AI.

xAI 的新模型系列表明，增加训练计算量仍然是打造更强大的 AI 的有效途径。

What's new: Elon Musk's xAI published a video demonstration of Grok 3，a family of four large language models that includes reasoning and non-reasoning versions as well as full- and reduced-size models. Grok 3 is available to subscribers to X's Premium+（$40 monthly for users in the United States; the price varies by country）and will be part of a new subscription service called SuperGrok. The models currently take text input and produce text output，but the company plans to integrate audio input and output in coming weeks.

**最新进展：** Elon Musk 的 xAI 近日发布了 Grok 3 的演示视频。Grok 3 是一系列共四个大语言模型（Large Language Model）的集合，包含推理型与非推理型两种版本，以及全尺寸与精简尺寸两种规格。Grok 3 现已向 X（原 Twitter）的 Premium+ 订阅用户开放（美国区定价为每月 40 美元，其他国家 / 地区价格有所不同），未来还将作为 SuperGrok 这项全新订阅服务的一部分提供。目前，Grok 3 仅支持文本输入和文本输出，但 xAI 计划在未来几周内加入音频输入和音频输出功能。

How it works: xAI has not yet disclosed details about Grok 3's architecture，parameter counts，training datasets，or training methods. Here's what we know so far:

工作原理：关于 Grok 3 的架构、参数规模、训练数据集和训练方法等详细信息，xAI 尚未公开。目前已知的信息如下：

1 Grok 3's processing budget for pretraining was at least 10 times that of its predecessor Grok 2. The processing infrastructure included 200,000 Nvidia H100 GPUs，double the number Meta used to train Llama 4.

Grok 3 预训练所使用的计算资源至少是上一代 Grok 2 的 10 倍。其计算基础设施包括 20 万个 Nvidia H100 GPU，是 Meta 用于训练 Llama 4 的 GPU 数量的两倍。

2 The team further trained Grok 3 to generate a chain of thought via reinforcement learning mainly on math and coding problems. The models show some reasoning tokens but obscure others，a strategy to stymie efforts to distill Grok 3's knowledge.

该团队进一步训练 Grok 3，通过强化学习，主要针对数学和编码问题生成思维链（chain of thought）。这些模型会展示部分用于推理的 Token，但同时隐藏另一些 Token。这是一种阻止他人提炼 Grok 3 知识的策略。

3 Similar to other reasoning models that generate a chain of thought，Grok 3 can spend more processing power at inference to get better results.

与其他生成思维链的推理模型类似，Grok 3 可以在推理过程中投入更多算力，从而获得更出色的结果。

4 Three modes enable Grok 3 to spend more processing power：(i）Think，which generates in-depth lines of reasoning;（ii）Big Brain，which is like Think，but with additional computation; and（iii）DeepSearch，an agent that can search the web and compile detailed reports，similar to Google's Deep Research and OpenAI's similarly named service.

Grok 3 拥有三种模式来增强算力：（i）Think 模式，能够生成深入的推理链；（ii）Big Brain 模式，与 Think 模式类似，但具有更强的计算能力；以及（iii）DeepSearch 模式，一种可以搜索网络并生成详细报告的 AI 智能体，类似于 Google 的 Deep Research 和 OpenAI 的同名服务。

Results: The Grok 3 family outperformed leading models in math（AIME 2024），science（GPQA），and coding（LiveCodeBench).

结果：在数学（AIME 2024）、科学（GPQA）和编码（LiveCodeBench）领域，Grok 3 系列的表现均超越了其他领先模型。

1 Non-reasoning models：Grok 3 and Grok 3 mini outperformed Google Gemini 2 Pro，DeepSeek-V3，Anthropic Claude 3.5 Sonnet，and OpenAI GPT-4o on all three datasets. On AIME 2024，Grok 3 achieved 52 percent accuracy，Grok 3 mini achieved 40 percent accuracy，and the next best model，DeepSeek-V3，achieved 39 percent accuracy.

无需推理的模型：在所有三个数据集上，Grok 3 和 Grok 3 mini 的性能都优于 Google Gemini 2 Pro、DeepSeek-V3、Anthropic Claude 3.5 Sonnet 和 OpenAI GPT-4o。具体来说，在 AIME 2024 测试中，Grok 3 的准确率达到了 52%，Grok 3 mini 的准确率达到了 40%，而表现次佳的 DeepSeek-V3 的准确率为 39%。

2 Reasoning models：Grok 3 Reasoning Beta and Grok 3 mini Reasoning（set to use a large but unspecified amount of computation at inference）outperformed OpenAI o3-mini（set to high「effort」），OpenAI o1，Deepseek-R1，and Google Gemini 2 Flash Thinking. For instance，on GPQA，Grok 3 Reasoning Beta achieved 85 percent accuracy，Grok 3 mini Reasoning achieved 84 percent，and the next best model，o3-mini，achieved 80 percent accuracy.

推理模型：Grok 3 Reasoning Beta 和 Grok 3 mini Reasoning（在推理时被设置为使用大量但未明确指定的计算资源）的表现优于 OpenAI o3-mini（设置为高「努力」模式）、OpenAI o1、Deepseek-R1 以及 Google Gemini 2 Flash Thinking。例如，在 GPQA 数据集上，Grok 3 Reasoning Beta 达到了 85% 的准确率，Grok 3 mini Reasoning 达到了 84%，而表现次优的模型 o3-mini 的准确率为 80%。

Behind the news: Reasoning models are pushing benchmark scores steadily upward，especially in challenging areas like math and coding. Grok 3，with its ability to reason over prompts，search the web，and compile detailed reports，arrives hot on the heels of OpenAI's Deep Research and o3-mini and Google's Gemini-2 Flash Thinking，which offer similar capabilities.

新闻背后：推理模型正在不断刷新各项基准测试的成绩，尤其是在数学和编码等高难度领域。Grok 3 具备了对提示（prompts）进行推理、网络搜索以及生成详细报告的能力，在此之前，OpenAI 的 Deep Research 和 o3-mini，以及 Google 的 Gemini-2 Flash Thinking 也相继发布，它们都拥有类似的功能。

Why it matters: Grok 3 is a substantial achievement — especially for a company that's less than two years old — and it pushes the state of the art forward by ample margins. But its significance may go farther. Research into scaling laws indicates that model performance scales with training. While xAI has not disclosed the amount of processing used to train Grok 3，the number of GPUs in its cluster suggests that the company applied a massive amount.

为什么重要：Grok 3 是一项重大的成就，对于一家成立不到两年的公司来说尤其如此。它以显著的优势大幅提升了技术水平。但它的意义可能远不止于此。对扩展法则的研究表明，模型性能会随着训练量的增加而提升。虽然 xAI 尚未公开训练 Grok 3 所使用的计算资源，但其 GPU 集群的规模暗示了其训练所消耗的巨大算力。

We're thinking: Grok 3's performance makes a case for both massive compute in pretraining and additional compute at inference. Running in its usual mode，Grok 3 mini Reasoning outperformed OpenAI o3-mini set at high effort on AIME 2024，GPQA，and LiveCodeBench. With an unspecified amount of additional compute，its performance on those benchmarks shot further upward by a substantial margin.

我们的思考是：Grok 3 的出色表现表明，预训练时需要强大的算力，推理时也需要额外的算力支持。在常规模式下，Grok 3 mini Reasoning 在 AIME 2024、GPQA 和 LiveCodeBench 等测试中，投入大量计算资源后，性能超越了 OpenAI 的 o3-mini 系列模型。更令人 впечатляющим 是，在使用了具体数量未知的额外算力后，它在这些基准测试上的表现更是突飞猛进。

#### Mobile Apps to Order

移动应用定制

Replit，an AI-driven integrated development environment，updated its mobile app to generate further mobile apps to order.

Replit，一个人工智能驱动的集成开发环境，更新了它的移动应用程序，以生成更多定制化的移动应用。

What's new: Replit's app，which previously generated simple Python programs，now generates iOS and Android apps and app templates that can be shared publicly. Mobile and web access to Replit's in-house code generation models is free for up to three public applications. A Core plan ($25 per month，$180 per year）buys unlimited access and applications，code generation by Claude 3.5 Sonnet and OpenAI GPT-4o，and monthly credits for generated checkpoints.

最新消息：Replit 的应用程序，此前仅能生成简单的 Python 程序，现在能够生成 iOS 和 Android 应用程序以及应用模板，并且这些程序和模板可以公开分享。通过移动端和 Web 端访问 Replit 内部的代码生成模型，最多可以免费创建三个公开应用程序。核心计划（Core plan)（每月 25 美元，每年 180 美元）提供无限访问权限和应用程序创建，支持使用 Claude 3.5 Sonnet 和 OpenAI GPT-4o 进行代码生成，并提供每月用于生成检查点（checkpoint）的积分。

How it works: The app and web tools are powered by Replit Agent，an AI coding assistant designed to help users write，debug，and deploy applications with little manual setup. Replit Agent is based on Claude 3.5 Sonnet and calls other specialized models. The agent framework is built on LangChain's LangGraph. It breaks down development tasks into steps to be handled by specialized sub-agents.

工作原理：这款应用和网页工具的背后，是名为 Replit Agent 的 AI 编码助手在提供支持。Replit Agent 旨在帮助用户轻松编写、调试和部署应用程序，最大限度地减少手动配置。Replit Agent 基于 Claude 3.5 Sonnet 构建，并能调用其他专业模型来完成特定任务。该 AI 智能体框架构建于 LangChain 的 LangGraph 之上（LangChain 是一个用于构建大语言模型应用的框架，LangGraph 是 LangChain 中的一个用于构建多智能体工作流的库）。它会将复杂的开发任务拆解为多个步骤，再由不同的专业子智能体分别处理 [20]。

1 The mobile app includes three views in development or「create」mode，enabling users to build applications with natural language instructions in a chatbot interface，ask Replit's chatbot questions，or preview applications in a built-in browser.

移动应用包含处于开发或「创建」模式的三种视图，允许用户通过聊天机器人界面，使用自然语言指令构建应用程序，向 Replit 聊天机器人提出问题，或在内置浏览器中预览应用程序。

2 A quick start panel also lets users import projects from GitHub，work using built-in templates，or build apps in specific coding languages.

快速启动面板还允许用户从 GitHub 导入项目、使用内置模板，或者使用特定的编程语言来构建应用。

3 The system can plan new projects，create application architectures，write code，and deploy apps. Users can deploy completed apps to Replit's infrastructure on Google Cloud without needing to configure hosting，databases，or runtime environments manually.

该系统能够规划新项目、创建应用架构、编写代码和部署应用。用户可以将开发完成的应用部署到 Replit 在 Google Cloud 上的基础设施，而无需手动配置服务器托管、数据库或运行环境。

Behind the news: The incorporation of Replit Agent to Replit's mobile app is a significant step for AI-driven IDEs. Competitors like Aider and Windsurf don't offer mobile apps，and mobile apps from Cursor and Github provide chat but not mobile app development. Moreover，few coding agents can deploy apps to the cloud on the desktop or mobile.

新闻解读：Replit 将 Replit Agent 集成到其移动应用中，标志着 AI 驱动的集成开发环境（IDE）迈出了重要一步。像 Aider 和 Windsurf 这样的竞争对手尚未提供移动应用。虽然 Cursor 和 Github 的移动应用提供了聊天功能，但不支持移动应用开发。更重要的是，鲜有编码 AI 智能体能够将应用部署到桌面或移动端的云服务器。

Why it matters: Replit's new mobile app produces working apps in minutes（although some early users have reported encountering bugs），and automatic deployment of apps to the cloud is a huge help. Yet it raises the stakes for developers to learn their craft and maintain a collaborative relationship with AI. While Replit's web-based environment exposes the code，encouraging users to improve their skills，the mobile app hides much of its work below the surface. It brings AI closer to handling full software development cycles and adds urgency to questions about how to address the balance between automation and hands-on coding.

为什么重要：Replit 的新移动应用可以在几分钟内生成可用的应用（尽管一些早期用户报告遇到了错误），并且自动将应用部署到云端是一个巨大的帮助。然而，这对开发者提出了更高的要求，他们需要不断学习精进技能，并与 AI 保持良好的协作关系。虽然 Replit 基于 Web 的环境公开了代码，鼓励用户精进技能，但移动应用将许多底层工作隐藏起来。它使 AI 更接近于处理完整的软件开发周期，这也使得如何平衡自动化和手动编程的问题变得更加紧迫。

We're thinking: AI continues to boost developer productivity and reduce the cost of software development，and the progress of Bolt，Cursor，Replit，Vercel，Windsurf，and others is exhilarating. We look forward to a day when，measured against the 2024 standard，every software engineer is a 10x engineer!

我们正在思考：生成式 AI（Generative AI）不断提升开发者的效率，并降低软件开发的成本。Bolt、Cursor、Replit、Vercel、Windsurf 等工具的快速发展，着实令人感到兴奋。我们期待着，在 2024 年的基准下，未来的每一位软件工程师都能成为效率提升 10 倍的卓越工程师！

#### Musk Complicates OpenAI's Plan

Musk 使 OpenAI 的计划复杂化

Elon Musk and a group of investors made an unsolicited bid to buy the assets of the nonprofit that controls OpenAI，complicating the AI powerhouse's future plans.

Elon Musk 和一群投资者主动提出收购控制 OpenAI 的非营利组织的资产，这使得这家人工智能领军企业 OpenAI 的未来计划变得复杂。

What's new: Musk submitted a $97.4 billion offer to acquire the assets of the nonprofit OpenAI Inc. CEO Sam Altman and the company's board of directors swiftly rejected it，and Altman publicly mocked Musk by offering to buy Twitter for $9.74 billion（one-tenth of Musk's bid and less than one-quarter the price he paid for the social network). OpenAI's board reaffirmed its control over the company's direction，signaling that it does not intend to cede governance to outside investors.

最新进展：Musk 提出以 974 亿美元收购非营利组织 OpenAI Inc. 的资产。但首席执行官 Sam Altman 和公司董事会迅速拒绝了这一要约。Altman 随后公开回应，提议以 97.4 亿美元收购 Twitter，以此嘲讽 Musk（仅为 Musk 出价的十分之一，且不到他收购该社交网络所支付价格的四分之一）。OpenAI 董事会再次强调对公司发展方向的掌控，明确表示无意将管理权让渡给外部投资者。

How it works: OpenAI was founded as a nonprofit in 2015，but since 2019 it has operated under an unusual structure in which the nonprofit board controls the for-profit entity that develops and commercializes AI models. This setup allows the board to maintain the company's original mission — developing AI for the benefit of humanity — rather than solely maximizing shareholder value. However，driven by the need for massive investments in infrastructure and talent，OpenAI is considering a new for-profit structure that would allow external investors to own more of the company. The high offer by Musk — who，as CEO of xAI，competes with OpenAI — could interfere with that plan.

运作方式：OpenAI 最初于 2015 年作为非营利组织成立，但从 2019 年开始，它采用了一种特殊的结构：非营利董事会控制着一个营利性实体，该实体负责开发和商业化 AI 模型。这种结构旨在让董事会能够坚持公司的最初使命 —— 为人类利益开发 AI—— 而不是仅仅追求股东价值最大化。然而，为了满足基础设施和人才方面的大量投资需求，OpenAI 正在考虑一种新的营利性结构，允许外部投资者持有更多公司股份。马斯克（作为 xAI 的 CEO，xAI 与 OpenAI 存在竞争关系）的高额收购提议，可能会对这一计划造成影响。

1 The board has a legal duty to consider both OpenAI's original mission and credible offers for its assets. While it rejected Musk's bid，it must ensure that any restructuring aligns with its charter and does not unfairly disregard potential buyers.

董事会肩负着法律义务，既要考量 OpenAI 的最初使命，也要审视针对其资产的可靠报价。尽管董事会已经拒绝了 Musk 的收购要约，但仍须确保任何重组方案都与其公司章程相符，并且不会不合理地忽略潜在收购方。

2 According to the current plan，the new for-profit entity would purchase the nonprofit's assets. Musk's bid suggests that the nonprofit's assets alone are worth at least $97.4 billion，more than 60 percent of the entire organization's valuation in late 2024. That could dramatically boost the cost of the planned restructuring.

根据目前的计划，新的营利性实体将购买该非营利组织的资产。马斯克（Musk）的出价表明，仅该非营利组织的资产价值就至少达到 974 亿美元，超过了该组织在 2024 年末总估值的 60% 以上。这可能会显著增加计划中的重组所带来的成本。

3 Some experts believe that Musk's offer is less about acquiring OpenAI than driving up its valuation，which could dilute the equity of new investors in the new for-profit entity. By introducing a competitive bid，he may be attempting to make OpenAI's restructuring more expensive or complicated.

一些专家认为，马斯克提出收购要约，与其说是真的想收购 OpenAI，不如说是为了抬高它的估值。这可能会稀释 OpenAI 新成立的营利性机构中，新投资者的股权。通过提出一个竞争性的收购方案，他可能试图让 OpenAI 的重组变得更加代价高昂，或者更加复杂。

4 Musk has indicated he is willing to negotiate，effectively turning OpenAI's transition into a bidding war. Altman stated that this could be a deliberate effort to「slow down」OpenAI and that he wished Musk would compete by building a better product instead.

马斯克已经暗示他愿意进行协商，这实际上将 OpenAI 的转型变成了一场竞价。奥特曼认为，这可能是为了故意「拖慢」OpenAI 的发展速度，并且他希望马斯克能够通过打造更优秀的产品来展开竞争。

Behind the news: Musk was one of OpenAI's earliest investors，but he departed in 2018 after disagreements over direction and control of the organization. His bid follows a lawsuit against OpenAI，in which he claims the company abandoned its nonprofit mission in favor of profit. OpenAI said that Musk's bid contradicts his legal claims and suggests that the lawsuit should be dismissed. Since then，Musk has stated that he would drop the lawsuit if OpenAI remains a nonprofit.

新闻背后：Musk 是 OpenAI 最早的投资者之一，但在 2018 年因在组织的方向和控制权上的分歧而离开。此前，他对 OpenAI 提起了诉讼，声称该公司放弃了其非营利使命，转而追求利润。OpenAI 表示，Musk 的出价与他的法律主张相矛盾，并建议应该驳回这项诉讼。此后，Musk 声明，如果 OpenAI 能够保持非营利性质，他将撤销诉讼。

Why it matters: OpenAI is a premier AI company，and its activities affect virtually everyone in the field by supplying tools，technology，or inspiration. Musk's xAI is a direct competitor，and his bid，whether it's sincere or tactical，unsettles OpenAI's plans. Even if OpenAI moves forward as planned，Musk's actions likely will have made the process more expensive and potentially invite closer scrutiny of the company's actions.

重要性：OpenAI 是一家领先的 AI 公司，它提供的工具、技术和灵感几乎影响着整个 AI 领域。Musk 的 xAI 是其直接竞争对手，Musk 的举动，无论出于真心还是策略，都将对 OpenAI 的计划造成干扰。即便 OpenAI 能够按原计划推进，Musk 的行为也可能增加其成本，并可能引来对 OpenAI 行为更严格的审查。

We're thinking: There's ample precedence for non-profits spinning out for-profit entities. For example，non-profit universities typically create intellectual property that forms the basis of for-profit startups. The university might retain a modest stake，and this is viewed as consistent with its non-profit mission. This isn't a perfect analogy，since OpenAI does little besides operating its AI business，but we hope the company finds a path forward that allows it to serve users，rewards its employees for their contributions，and honors its non-profit charter.

我们是这样考虑的：非营利组织衍生出营利性机构早有先例。例如，非营利性大学通常会创造知识产权，而这些知识产权往往会成为营利性初创公司的基石。大学可能会保留少量股份，而这种做法也被认为符合其非营利使命。当然，这并非完全对等，因为 OpenAI 的主要业务就是运营其 AI 业务，但我们仍然希望 OpenAI 能够找到前进的方向，既能服务用户，又能回报员工的贡献，同时坚守其非营利宗旨。

#### World Powers Move to Lighten AI Regulation

世界大国寻求放宽 AI 监管

The latest international AI summit exposed deep divisions between major world powers regarding AI regulations.

最新一届国际 AI 峰会揭示了主要大国之间在 AI 监管问题上的严重分歧。

What's new: While previous summits emphasized existential risks，the AI Action Summit in Paris marked a turning point. France and the European Union shifted away from strict regulatory measures and toward investment to compete with the United States and China. However，global consensus remained elusive：the U.S. and the United Kingdom refused to sign key agreements on global governance，military AI，and algorithmic bias. The U.S. in particular pushed back against global AI regulation，arguing that excessive restrictions could hinder economic growth and that international policies should focus on more immediate concerns.

最新进展： 之前的峰会主要关注的是 AI 带来的潜在生存威胁，而巴黎的 AI 行动峰会则标志着风向转变。法国和欧盟不再一味强调严格的监管，而是转向投资，希望以此和美国、中国一较高下。然而，要达成全球共识仍然困难重重：美国和英国拒绝签署关于全球治理、军事 AI 和算法偏差（algorithmic bias）的重要协议。特别是美国，强烈反对全球范围内的 AI 监管，他们认为过多的限制可能会阻碍经济发展，并且国际政策应该优先关注更紧迫的问题。

How it works: Participating countries considered three policy statements that address AI's impact on society，labor，and security. The first statement calls on each country to enact AI policies that would support economic development，environmental responsibility，and equitable access to technology. The second encourages safeguards to ensure that companies and nations distribute AI productivity gains fairly，protect workers' rights，and prevent bias in hiring and management systems. The third advocates for restrictions on fully autonomous military systems and affirms the need for human oversight in warfare.

运作方式：参与国审议了三项政策声明，这些声明关注 AI 对社会、劳工和安全的影响。第一项声明呼吁各国制定 AI 政策，以支持经济发展、环境责任和公平地获取技术。第二项鼓励采取保护措施，以确保公司和国家公平地分配 AI 带来的生产力提升，保护工人权益，并防止招聘和管理系统中的偏见。第三项则倡导限制全自动军事系统，并强调在战争中需要人来监督。

1 The U.S. and UK declined to sign any of the three statements issued at the AI Action Summit. A U.K. government spokesperson said that the declaration lacked practical clarity on AI governance and did not sufficiently address national security concerns. Meanwhile，U.S. Vice President JD Vance criticized Europe's「excessive regulation」of AI and warned against cooperation with China.

美国和英国拒绝签署在 AI 行动峰会（AI Action Summit）上发布的三份声明中的任何一份。一位英国政府发言人表示，该声明在 AI 治理方面缺乏实际可操作的明确性，并且没有充分解决国家安全问题。与此同时，美国副总统 JD Vance 批评欧洲对 AI 的「过度监管」，并警告不要与中国合作。

2 Only 26 countries out of 60 agreed to the restrictions on military AI. They included Bulgaria，Chile，Greece，Italy，Malta，and Portugal among others.

在 60 个国家中，仅有 26 个国家同意对军事领域的人工智能应用进行限制，其中包括保加利亚、智利、希腊、意大利、马耳他和葡萄牙等。

3 France pledged roughly $114 billion to AI research，startups，and infrastructure，while the EU announced a roughly $210 billion initiative aimed at strengthening Europe's AI capabilities and technological self-sufficiency. France allocated 1 gigawatt of nuclear power to AI development，with 250 megawatts expected to come online by 2027.

法国承诺投入约 1140 亿美元，用于人工智能研究、初创公司和基础设施建设。与此同时，欧盟也宣布了一项金额约为 2100 亿美元的计划，旨在提升欧洲的人工智能研发能力和技术自主性。法国已划拨 1 吉瓦的核电用于人工智能发展，预计到 2027 年将有 250 兆瓦的电力投入使用。

4 Despite the tight regulations proposed at past summits and passage of the relatively restrictive AI Act last year，the EU took a sharp turn toward reducing regulatory barriers to AI development. Officials emphasized the importance of reducing bureaucratic barriers to adoption of AI，noting that excessive regulation would slow Europe's progress in building competitive AI systems and supporting innovative applications.

尽管在过去的峰会上提出了严格的法规，并且去年通过了相对具有限制性的人工智能（AI）法案，但欧盟 резко изменился курс，转而减少 AI 发展的监管壁垒。官员们强调了减少 AI 应用的官僚障碍的重要性，并指出过度监管会减缓欧洲在构建有竞争力的 AI 系统和支持创新应用方面的进展。

5 Shortly after the summit，the European Commission withdrew a proposed law（the so-called「liability directive」）that would have made it easier to sue companies for vaguely defined AI-related harms. The decision followed criticism by industry leaders and politicians，including Vance，who argued that excessive regulation could hamper investment in AI and hinder Europe's ability to compete with the U.S. and China in AI development while failing to make people safer.

不久之后，欧盟委员会撤回了一项法律草案（也就是所谓的「责任指令」），该指令旨在让人们更容易地起诉那些造成定义模糊的与 AI 相关的损害的公司。这一决定是由于包括 Vance 在内的行业领导者和政治家的批评。他们认为，过度监管不仅可能阻碍对 AI 的投资，还会削弱欧洲在 AI 开发领域与美国和中国竞争的能力，并且并不能提高人们的安全。

Behind the news: The Paris summit follows previous gatherings of world leaders to discuss AI，including the initial AI Safety Summit at Bletchley Park and the AI Seoul Summit and AI Global Forum. At these summits，governments and companies agreed broadly to address AI risks but avoided binding regulations. Nonetheless，divisions over AI governance have widened in the wake of rising geopolitical competition and the emergence of high-performance open weights models like DeepSeek-R1.

新闻背景：巴黎峰会的召开，紧随此前世界各国领导人举行的一系列人工智能（AI）讨论会议之后，包括在布莱切利公园举行的首届人工智能安全峰会（AI Safety Summit）、人工智能首尔峰会（AI Seoul Summit）和人工智能全球论坛（AI Global Forum）。在这些峰会上，各国政府和公司虽然都大致同意要解决 AI 风险，但同时也都避免制定具有约束力的法规。尽管如此，随着地缘政治竞争的加剧，以及像 DeepSeek-R1 这样的高性能开放权重模型（open weights models）的出现，各方在 AI 治理问题上的分歧也日益扩大。

Why it matters: The Paris summit marks a major shift in global AI policy. The EU，once an ardent proponent of AI regulation，backed away from its strictest proposals. At the same time，doomsayers have lost influence，and officials are turning their attention to immediate concerns like economic growth，security，misuse，and bias. These moves make way for AI to do great good in the world，even as they contribute to uncertainty about how AI will be governed.

Why it matters：为什么这件事很重要：巴黎峰会标志着全球人工智能（AI）政策的一次重大转变。曾经大力倡导人工智能（AI）监管的欧盟（EU），放弃了其最初提出的最为严苛的提案。与此同时，「末日论」的观点逐渐式微，决策者们正将注意力转向更紧迫的问题，例如经济增长、安全、滥用以及偏见。这些转变让 AI 能够在世界范围内发挥积极作用，但同时也增加了 AI 治理方式的不确定性。

We're thinking: Governments are shifting their focus away from unrealistic risks and toward practical strategies for guiding AI development. We look forward to clear policies that encourage innovation while addressing real-world challenges.

我们的想法是：各国政府正逐渐将重心从虚无缥缈的风险，转向指导人工智能（AI）开发的务实策略。我们期待出台更加明晰的政策，在鼓励创新的同时，也能有效应对现实世界的挑战。