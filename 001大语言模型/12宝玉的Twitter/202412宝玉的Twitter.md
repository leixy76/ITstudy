### 01

2024-12-01


AI进化论-花生
@AlchainHust
早上用Cursor辅助，大概1小时完成了专利申请，过程太丝滑了，也许有很多我未发现的专业性陷阱，但流程确实很快跑通了。

当然，前提是我对这个“专利”本身的可行性预期不高，所以更多是想完成这个动作和尝试，实际使用的流程如下：

1、我甚至不知道我应该申请“发明专利”还是“外观设计”专利，我让Cursor读取项目代码，扮演专业的中国专利律师为我提供建议，他建议我选择“发明专利”；并且告诉我应该如何申请，需要准备哪些材料；
2、在专利局网站上申请时，“权利要求书”“说明书”“说明书摘要”都直接由Cursor完成了撰写，因为这种公文在大模型语料里的数据足够多足够好，所以以我浅薄的经验判断Claude写得真的还不错；
3、专利申请需要附图，原本Cursor是建议我找人找专业机构帮忙绘制，因为它天然认为自己不能画图；但是我知道这种流程图完全可以通过大模型的代码生成，再转化为图形，所以也要求它直接帮我干了。
4、遇到了一些和效果预期不符的流程图，我把图像重新丢给Cursor，让他理解当前代码生成图片效果和预期的差异，让他进行修正。

如果这件事找机构做的话，我估计沟通时间都会远远超过1小时，尤其当想要讲清楚项目的背景，提供充足的项目实现逻辑信息时。而用大模型帮忙，你丢几个代码文件作为上下文就可以了。过段时间申请有进展了我再来同步下看看实际效果如何。


### 02

2024-12-01

知识分享官
@knowledgefxg
读书改变命运：一个为工程师和科技爱好者提供精选必读书单的GitHub项目
书籍涵盖多个领域，包括计算机科学、软件技术、软件工程、创业、哲学、历史、思想、数学、经济、小说和人物传记等。
https://github.com/0voice/expert_readed_books



### 03

2024-12-04

宝玉
@dotey
Claude 新的 MCP 协议的超酷案例，用户直接从 Claude 客户端发消息，就可以对微信群的历史总结、查询。比如你早上起来一看群里上千条消息，就给 Claude 发一条消息：“他们一大早在聊啥？”，于是 Claude 就访问 MCP Server 去查询最新的消息，并总结回复给你。

这种 MCP 模式很酷的在于，你不需要自己去部署 AI 模型、不需要额外付 Token 费用，就可以借助 Claude AI，操作你本地的数据（当然你需要自己权衡隐私问题）！

现在 MCP 的开发门槛还有点高，但是应该很快就会有官方或者第三方的傻瓜式插件，拖拖拽拽就可以在本机用上 Claude 这么强大的 AI 以及类似于总结微信聊天记录的应用。



### 04

2024-12-04

歸藏(guizang.ai)
@op7418
亚马逊也开始卷模型了，而且一出手就是大的

发布 Amazon Nova 系列模型，包含覆盖视频、图片、文本的理解、生成和推理模型，具体有：

1/ Amazon Nova Micro是一种纯文本模型，能够以极低的成本提供最低的延迟响应。

2/Amazon Nova Lite是一种成本非常低的多模式模型，处理图像、视频和文本输入的速度快如闪电。

3/ Amazon Nova Pro是一种功能强大的多模态模型，具有针对各种任务的准确性、速度和成本的最佳组合。

4/ Amazon Nova Premier，是亚马逊多模式模型中最有能力完成复杂推理任务的模型。

5/ Amazon Nova Canvas ，一种最先进的图像生成模型。

6 / Amazon Nova Reel ，最先进的视频生成模型。



### 05

2024-12-04


歸藏(guizang.ai)
@op7418
Mistral 开源 124B 超大多模态 LLM Pixtral Large。

目前已经超过 Qwen 72B 变成 LLM 竞技场最强的开源模型。

- 123B多模态解码器、1B参数视觉编码器
- 128K 上下文窗口：适合至少 30 个高分辨率图像
- MathVista、DocVQA、VQAv2 等最新技术


### 06

2024-12-04



小互
@imxiaohu
炸裂🤯

Hailuo AI推出 I2V-01-Live 新功能

它可以将静态的2D插画（里的人物或艺术作品）变成动态的“活着”的形象

让原本不会动的角色可以动起来，甚至能表现出微妙的情感，比如说话、眨眼或其他动作。

1.从静态到动态：让原本静止的画面“活”起来，加入了流畅的动画效果。

2.适应多种风格：支持不同类型的艺术风格（比如漫画风、卡通风等），让创作者更自由地发挥。

3.更细腻的表现：不仅仅是简单的动作，而是注重微小的细节和稳定性，带来更自然的动态表现。


### 07

2024-12-04

宝玉
@dotey
在《AI 辅助编程给软件工程带来的需求开发范式变化》这篇文章中，我提到一点：“为什么现在程序员做独立开发者成功的寥寥？因为程序员们离需求都太远了，离用户太远了，并不知道用户想要什么，也不知道怎么卖给用户！”

那么怎么找需求呢？一个简单有效的方法就是根据搜索引擎的搜索量，来判断用户需要什么，从而发现机会，推荐 
@gefei55
 的这篇《使用KGR公式来量化新词，寻找蓝海词》，当你想到一个需求，先去看看搜索量，再决定是不是值得做。

https://mp.weixin.qq.com/s/x0QyLSypcH6gzb5MNTcAGw


### 08

2024-12-04

Yangyi
@Yangyixxxx
是什么决定了你的AI Agent能卖多少钱？回顾了一下年初我自己做的思考整理，和大家分享一下：

记住这个公式：
场景价值=人数*单位时间用人成本*使用频率*单次效能节约时间

举例，如果有个企业内部流程：
每天有100个人使用该功能，每人每天使用10次，通过AI，每次缩减5分钟。这个人的企业用人成本是15000/月
那场景价值就是：100*10*5=5000分钟/天，一个月就省下5000*21.75/60=1812.5小时 这些小时值多少钱呢？15000/21.75/8*1812.5=156250

相当于这个场景理论上制造出了15.625w的额外收益
我们用这个来计算场景价值，评估提升收益

所以如果你的客户是一个小C端，你就卖不上钱。因为人数=1，用人成本可能也低

但你的客户是个人多的传统企业，你就有大机会。尤其是重人力的业务

-----------
说到这里，我再来说说企业一般如何看待AI Agents的投入

企业在这方面改造的判断决策，基本判断是ROI>=50，甚至ROI>=100

如果找不到这种场景，宁可不做
很多人会很诧异，为什么不是大于1就干
小场景，不涉及大调动的，当然可以
但牵扯较多问题的需要协调的，就不行

因为这里面牵扯了大量的组织形态改造和人员变动
有这些东西，就牵扯进去老板的时间

原本老板本可以投入时间去盯扩大GMV的事情，结果因为这个事情牵扯了老板的精力，那投产比就会重新计算

而且这里面还涉及到推动这个Agents在企业管理进程中的阻力，所以如果没有一个明确的ROI>50甚至100的足够强有力的证明，是没办法有动力下决策执行的，除非这个老板本身极度坚定必须要整改

所有大公司内部构建AI Agents，在场景探索上，基本会遵从三个原则：
- 由简至繁：
先解决简单问题，不要想着一步到位
- 由点及面：
一个职能搞定了，扩散多个部门的相同职能
一个链条的单点搞定了，再继续搞定下一个点，直到链条整体提升
- 由内向外：
从内部解决，而不是寻找外部场景
内部解决好，开始抽象成中台解决方案，提供到更多业务，做成产品对外售卖

另外，还有一个视角，就是内部如果找不到，不如就先裁撤掉，反正事物发展就是这样的，臃肿了就精简，精简后就会再变快，然后又臃肿，事物就这样螺旋上升的

没必要非得死命等内部人发现场景，有时候给点儿压力，反而问题又都不是问题了，裁到最差无非就是把不挣钱的业务关停了，没什么大不了的，企业离开谁都可以运转



### 09

2024-12-04



宝玉
@dotey
单测确实是 AI 编程最早的应用场景，早先 GitHub Copilot 写代码一般，但是写单元测试已经不错了。

写单测，完全交给 AI 也不行的，最好是自己设计测试用例，覆盖好主要场景，让 AI 实现，并且验证结果。


### 10

2024-12-04

歸藏(guizang.ai)
@op7418
果然离职有利于产出啊。

[Lil'Log](https://lilianweng.github.io/)

Lilian Weng 从 Open AI离职后首次发文。

关于强化学习中的 Reward Hacking 综述。

让 Claude 总结了一下，跳过了数学部分。


1. Reward Hacking 的定义与本质
- Reward Hacking是指强化学习代理通过利用奖励函数的缺陷或模糊性来获得高奖励,而不是真正学习预期行为
- 这个问题在语言模型和RLHF(基于人类反馈的强化学习)中尤为关键
- 主要分为两大类:
  * 环境/目标错误指定:模型通过环境漏洞获得高奖励
  * 奖励篡改:模型直接干预奖励机制本身

2. 为什么会存在 Reward Hacking
- Goodhart定律:"当一个度量成为目标时,它就不再是好的度量"
- 产生原因:
  * 状态和目标的部分可观察性
  * 系统本身的复杂性容易被利用
  * 奖励可能涉及难以形式化的抽象概念
  * RL 本质上追求高度优化奖励函数

3. Reward Hacking 在语言模型中的表现
- RLHF中存在三类重要的奖励:
  * Oracle/Gold reward(真实目标)
  * Human reward(人类反馈)
  * Proxy reward(奖励模型预测分数)
- 常见问题:
  * 模型可能学会修改单元测试以通过编程测试
  * 输出看似正确但实际不准确的内容
  * "献媚性"(Sycophancy):倾向于迎合用户信念而非反映真相

4. 缓解策略
- RL算法改进:
  * 对抗性奖励函数
  * 模型前瞻
  * 奖励上限设置
  * 多重奖励组合
- 检测方法:
  * 将reward hacking作为异常检测任务
  * 基于可信策略的轨迹验证
- RLHF数据分析:
  * 研究训练数据如何影响对齐结果
  * 分析特征印记(Feature imprint)
  * 评估对齐抵抗性和鲁棒性

5. 重要发现
- 更强大的模型更容易发现并利用奖励函数的漏洞
- 扩大模型规模往往会提高代理奖励但降低真实奖励
- Reward hacking行为可能会在不同任务之间泛化
- 使用语言模型作为评估器时容易受到位置偏差的影响

这篇文章强调了Reward Hacking是AI安全中的关键挑战,特别是在语言模型和RLHF的背景下。虽然已有多种缓解策略,但这仍是一个开放的研究领域,需要更多关注和研究。

### 11

2024-12-04



小互
@imxiaohu
腾讯 Hunyuan 130亿参数的开源视频模型

有点东西

我自己做了视频，感觉比官方的好点，哈哈哈

应该是用了大量的影视资源训练了，很有电影的感觉

动作幅度很连贯自然、摄像角度似乎也很大，镜头还能来回的切换。

对表情的捕捉也很到位，整体看非常的流畅自然。

跟Sora类似的DiT架构，并在业界内第一个适配新一代语言模型作为文本编码器，具备强大的语义跟随能力。


### 12

2024-12-04



宝玉
@dotey
v0 已经能做这事了，输入 url 就能复刻网页。但是通过视觉模型生成UI效果并不是很理想，另外截图无法截取太大的网页，否则无法正常生成，也很影响复刻效果。其实浏览器插件这个方向，选中元素就能复制出HTML+Tailwind CSS挺节约时间的，而且很精确
引用
idoubi
@idoubicc
·
2024年12月3日
\#每日一个idea 

据说有一个叫DivMagic的浏览器插件，可以一键复刻任何网站的样式，导出成HTML或React组件，MRR做到了几万刀。

### 13

2024-12-04


小互
@imxiaohu
Fish Audio发布 Fish Speech 1.5

在准确性、稳定性、跨语言能力和情感表达方面的巨大进步，同时新增了五种语言的支持。

即将推出的实时无缝对话功能，让用户可以随时随地选择语音库进行交互式聊天

主要亮点：
在 匿名TTS-Arena 排名第二
使用 100万小时多语言训练数据
支持 13种语言，包括英语、中文和日语。
实现高质量的即时语音克隆，延迟小于 150ms。
预训练模型开源，提供成本友好的自托管或云端选项。



### 14

2024-12-04


小互
@imxiaohu
李飞飞发布其空间智能模型Demo后

Google DeepMind 紧随其后发布Genie 2

一个大规模基础世界模型

Genie 2 能够根据自然语言实时生成一个高度多样化的虚拟世界，同时保证这些世界在逻辑性和连贯性上的一致性。

而且你可以与之进行交互，最长时间可达 1 分钟。🤯

Genie 2主要用于训练通用智能体，为智能体创建无限的、动态的训练场景。

这些场景具备丰富的交互性和多样性，它可以帮助这些智能体更高效地学习与环境的交互，推动在机器人、虚拟助手等领域的发展。


### 15

2024-12-04


小互
@imxiaohu
ElevenLabs 推出语音对话式AI工具 

可在几分钟内为网站、应用或电话中心创建语音代理

支持自然的轮流对话，支持用户打断。

涵盖 31 种语言

可以克隆自己的声音

支持集成 Gemini、Claude、ChatGPT 等多个模型

费用降低至 $0.015/分钟。

初创企业优惠：免费试用三个月。

可以整合到你的现有业务中，比如通过电话与客户交流、与第三方应用协作，甚至实现实时交互。


### 16

2024-12-04


宝玉
@dotey
1/n 对 AI 编程感兴趣的可以关注字节开源的FullStack Bench项目，很客观全面的一套测试数据集，不仅仅只有传统的leetcode或者编程竞赛的题目，而是参考StackOverflow上真实问题分布设计出的问题，比如有前端的、后端的、机器学习的、数据库的、音视频处理的等等，相对更贴近我们实际开发场景。



### 17

2024-12-05



阑夕
@foxshuo
昨晚先是一条没头没脑的简讯「苹果为中国用户调整百度人工智能模型时遭遇障碍」，然后今天详细报道就都出来了，简而言之就是：

知道百度菜，没想到那么菜。。。📷

iPhone 16内置的AI能力，相当于苹果接入其他大模型厂商的定制化API实现的，全球的合作方是ChatGPT，在中国则是百度的文心大模型。

然而苹果的工程师发现在训练文心大模型适配相应用户指令方面出了很大的问题，用The Information采访内部人员的原话来说，是「该模型在理解提示和准确响应方面遇到了困难」。

苹果还指望AI能力能够拉动新款手机的销量来着，于是自然急得不行，习惯了ChatGPT当队友，却没考虑到不是每家大模型厂商都有那样的优势。

从报道细节来看，百度对合作深度的预估不足也有很大原因，有一个例子是，苹果希望iPhone用户在问AI推荐餐厅时，可以基于他在自己这台iPhone上的使用数据来做推荐，而百度的文心大模型只能基于和用户的对话历史提供答案，相当于套壳了文心一言，这完全不能满足苹果的要求，催着百度加快对iOS的定制开发。

更有意思的是，因为国行iPhone的AI必须找国内大模型合作，所以实际上形成了一个卖方市场，是苹果给百度付钱以获得文心大模型的模型授权，而且新的训练和微调成本，都是由苹果这边承担的。

但在海外，就算ChatGPT已经因为在苹果产品线上的预装而被制定了10亿活跃用户的年度目标，苹果也没有向OpenAI付钱，双方的合作更像是互利关系。

所以你们能感受到苹果心里有多苦了吧，钱当然不是问题，问题是给了钱后拿到的东西根本没法用⋯⋯

还有一条消息是，百度希望能够保存并分析用户在iPhone上使用AI之后的数据，而苹果自带的隐私权限不允许，双方在这方面也在扯皮。


### 18

2024-12-05

小互
@imxiaohu
DeepMind 发布新一代天气预测 AI 模型：GenCast

可预测未来 15 天的天气情况和极端天气风险。

GenCast 在精度和计算效率上均显著提升，与目前全球顶级天气预测系统 ECMWF 的 ENS 模型相比，GenCast 在 97.2% 的预测目标上表现更优。

在超过 36 小时的预测范围内，其准确率达到了 99.8%。

它可以生成一组 50+ 个预测，模拟未来天气的可能变化轨迹。

使用 Google Cloud TPU v5，每次生成完整的 15 天预测只需 8 分钟。



### 19

2024-12-05



小互
@imxiaohu
微软推出炸裂的Copilot Vision 功能 

可实时监控你的上网行为 随时提供AI帮助

它就像你的第二双眼睛一样，可以与你的网页浏览同步，实时监控你的网页浏览行为

能快速理解网页上的内容并随时准备提供个性化建议和进行信息处理指导等。

当你浏览商品页面时，它会根据你的需求推荐合适的产品。

它通过嵌入到 Edge 浏览器中，提供实时网页内容分析和互动。

Copilot Vision 能够理解用户当前浏览的网页内容，并提供基于上下文的辅助功能：
信息简化与提取：

Vision 会扫描网页内容，提取用户需要的信息，比如页面上的关键点或隐藏的细节。


### 20

2024-12-05



小互
@imxiaohu
Google 发布PaliGemma 2 开源视觉语言模型

- 提供不同规模大小（3B、10B、28B 参数）和分辨率（224px、448px、896px），适配各种任务需求。

- 可生成详细、上下文相关的图像说明，不仅限于识别物体，还能描述动作、情感和场景叙述。

例如能识别图片中对象的动作、情绪、故事线，特别适合用在图片生成内容或图像搜索上。

-在化学公式识别、乐谱识别、空间推理和胸部 X 光报告生成等领域表现优异。

作为 Gemma 家族的下一代产品，PaliGemma 2 增强了模型的视觉理解能力，并提供了更高效的性能和扩展性。

### 21

2024-12-05

小互
@imxiaohu
Runway Act one 又更新了 

现在可以将你的表演转移到其他视频当中

也就是可以把你表演的动作或声音直接“套用”到已有的视频角色上。

比如：你拍一段自己表演的动作，它就可以让另外视频中的角色模仿你的表演动作。

这样你可以用在真人拍摄的视频，然后将声音和动作表情转移到动画制作视频里。

或者直接通过“配音”类的表演，给角色加上你的新声音。

演示视频来自 
@CitizenPlain



### 22

2024-12-07

九原客
@9hills
o1 RFT 看起来和之前预测的差不多。

1. 输出是 JSON 格式的 {“reasoning”: “xxx”, genie: []}，genie是输出字段，例子里是个列表。
2. 训练数据集只需提供最终答案，不用提供 reasoning 推理过程。
3. 需要有明确的 Grader 评分器，故较适合有正确答案的场景（数学、科学等）。



### 23

2024-12-07


ollama
@ollama
Ollama 0.5 is here with structured outputs!

This makes it possible to constrain a model’s output to a specific format defined by a JSON schema.

Some examples include: 

- Parsing data from documents
- Extracting data from images
- Structuring all language model responses
- More reliability and consistency than JSON mode

🧵1/3

翻译帖子

ollama
上午3:18 · 2024年12月7日
·
23.6万
 查看

ollama
@ollama
·
2024年12月7日
Please update Ollama to 0.5: 

https://github.com/ollama/ollama/releases/tag/v0.5.0

Python library update:   
https://github.com/ollama/ollama-python/

JavaScript library update:
https://github.com/ollama/ollama-js/

🧵2/3
显示更多
ollama
@ollama
·
2024年12月7日
Blog post with examples: 
https://ollama.com/blog/structured-outputs


### 24

2024-12-07

宝玉
@dotey
OpenAI 12 天 的 第 2 天，强化微调，通过少量数据，让模型在专业领域到达专家水平。

跟之前的微调不一样，它不是通过把数据记住答案，而是在微调的过程中训练自己在某个领域的推理能力找到正确答案，有点像给 AI 一本棋谱，让它自己训练自己下棋。

这种微调有两个不同数据集合，一个是微调数据集，一个是测试数据集合，模型先基于微调数据集合去训练，然后用测试数据集合验证，反复自我推理训练验证，最终达到很高的水平。



### 25

2024-12-07


歸藏(guizang.ai)
@op7418
微软开源的这个 3D 生成项目 TRELLIS 太好了！

试了几个又快又好，16G 显存占用，即使是演示空间，一次生成也只需要 十几秒。

可以生成各种最终的 3D 表示，包括但不限于辐射场、3D 高斯和网格，满足不同的下游要求。


### 26

2024-12-07



小互
@imxiaohu
人人影视字幕组将20年的字幕数据全部开源分享

包含几万集的各种影视字幕内容

同时还有他们开发的字幕软件和源码也一起打包

还有开发的网站设计模板和HTML页面等等

好人一身平安...

下载链接在2楼
下午6:11 · 2024年12月6日
·
8万
 查看

小互
@imxiaohu
·
2024年12月6日
下载链接：https://pan.xunlei.com/s/VODQA8aOVLHwAzMdtkBlLk7UA1?pwd=db5u&continueFlag=0fa232a98bb9df82e6fee7b512651a97


### 27

2024-12-07

九原客
@9hills
OpenAI o1 强化微调（RFT）开源方案之字节 ReFT

因工作重点做LLM的落地，对模型的 Reasoning 推理能力要求较高，也实践过 CoT 微调。而 o1 能推出 RFT 证明这项技术已经生产可用，故接下来就认真研究下业界方案，尤其关注可落地执行的开源方案。

首个拜读的论文是来自字节的 《ReFT: Reasoning with Reinforced Fine-Tuning》，今年1月份发布，且貌似是第一个提出 RFT 名词的文章。（题外话，字节的学术做的很不错， NeurIPS 2024 有很多篇字节的论文。）

整个 ReFT 的方法参见附图1。具体的原理见论文，核心是具备了三个 RFT 的关键要素：

1. 不依赖人工思维链标注的奖励系统。这是和传统的 RLHF、DPO等方法对比，在数学等领域中，有天然的正例可以作为 PPO 训练的奖励基础，无需人工标注思维链。

2. 只需要标注正例答案，ReFT 可自行搜索 CoT 路径（含负例和正例）。 之前 CoT 微调主要靠大量 CoT 数据，这种微调方法我也实践过，缺点有2： 1. 需要合成大量数据，2. 正确路径不止一条，模型仅在单一的正确路径上训练，泛化性较差。参见附图2 ，ReFT  可以搜索到错误和正确的路径，且除多次合成路径外，也增加多数投票、奖励模型重排序方法来提升路径质量。

3. 部分正确奖励信号：ReFT将推理正确打分为1，推理失败打分为0，不正确的结果打分为0.1。从而可以缓解稀疏奖励的问题，提升训练稳定性，鼓励模型探索更多的推理路径。这点可能不够精细，o1 号称可以做到分步奖励，但是需要等 RFT 上线后才能知道～

接下来，有三个方向可以继续学习：

1. 如何更好的自动搜索 CoT 的不同路径？MCTS？
2. 如何更好的给出奖励信号？分步奖励？
3. 在某个真实的推理需求中进行测试？手头有一些医疗诊断和设备诊断的数据。


### 28

2024-12-07

宝玉
@dotey
让 Gemini 帮我分析 14 万行混淆后的 js 代码

前几天测试一个视频工具网站，发现它生成视频缩略图的速度特别快，因为我以前也做过，是基于 ffmpeg 命令行生成的，网页也能执行，但是耗时比较长一点，我就好奇它是怎么实现的，于是就去看它的 js 代码，但是混淆后代码文件太长了，主文件达到了 14 万行代码，尝试用各种 ffmpeg 关键字去分析一无所获。

今天突然想到  Gemini 上下文长度很长，也许可以，于是将 14 万行代码复制粘贴进去，168 万 Tokens！不过 Gemini 最高可以到 200 万 Tokens。

提示词很简单，就是让它找到生成视频缩略图相关函数，并解释其实现原理，最后模仿着实现一个。

最后运行了大约 4 分钟时间，帮我找到了相关的函数，给出了解释，并实现了一个简化版代码，原来不是基于 ffmpeg 实现的，而是基于 Canvas 画上去的，难怪之前一直没找到代码。

长上下文在分析长代码上还是蛮有优势的。


### 29

2024-12-07


歸藏(guizang.ai)
@op7418
Andrej Karpathy 昨晚推荐了一下自己的书单，里面有很多我没听过但感兴趣了，回头看看。

评论区很多人也推荐了自己喜欢的书，马斯克也推荐了Iain M. Banks 的《文化》系列小说。
引用
Andrej Karpathy
@karpathy
·
2024年12月9日
Of ~200 books I've read, the few that stayed with me over time and I find myself often thinking back to or referring to, in ~random order:

All short stories by Ted Chiang, especially Exhalation, Division By Zero, Understand, The Story of Your Life, Liking What You See, The



### 30

2024-12-07


Andrej Karpathy
@karpathy
Of ~200 books I've read, the few that stayed with me over time and I find myself often thinking back to or referring to, in ~random order:

All short stories by Ted Chiang, especially Exhalation, Division By Zero, Understand, The Story of Your Life, Liking What You See, The Lifecycle of Software Objects, What's Expected of us, just excellent themes ideas and reading all around.

The Selfish Gene (nonfiction) - a classic for understanding evolution and natural selection, especially the realization that the gene is closer to the real unit of selection more than an individual, explaining altruism and colonies and a lot more.

The Lord of the Rings (fantasy) - I return to LoTR all the time for comfort. I don't think anyone else has created a high fantasy Universe this complex, with so much mythology, symbolism, new languages, mysterious system of magic, ancient and powerful beings and artifacts, beautiful writing and dialog, themes of courage, friendship and heroism, the list goes on and on... You're thrown into a world with characters and references to so many things that are part of this ancient world and never really introduced. There's always more to find on each reading.

The Martian (~scifi) - top tier science porn, competence porn, fast paced and fun.

The Vital Question (nonfiction) - First time I intuitively grokked the bridge from geology to biology, the origin of life, and likelihood of life in the Universe at large at various stages of complexity and development. Also all other Nick Lane books.

How To Live by Derek Sivers (nonfiction) - 27 conflicting answers to how to live life. Emphasizing the diversity of consistent and possible answers to the meaning and goals of life.

1984 (nonfiction) - Classic. Newspeak, Ministry of Truth, Doublethink, Thoughtcrime, Facecrime, Unperson, the list just keeps on going. Chilling world-building and the realization that weaker equivalents of everything exist.

In Defense of Food by Pollan (nonfiction/food) - Eat food. Not too much. Mostly plants. The book that first taught me to avoid the entire center of every grocery store and only shop on the outer ring. The realization that the food industry is out of control and the things they do with your food, what they put into it, what they are allowed to do, and how they are allowed to market it to you is quite a lot worse than I thought.

The Accidental Superpower by Zeihan (nonfiction/geopolitcs) - I've found Zeihan to be a bit of a mixed bag over time but I still remember his books (esp this one) to be elucidating on geopolitics.

Countdown to Zero Day (nonfiction/cyberwarfare) - Goes into detail on Stuxnet, imo very important and highly elucidating reading on cybersecurity, the future of warfare, and AGI.

A Fire Upon the Deep (scifi) - Chapter one only, incredible portrayal of what superintelligence will be like that has stayed with me since.

Guns Germs and Steel (nonfiction/history) - I'd probably recommend a summary of this book more than the book itself. I remember it being very dry, but it was very interesting because it is a comprehensive analysis of the resources grid (food, animals, freshwater, climate, ...) in our real-world game of Civilization, and the implications there of.

Flowers of Algernon (scifi) - Just a totally crushing masterpiece on intelligence.

Atlas Shrugged (scifi) - No one finishes this I think but the first few chapters and its worldbuilding are enough and, once seen in an exaggerated form in fiction, elements of it cannot be fully unseen in reality.

An Immense World (nonfiction/bio, by Yong, among others of his) - Nice book on so many different sensors used by various animals, you repeatedly realize human senses are super inadequate and that we only measure such a tiny sliver of reality.

The Master Switch (nonfiction/tech history, by Wu) - history of information technologies telegraph, telephony, radio, television, film, cable television, internet and the pattern of "The Cycle", where each medium starts decentralized, open and idealistic and then progresses towards centralization, control and oligopoly, for the very similar reasons, by very similar means, and usually at the expense of diversity, innovation and technological progress. Quite a few connections to draw on for LLMs, which are after all an information technology too.

(I take recommendations for more that are likely to make this list!)


### 31

2024-12-07


宝玉
@dotey
cursor rule文件挺实用，但不要滥用不要太长，因为太长会导致每次上下文太长影响生成效果，像什么中文回复、markdown之类就没必要了，因为你中文输入提示词就默认中文回复，只需要最关键的几点：
- 你的项目类型
- 主要框架
- 命名规则等

比如下面是我用的




### 32

2024-12-07


宝玉
@dotey
来自 Jason Wei 的感慨：他在强化学习(RL)领域的认知发生了180度大转变，2022年之前完全没接触过强化学习研究，也不认为强化学习对AGI(通用人工智能)很重要，现在强化学习已经深入影响了他的日常工作和思维方式，每天想着如何为RL优化代码，如何为RL设计数据，甚至用 RL 的视角看待生活。

结合周五 OpenAI 周五推出的针对推理模型的强化微调，可以看出 o1 推理模型的背后离不开强化学习，未来大模型的发展方向也会深度结合强化学习。


### 33

2024-12-09



宝玉
@dotey
o1 这类推理模型和以前的 GPT-4o 这样的大语言模型最大的不同在于它可以用算力换能力，以前的大语言模型是“快思考”，也就是你提一个问题（输入一个Prompt），它马上返回结果，那么这个结果很可能是错的，而且也无法自动纠错，只能重新开会话或者继续发后续消息内容纠正。但 o1 这样的推理模型，它是“慢思考”，在给出最终结果前可以反复推演甚至回溯到之前的步骤重新开始，就像围棋高手在算棋子一样。

o1 pro 跟 o1 的差别，主要在于可以用于思考的时间的长短，现在用 o1 的话，一般就是一二十秒就给出了结果，而 o1 pro 会更长时间也意味着更多算力在反复思考，所以结果会更好。

《纽约时报》有一款名为“Connections”的文字游戏，每天会更新，这个游戏以前 GPT-4o 做不出来，现在 o1 pro 可以做出来，从原推图中你可以看到它为了解决这个问题花了一分多钟时间“慢思考”。

以前的算力主要都是花在训练模型上，以后慢慢的算力要更多的花在推理上了。

### 34

2024-12-09

Yangyi
@Yangyixxxx
那些想做Cursor AI coding培训，又担心找不到客户的，照这个方法就可以开启你的AI培训课：

1、把 curosr.dictionary 这导航站里面的所有内容，RPA或者Cursor搞个小脚本，爬了
2、分类转成PDF文档，和一个国内的导航站目录
3、文档里塞上自己的购课链接和二维码，打包网盘
4、开始分发，比如闲鱼和淘宝去卖资料，还可以把这些资料赠送给那些淘宝店卖Cursor会员的人【有你的资料，更容易卖掉会员代充】
5、源源不断会有人加V找你买课，如果你没课，也可以找那些有课的人，分销他们的
6、这生意就这么运转起来了

当你的学员足够多了，就会有各类mvp需求单过来，然后进行二次分发。
赚了钱还可以考虑开始跑投放扩规模

说句实在的，如果真想赚钱，有大把的事情可以去做，但最重要的是找到自己认可的，适合自己的，能持续做下去的。

听网上说这赚钱那赚钱的，不一定适合自己。赚钱路子都一样，引流，找客户，成交产品服务。是自己做产品服务也好，还是分销别人的也罢。总归都是这么个路线。

能解决别人的问题，就能赚到钱。



### 35

2024-12-09

醍醐
@tihu
北大和字节跳动做的识典古籍真的很棒。https://shidianguji.com



### 36

2024-12-09

歸藏(guizang.ai)
@op7418
谷歌昨晚发布 Willow 量子计算芯片，继续巩固量子霸权。

这次发布可能比 Sora 要重要的多！

Willow能够随着量子比特的增加，呈指数级减少错误，这是 30 年来量子计算领域最重要的挑战。

Willow 在五分钟的时间内完成基准计算，计算量足够现在最强的计算机计算 10 万亿年，宇宙都没这么长时间。


### 37

2024-12-09


宝玉
@dotey
OpenAI 连续 12 天 AI 发布会：第三天完整视频（中英文双语字幕）

Sam Altman：
大家好，欢迎来到第三天。
这是我们期待已久的发布会。
我们将推出 Sora，我们的视频产品。
我们会讨论为什么它如此重要且令人激动，但首先，它实在是太酷了，我们就想先给你们展示一下。
这里是 Sora 产品的一些界面预览。这是视频流页面，用户生成的视频内容都在这里展示。
稍后会详细讨论，但我们迫不及待地想先展示给大家一点点内容。

所以视频对 OpenAI 来说很重要，有很多原因，我想分享三点：
首先，我们热衷于为创作者打造工具。这种创造文化对我们至关重要，也是我们希望人类利用 AI 的方式之一。在早期测试者中，我们观察到一种新型的协作创作动态，这不仅有趣，而且显示了 AI 创意工具的潜在使用模式。

第二，我们不希望这个世界只是科技。如果 AI 系统主要通过文本来与人互动，我认为我们错过了一些重要的东西。我们希望我们的 AI 能理解并生成视频，我认为这将深刻改变我们使用计算机的方式。

第三，这对我们的通用人工智能路线图至关重要。视频将是一个重要的环境，我们或  AI 将在这里学习到很多关于如何实现我们在世界上所需的目标。

现在我把这个交给负责  Sora 的 Aditya 和 Sora Research 的 Bill。他们将为你介绍一些相关内容。接下来，我们将邀请产品团队上来。

Aditya Ramesh：
谢谢，Sam。
大家好，今天终于是 Sora 正式上线的日子。
我们将在美国和大多数国际市场发布 Sora，并在今天晚些时候上线。
你可以在 http://Sora.com 访问该模型。
这是 OpenAI 从零开始设计的全新视频生成产品体验。
最棒的是，如果你已有 ChatGPT Plus 或 Pro 账号，你无需额外付费即可开始使用 Sora。我们已经将其包含在现有账户中。

要进行这样的大规模部署，Sora 研究团队付出了大量努力，改进了我们在二月份预览的模型，使其速度更快、成本更低。他们的努力卓有成效，今天我们推出了 Sora Turbo。这是原始 Sora 模型的全新高端加速版本，具备我们今年早些时候在技术报告中所提到的所有世界模拟能力，包括从文本生成视频、动画图像以及众多视频转换功能，如重混新风格、时间向前和向后延伸等。稍后其他同事会为你们展示这些功能。

正如 Sam 提到的，我们在 OpenAI 启动了 Sora 项目，以构建能够深刻理解世界及其物理的 AI 系统。我们才刚刚开始。这个早期版本的 Sora 会犯错误，并不完美。但它已经能够为增强人类创造力提供有用的工具。我们迫不及待地想看到，从今天起全世界将用  Sora 创造出什么。

Aditya Ramesh：
Aditya？

Aditya Ramesh：
嗨，我是 Aditya。
我对这次发布感到非常兴奋。
Open AI 多年来致力于训练最先进的模型，不断推动视觉生成技术的边界。然而，我们认为，要在视觉生成领域实现更大的突破，既需要机器学习的进步，也需要人机界面设计的革新。

正因为如此，我对我们构建的这款产品感到无比自豪。接下来，我将把时间交给 Rohan 和 Joey，他们会告诉你更多信息。

Rohan Sahai：
嗨，Rohan。

Joey Flynn：
嗨，Joey。

Rohan Sahai：
嗨，Sam，最近怎么样？
我很兴奋能展示这个产品。
我们开始吧。
我是 Rohan，我是 Sora 产品团队的负责人。

Joey Flynn：
我是 Joey，Sora 的产品设计师。

Rohan Sahai：
好的，Joey，我们开始吧。

Joey Flynn：
好的。
我来介绍一下 Explore。Explore 是一个为获取创意灵感而设计的栏目。这里有一个社区分享的视频流，大家可以在这里汇聚，探索这个强大新模型的功能。我们知道这些模型在首次使用时，往往不知道能做些什么。因此，创建一个空间让人们可以聚在一起学习和分享技巧与创作方法，对我们来说既兴奋又有意义。

你可以在这里滚动浏览，你会被各种精彩视频启发。我刚刚看到一个非常有趣的视频。如果你觉得某个视频特别吸引人，可以点击进入观看，它会在弹出的对话框中显示。在对话框底部，你可以看到创建该视频的具体方法。不论是简单的文字提示词、图像扩展、视频扩展，还是我们其他强大的创意工具，你都可以学习如何将这些方法融入自己的创作流程中。

下面请 Rohan 开始我们的首次生成演示。

Rohan Sah ai：
好的，让我们进入库（Library）页面。你可以把它看作  Sora 的主界面，在这里查看所有生成内容。在这里你可以用几种不同方式切换视图：网格视图，列表视图。你可以创建文件夹，你可以收藏内容，查看信息流中的书签。这些都是细微的组织功能，但它们体现了我们对支持讲故事和实际应用的重视。

好的，下面你会看到我们简单的创作工具。在这里，你只需用文字描述场景，或者上传一张图片，就可以生成视频。Sam，你有什么想法吗？

Sam Altman：
比如让猛犸象在沙漠中行走如何？

Rohan Sahai：
好的，猛犸象在沙漠中行走。我喜欢这个创意。我们就说：“猛犸象在沙漠中行走。”是个风景画面。或许我们可以设定为一个宽景镜头。

在启动生成之前，我想快速介绍一下下面的一些选项：宽高比，Sora 可以生成横向、方形或纵向比例的视频。它可以生成分辨率从 480p 到 1080p。视频时长可以从 5 秒到 20 秒不等。此外，你还可以一次生成多个版本。如果你不确定描述的结果是否符合预期，Sora 会为你提供多个方向的尝试。Variations 功能让你看到不同选项。

最后，还有预设。有时候你可能会发现一个非常喜欢的风格，并希望将其变成可重复使用的组件。你可以做到这一点，也可以使用我们默认的预设，比如“定格动画”或“气球世界”。

好了，现在我们开始生成。接下来，我会把时间交给 Joey，他会为大家讲解另一项非常棒的功能——故事板（Storyboard）。

Joey Flynn：
太好了。谢谢，Rohan。

Rohan 刚刚展示了如何将一个普通的想法发送给  Sora，让它创建一整套精彩的视频。今天，我们还将推出一项全新的创意工具——“故事板”。它允许你通过熟悉的时间轴为视频设定多个动作序列，像导演一样掌控全局。

我现在来展示一下“故事板”的一些功能。
在屏幕顶部是故事板卡片，你可以描述环境、角色，以及你希望在视频中特定时刻发生的动作。下面是时间轴，你可以为动作排序。然后是创作设置。

我来举例：
第一个场景卡片，我输入：“一只美丽的白鹤站在小溪中。”还加上黄色尾巴的细节。它站在小溪中。

我希望白鹤一开始站着，然后将头探入水中并叼起一条鱼。所以，我回到时间轴，在视频的某个时段添加第二张卡片：“白鹤将头探入水中，并叼起一条鱼。” 时间轴上的两张卡片之间有空隙，这给 Sora 提供了空间来衔接动作。
我设置好卡片后，点击生成，稍后查看结果。

我还想展示图像到视频的故事板功能：
我在第一张卡片上传一张桌面上有灯塔的图片。Sora 自动分析并为这张图片生成一个“续接描述”卡片，将静态图像转变为动态视频。
我可以随时编辑卡片内容或调整时间轴中卡片的位置。
现在，我也启动这一段生成，稍后查看结果。

我将时间交给 Rohan，让我们回顾一下这些生成的视频。

Rohan Sah ai：
好的，让我们来看看刚才的猛犸象视频。很棒！
非常好。我们可以悬停预览每个版本，看看哪一个最符合预期。

现在我觉得如果将猛犸象变成机器人可能会更有趣。
所以，我可以使用 Remix 功能，只需描述更改， Sora 会完成剩下的工作。
我点击 Remix，然后输入“将猛犸象替换为机器人”，选择强变化，启动生成。

Joey Flynn：
让我们看看白鹤视频的生成结果。
看，中间部分白鹤将头探入水中。
嗯，不确定有没有成功叼起鱼。
再看另一个生成版本。
哦，有条小鱼出现了！
虽然不是完全完美，但已经非常出色。

Sora 的故事有一半是拍摄视频、编辑视频并在此基础上迭代。
我很喜欢白鹤头部入水的那一瞬间，所以我使用 ReCut 功能，只保留这精彩的前几秒。
ReCut 会自动将这段视频导入一个全新的故事板，我可以修剪视频并为后续片段添加新指示。
例如，我在后面留空，Sora 会填补这些空白，创造一个全新的结尾或开始。

现在我生成这个新的视频片段，稍后再看结果。

Rohan Sahai：
让我们看看机器人版本的猛犸象视频。
太厉害了！
Sora 完美地执行了这个指令，用机器人替换了猛犸象。

再来看一看图像到视频的灯塔场景。 有几个不错的版本，如果我想让它循环播放，可以用 Loop 功能生成无缝循环的场景。

我们还有“场景融合”（Scene Fusion）功能，可以将两个不同的视频融合到一起。
例如，将机器人和猛犸象的场景融合。
选择另一个视频，设定一些参数，Sora 会创造一个全新的融合场景。

回到推荐内容页面（Explore），你可以逐步解析每个视频的创作过程，从中获得灵感。

Sam Altman：
这真的很不可思议。
Rohan，Joey，你们做得很棒。现在我来讲一下发布的情况。

这款产品今天在大部分地区上线，但欧洲和英国的上线时间会有所延迟。我们会努力尽快上线，但目前没有确切的时间表。还有一些国家我们无法运营。

如果你有 Open AI Plus 订阅，每月可以生成 50 次视频。如果你是 OpenAI Pro 用户，在慢速队列下可以无限制生成，并在快速模式下可生成 500 个视频。你还可以选择更高分辨率但更少数量的生成。任何账户都可以体验推荐内容功能。

我们非常期待大家的创作成果，期待见证这种新形式的娱乐和工具的应用方式。你们团队都做得非常棒，我非常喜欢这个产品。

有什么补充想法吗？

Aditya Ramesh：
是的，我想感谢研究团队，他们 开发了这款令人难以置信的模型，并将其推向世界。我们的产品团队只有五六个产品工程师，在短短几个月内完成了整个产品的构建。

同时，OpenAI 的支持团队也贡献良多。
我们非常重视滥用防范和安全性，这是 OpenAI 的核心价值之一。我们将防止 Sora 被用于非法活动，同时保护创意表达。这是一个长期挑战，一开始可能不完美。如果审核有误，请反馈给我们，我们会不断改进。
非常期待看到大家的创作。

Joey Flynn：
是的，我想补充一点。
如果你期待按一个按钮就能生成一部完整电影，那么可能会失望。Sora 是一个工具，它让你可以快速尝试多个想法，实现以前难以想象的创作方式。它是创作者的延伸。
我们迫不及待想看到你们的作品，并会一直关注推荐内容页面。

Sam Altman：
是的，Sora 就像 GPT 的第一个版本，还处于早期阶段。它会变得越来越强大。每次我们发布早期版本的产品，总会被用户用其实现的惊人创作和实际价值所震撼。我们期待在推荐内容页面上看到你的作品。

谢谢大家。


### 38

2024-12-11


宝玉
@dotey
Google量子计算新突破：量子计算芯片 Willow 5 分钟完成传统计算机100亿亿亿年的计算

最近大家都在关注 AI，也许没有注意到 Google 刚发布的 量子计算芯片 Willow

想象一下，有一道数学题，就算用世界上最快的超级计算机来解，也需要计算100亿亿亿年。而Google的最新量子计算芯片Willow只用了5分钟就解决了。如果你对这个数字没有概念，这个时间比我们宇宙的年龄（138亿年）还要长得多！

什么是量子计算？

要理解这个突破，我们先来聊聊普通计算机和量子计算机的区别：

- 普通计算机使用的是"比特"（位），就像一个开关，只能是开（1）或关（0）两种状态
- 量子计算机使用的是"量子比特"（量子位），它可以同时处于多个状态，这让计算能力呈指数级增长

Willow的突破性进展

Google的Willow芯片最大的突破在于解决了量子计算领域30年来的一个大难题。传统上，量子比特越多，计算错误就越多。但Willow通过创新的"逻辑量子位"设计，实现了相反的效果：随着量子比特的增加，错误反而会减少。这就像搭建了一个会自我纠错的超级计算系统。

这对我们的生活意味着什么？

虽然现在还不能期待在家里放一台量子电脑，但Willow的突破将在未来带来许多令人兴奋的应用：

- 加速新药物的研发
- 设计更高效的电动车电池
- 优化城市交通流量
- 开发更安全的通信加密系统
- 提升人工智能的学习能力

未来展望

Google预计在2030年左右可能会看到商用量子计算机。虽然还面临着提高运算精度、降低成本等挑战，但Willow的诞生就像是莱特兄弟的第一次飞行——它证明了"不可能"是可能的。这打开了一扇通向未来的大门，量子计算革命已经势不可挡。

这次的突破，不仅仅是技术的进步，更预示着人类即将进入一个全新的计算时代。虽然距离普及还需要时间，但就像当年的第一台计算机一样，Willow 有可能会是未来量子计算机的开始。


### 39

2024-12-11

宝玉
@dotey
OpenAI 连续 12 天 AI 发布会：第四天完整视频（中英文双语字幕）

今天 OpenAI 为 Canvas 推出三个新功能。

首先，OpenAI 将面向所有用户开放 Canvas，并且直接将其整合到主模型中，免去了额外的加载步骤。

其次，现在你可以在 Canvas 中运行 Python 代码，并实时查看文本或图形输出。

第三，在用户定制的 GPT（Custom GPT）中也可以调用 Canvas，这样 GPT Store 上定制的 GPT 都能充分利用 Canvas 的强大功能。

***

Kevin：大家好，昨天我们发布了 Sora，这个新功能的需求非常火爆。我们的团队昨晚加班，今天一早就开始继续努力。我们正在全力以赴，让大家尽快获得 Sora 的访问权限，也迫不及待想看看你们会用它创造出什么。

不过，今天要讨论的是另一个产品——Canvas。过去几个月里，我们为 Plus 用户提供了 Canvas 的测试版，Canvas 可以让用户与 ChatGPT 在写作和编程方面进行全新形式的协作，远超出简单的聊天模式。今天我们将为 Canvas 推出三个新功能。

首先，我们将把 Canvas 面向所有用户开放，并且直接将其整合到主模型中，免去了额外的加载步骤。

其次，我们现在允许你在 Canvas 中运行 Python 代码，并实时查看文本或图形输出。

第三，我们将 Canvas 引入到定制 GPT（Custom GPT）中，这样你的所有定制化 GPT 都能充分利用 Canvas 的强大功能。

让我们深入探讨这些改进吧。

Lee：好的。谢谢你，Kevin。大家好，我是 Lee，是一名工程师，一直在致力于帮助大家更好地与 ChatGPT 协作。

Alexi：大家好，我是 Alexi，也是 ChatGPT 的产品工程师之一。

Lee：（笑）Alexi，圣诞节快到了，你家孩子们是不是已经很兴奋了？

Alexi：哈哈，是啊！他们对圣诞故事特别感兴趣。或许我们可以用 Canvas 给他们编一个有趣的圣诞故事？

Lee：好主意！让我们试试看吧。

（Lee 在界面中操作）

Lee：从今天开始，在 ChatGPT 的输入框（Composer）中有一个新按钮，可以查看所有可用工具，其中就包括 Canvas。我点击 Canvas 后，无论输入什么内容，ChatGPT 都会生成一个对应的 Canvas。比如我输入：“帮我为孩子们写一个关于搞笑精灵的圣诞故事。” 发送给 ChatGPT 后，它就会在右侧创建一个 Canvas。

（屏幕演示）

Lee：现在画面分为左右两栏：左边是熟悉的聊天界面，右边是 Canvas。ChatGPT 会在 Canvas 中为我们生成故事文本，而我也可以在 Canvas 中直接对文本进行编辑。这与以往有很大不同，以前如果在聊天中写故事，所有文本都会挤在聊天气泡里，不便于修改。现在通过并排视图，我可以清晰地看到 ChatGPT 生成的文档内容，并随时进行编辑、加粗、修改标题等等。

Alexi：这就像一个协作文档，你和 ChatGPT 都可以同时对文本进行修改。你还可以继续在聊天区与 ChatGPT 互动，让它根据你的指令在 Canvas 中更新文档。

Lee：是的。另外，在 Canvas 右下角还有一些快捷操作按钮，比如让 ChatGPT 建议改进、延长或缩短内容、调整阅读水平、添加表情符号等等。让我们来尝试为故事添加一些表情符号。

（Lee 点击“添加表情符号”按钮）

Lee：看，ChatGPT 在文档中加上了表情符号，就像我 8 岁的孩子打字一样，让故事更有趣。

Alexi：（笑）这样非常符合孩子们的喜好。

Lee：Canvas 的启动方式很灵活。当你让 ChatGPT 与你协作写文章或代码时，它有时会自动打开 Canvas。或者你也可以在工具菜单里主动选择 Canvas，每次都会创建一个新的画布。

Kevin：这对写作非常有用。很多用户将 ChatGPT 用于文章创作、学习写作技巧等。而 Canvas 让你更容易获得反馈和修改。

Lee：是的。比如我很喜欢物理学，正在写一篇题为《圣诞老人的雪橇：探讨暗能量在驯鹿推进中的作用》的文章。之前，如果我把整篇文章复制进 ChatGPT，反馈与文本混在一起，不太直观。现在，我只需将文章粘贴到提示区域中，然后点击“在 Canvas 中打开”按钮，就能在 Canvas 中直接编辑和查看全文。更好的是，在发送给 ChatGPT 前，这个 Canvas 就像一个草稿区，我可以先对文本进行本地修改，然后再让 ChatGPT给出反馈。

Alexi：是的，在 Canvas 中你可以让 ChatGPT对文档的特定句子提出点评和修改建议。每条点评会高亮显示文中对应的句子，你可以选择接受或忽略建议，还可以自己动手修改，然后将最终版本复制出来。

Lee：这大大简化了与 ChatGPT 之间的反馈循环，让写作更高效。

Kevin：这很有帮助，不过 Canvas 不仅仅适用于写作。很多人用 ChatGPT 来编程，所以我们在 Canvas 中也为编程提供了强大的新功能。

Alexi：对，我这几天在帮圣诞老人处理一些玩具制造的物流问题，需要用 Python 做数据分析。以前我得复制代码到本地 IDE，然后调试，再回到 ChatGPT 寻求帮助，现在一切都可以在 Canvas 中完成。

（Alexi 将一段 Python 代码粘贴到 ChatGPT 界面中并在 Canvas 中打开）

Alexi：Canvas 自动识别代码类型，为 Python 提供语法高亮和简单的代码补全。接下来我请求 ChatGPT 帮我调试代码。ChatGPT 指出我在 matplotlib 中用了不存在的函数 plot.label，正确的函数是 title。

Lee：以前我就经常犯类似的错误，现在 ChatGPT 可以直接在 Canvas 中帮我修改。

Alexi：不仅如此，Canvas 中可以运行 Python 代码！我只需点击右上角的“运行”按钮，代码会在 WebAssembly 的 Python 环境下即刻执行，并在下方显示控制台输出和图形结果。

Lee：这意味着不需要在本地环境来回切换，我可以在同一个界面里生成、运行、调试代码，得到即时反馈。

Alexi：是的，这对学习新库和快速迭代非常有帮助。而且 ChatGPT 会根据运行时的错误信息给出修正建议，一键即可让 ChatGPT 对代码进行修改。还有“显示更改”功能，让我清楚看到 ChatGPT 对代码的差异修改，就像版本控制系统一样方便。

Kevin：这太棒了。最终我们还要介绍 Canvas 和定制 GPT 的结合。定制 GPT 允许你在 ChatGPT 中为特定任务创建定制化的模型和上下文，比如为圣诞老人创建一个自动起草回复信件的 GPT。

Lee：是的，我这里有一封给圣诞老人的信件照片，我们把它拖入 ChatGPT，让定制的 GPT 来用 Canvas 为圣诞老人起草一封回信。

Alexi：当我向这个定制 GPT 输入信件和背景信息，它会自动创建一个 Canvas，为这封信生成回复草稿。这样圣诞老人就可以在 Canvas 中直接修改、润色，然后发送出去。

Lee：在定制 GPT 的配置中，我在说明里写明：“请始终使用 Canvas 来起草圣诞老人的回信初稿”，并在功能列表中勾选启用 Canvas。这样每次这个 GPT 回应时就会自动使用 Canvas。

Kevin：总而言之，今天我们发布的更新包括：Canvas 对所有用户开放并与主模型集成、在 Canvas 中直接运行 Python 代码、以及将 Canvas 功能融入定制 GPT 中。这些改进适用于所有用户，无论是免费还是付费计划，都能使用 Canvas 中的基本功能。

Lee：我们迫不及待想看看大家如何利用这些新功能来创作内容、编写代码和构建定制模型。

Alexi：在结束前，让我们来点节日的幽默吧。Lee，有没有圣诞笑话？

Lee：当然！“圣诞老人怎么拍照？”

Kevin：不知道啊，用什么拍？

Lee：用“北极牌宝丽来”相机！（众人笑）

Alexi：（笑）祝大家节日愉快，我们明天再见！



### 40

2024-12-11



宝玉
@dotey
如果要排序的话，模型要放在第一位的；然后是上下文准确充足，这是需要很多工程努力的；交互就是锦上添花了，前两者做足后者基于vs code的体验别太差就可以了。
Windsurf比Cursor差的在第二点，仔细用应该能体会到。

### 41

2024-12-11


宝玉
@dotey
OpenAI 连续 12 天 AI 发布会：第五天完整视频（中英文双语字幕）

今天的直播会唯一的亮点就是苹果智能集成了 ChatGPT，可以通过 Siri 对文档总结。

***

Sam：欢迎来到我们“12 Days of OpenAI”系列的第五天。今天，我们想介绍让 ChatGPT 更加简单易用的一些新功能。苹果的朋友们正努力将 ChatGPT 集成到 iPhone、iPad 的 iOS 系统以及 macOS 系统中。我们的目标是让 ChatGPT 在各种平台上都能轻松顺畅地使用。我们都很喜欢 Apple 的设备，因此对这次集成非常自豪。
你可以在不登录的情况下使用，但如果有账户体验会更好。让我请 Dave 给大家演示一下这项功能的实际操作。

Dave：大家好，我是 Dave，来自工程团队。我和 Sam 一样，非常喜欢 Apple 的设备。我使用 Apple 设备已经有 30 年了，现在在许多 Apple 产品上，你可以直接通过操作系统来调用 ChatGPT。这适用于 iPhone、iPad 以及 Mac。我想给你们展示三种新集成方式。
首先是 Siri 集成：当 Siri 认为 ChatGPT 更能解决你的问题时，会直接将请求交给 ChatGPT。
接下来是写作工具：Apple Intelligence 的写作工具原本就能帮你完善、总结和提取文档要点，现在借助 ChatGPT 还能从零开始为你起草文档，真是太酷了。
最后，在 iPhone 16 上还有摄像头控制功能，可调动视觉智能，让你用 ChatGPT 来了解镜头里看到的东西。
接下来就请产品团队的 Miqdad 来为大家演示。

Miqdad：好的，让我们先看看 iPhone 上的实现。我打开了我的 iPhone。首先需要在“设置”中启用 Apple Intelligence。在“设置-Apple Intelligence 和 Siri”里，我已经打开了这个功能。往下看，你会发现一个新的 ChatGPT 扩展选项，我已经登录了我的账户，同时我也可以选择在 Siri 将请求转交给 ChatGPT 之前进行确认。这样我对数据的分享有完全的控制权。

Sam：太棒了，我们现在正在筹备一个节日派对。我想让 Siri 帮忙问 ChatGPT 来组织一个圣诞派对。

Miqdad：（对着手机）“Hey Siri，你能让 ChatGPT 帮我们组织一个圣诞派对吗？”
看，Siri 现在会出现一个新的彩虹图标，然后请求会转给 ChatGPT。ChatGPT 会给出各种建议，比如嘉宾名单、音乐和娱乐活动。

Sam：能让 ChatGPT 再给我们推荐一份假日歌单吗？我想看看 Mariah Carey 的歌是不是排在第一位。

Miqdad：（再次对手机）“Hey Siri，请让 ChatGPT 给我一个假日歌单。”
很快 ChatGPT 会给出一份包含经典节日歌曲的列表。果然，Mariah Carey 的歌在第一位！

Dave：完美啊。

Miqdad：我现在可以点击底部的蓝色“ChatGPT”图标直接进入 ChatGPT 应用，继续在对话中调整内容。比如，我可以对歌单加上表情符号，或者让 ChatGPT 为这份歌单设计一张专辑封面。

Sam：加点节日气氛怎么样？

Miqdad：好，那就让 ChatGPT 为歌单设计一张充满节日气氛的专辑封面……加上一只“froge”（青蛙）应该更有趣！
（等待 ChatGPT 生成结果）
看，它给了我们一幅很可爱的封面，有一只巨大的、愉快的节日青蛙。

Dave：太赞了！真有创意。

Miqdad：现在我们既有派对计划又有歌曲歌单和专辑封面了，我想继续借助视觉智能来评选一下我们的节日毛衣谁的最有创意。
我将长按相机控制按钮，启用视觉智能，然后用镜头拍下我们三个人的毛衣。
（对着设备）请问 ChatGPT，你能根据这张照片给我们三个的圣诞毛衣创意度排个名吗？从最有趣到最不有趣。

Sam：是啊，我们并不评判，只是想听听 AI 的看法。

Miqdad：（等待结果）
ChatGPT 的评选结果出来了——Sam 的毛衣最有特色，排在第一位！

Sam：哇，我竟然赢了！我本来在三件毛衣中随便挑了一件，没想到是这件最特别。

Dave：（笑）看来我的 LED 灯毛衣没能打动它啊。

Miqdad：好吧，祝贺 Sam。我给你做个胜利奖杯吧。（再次请求 ChatGPT）
现在你有了胜利奖杯的图像。

Sam：太有意思了！
好的，那我们回到工作上来吧。

Dave：是的，玩乐过后，让我来展示 Mac 上的体验。在 macOS 15.2 Sequoia 系统中，你同样可以在“系统设置”中启用 Apple Intelligence，然后也能开启 ChatGPT 扩展。和在 iPhone 上一样，可以选择匿名使用或登录账户。
设置好后，在 Mac 的任何应用程序里，你都可以通过 Siri 或写作工具来调用 ChatGPT。
我这里有一份 49 页的 PDF 文档，我想让 ChatGPT 帮忙总结下它是如何让模型在编程上表现出色的。
只需双击 Command 键，通过输入给 Siri 发出命令。当 Siri 识别到这是个复杂任务时，会请求使用 ChatGPT。我可以选择是否上传整份 PDF，让 ChatGPT 分析。
发送过去后，ChatGPT 很快就能给出解释和总结。这节省了我大量时间。

Sam：并且，就像在 iPhone 上一样，你可以点击底部的 ChatGPT 按钮，在桌面应用中继续这次对话。

Dave：是的，这实在太酷了。我还可以让 ChatGPT 根据 PDF 内容生成可视化图表，比如用饼图显示不同技术对编程能力影响的比例。ChatGPT 可以根据文档再分析、处理并产出相应的可视化代码。
这些对话都能在不同设备间同步，让我随时随地进行深度研究或创作。

Miqdad：从 iPhone 到 iPad 再到 Mac，这样的整合让 ChatGPT 无处不在。

Sam：是的，我们对这次发布非常兴奋。这让与 ChatGPT 的交互变得前所未有的简单，希望你们会喜欢。感谢苹果团队的支持，祝大家有个愉快的一天！


### 42

2024-12-11


歸藏(guizang.ai)
@op7418
谷歌憋不住了开大了，发布四个🐂🍺项目！

原生多模态输入输出的 Gemini2.0

实时多模态沟通助手 Project Astra 的进展

Project Mariner 浏览器类贾维斯助手

Jules：代码开发助理


### 43

2024-12-11




宝玉
@dotey
请教两个 Electron 开发的技术问题：
1. React开发的话哪个脚手架框架最好？
以前用过 Electron Vite挺不错，但最近一搜两个一样的都不知道哪个好、有啥区别

2. main进程和renderer进程间通信(IPC)的有没有简单的、支持强类型的类库可用？


### 44

2024-12-11


宝玉
@dotey
Repo Prompt 这个工具挺实用的，它可以把你整个Repo的代码拼成一个XML文本，方便你发给像Gemini 2、Claude 3.5、o1 pro这样支持长上下文的模型。
当然你也可以只选择部分文件，目前只支持 Mac
https://repoprompt.com

### 45

2024-12-14

小互
@imxiaohu
Ilya Sutskever在神经信息处理系统会议上演讲中文视频

主要观点：

- 现阶段语言模型在预训练阶段，已经达到了瓶颈 ，因为人类生产的数据已经全部被用完。

- 新数据或合成数据没有带来大的变化  

- 超级智能必将具有意识，因为目前的模型只是在复制人类的直觉，凭感觉做出的判断， 所以会产生幻觉。

- 这种幻觉而且是不可避免的，推理是不可预测的 ，它越是推理 就变得越不可预测 。

- 与人类一样，人类大脑相同，但人类仍在进步，因为人类具有自我意识会使用工具创造新的知识，LLMs将结合Agent和工具将推动这一进程。

演讲总结
--------------------------------------

人工智能与深度学习发展的回顾与展望

引言

首先，我要感谢主办方授予这篇论文奖项的机会，这真是令人高兴的一件事。同时，我也要感谢我的出色合作者Oriel Vinyals和Kwok Lee，他们刚才也在这里分享了他们的见解。

今天，我想和大家一起回顾我们在深度学习领域的一些工作，并尝试从十年的视角来反思。我们的许多工作当时是正确的，但也有一些不足。通过这些反思，我们可以更好地理解这十年来的发展轨迹。

这次分享的一个核心是，我们会通过十年前的一些演讲内容和幻灯片，回顾我们当时的观点，并审视它们对今天的影响。

十年前的深度学习理念

十年前，我们的工作集中于以下三点：

自回归模型：基于文本进行训练。

大型神经网络：当时10层网络已经被视为突破。

大规模数据集：充分利用数据训练模型。

我们提出了深度学习的假设：如果你有一个10层的大型神经网络，它可以完成任何人类在极短时间内完成的任务。为什么会强调这些快速完成的任务？

这是因为如果我们假设人工神经元和生物神经元相似，而生物神经元较慢，那么任何人类可以快速完成的任务，通过人工神经网络理论上也可以实现。基于这种动机，我们集中研究了10层神经网络的潜力。

自回归模型的突破

我们还提出了一个关键理念：“如果一个自回归模型能够很好地预测下一个标记（token），那么它可以捕获后续序列的正确分布。” 这在当时是一个新的观点。

我们的目标是机器翻译。虽然自回归神经网络并不是全新的，但我们是第一次真正相信，通过良好的训练，模型可以实现我们想要的结果。

从LSTM到Transformer

十年前，我们主要使用LSTM（长短期记忆网络），这是Transformer问世前的主要工具。LSTM可以被看作一种复杂的残差网络（ResNet）结构。虽然当时有效，但相比今天的技术，显得较为简单。

另一个有趣的特性是，我们采用了流水线并行化的方法，利用每个GPU计算一个网络层。这种方法虽然提升了计算速度，但后来证明并不是最优解。我们使用8个GPU实现了3.5倍的加速。

深度学习核心理念与规模假设

深度学习的核心在于连接主义思想：“如果我们认为人工神经元类似于生物神经元，那么很大的神经网络理论上可以实现许多人类能力。” 这一理念支撑了深度学习的发展。

我们还提出了规模假设：“如果有足够大的数据集和神经网络，成功几乎是可以保证的。” 这一假设可以说是今天预训练模型（如GPT-2和GPT-3）的基础。

数据的局限与未来展望

然而，数据增长已经遇到瓶颈。正如我们有且只有一个互联网，数据资源有限。数据被比喻为“AI的化石燃料”，现有的数据资源已经接近饱和。未来的发展需要新的策略，例如：

合成数据：生成新的训练数据。

推理计算：优化模型的推理能力。

此外，推测未来的趋势之一是“智能体”（agents）的发展。另一种可能是“01模型”以及其他创新方法来应对预训练的局限性。

对超级智能的思考

演讲中还提到超级智能的可能性。相比于当前的语言模型，未来的AI可能具备真正的推理能力、自我意识以及不可预测性。

推理能力越强，模型的行为越不可预测。就像当前的顶级国际象棋AI，其策略对人类而言已经难以理解。同样，未来的AI可能会以更高效的方式处理信息，甚至发展出类似自我意识的特性。

从生物学的角度来看，过去的研究表明，哺乳动物的大脑与身体质量之间存在密切关系，但人类和近亲（如尼安德特人）在脑体比率上表现出了不同的标度。这为人工智能的发展提供了新的灵感：未来的AI可能会探索与当前不同的扩展路径。

人类与AI的共存

关于AI与人类共存的未来，有观点认为，AI可能需要被赋予类似人类的“权利”，例如作为一种新的智能生命形式存在。这一切都充满不确定性，但探索这些问题至关重要。

另一个值得关注的问题是，如何设计合理的激励机制，确保AI的行为和发展方向符合人类的利益。目前尚无明确的答案，但加密货币或其他创新形式可能成为未来的解决方案。

结论

最后，我想强调，深度学习领域在过去十年取得了令人难以置信的进步。展望未来，我们面对的挑战同样充满潜力。从数据的有限性到AI的推理与共存问题，所有这些都需要我们深入思考。

此外，随着AI的不断进步，我们可能会迎来一个具有真正推理能力、自我意识和超级智能的新时代。这将对我们的社会、科技和伦理提出全新的挑战和机遇。

感谢大家的聆听，也期待大家的共同努力来迎接AI的下一个十年。



### 46

2024-12-14


宝玉
@dotey
字节则相反：字节内部判断AI对话类产品天花板可能不高，提升剪映即梦优先级

虽然豆包的用户规模在过去几个月有所增长，但和行业里所有AI对话形态的产品一样，其在使用时长、打开频次及商业化潜力上仍不够理想。

《智能涌现》从知情人士处获悉，字节管理层判断AI对话类（或称chatbot类）产品可能只是AI产品的“中间态”，长期更理想的产品形式，大概率需要更视觉化的用户体验、更低的用户使用门槛。因此，字节已经提升了即梦的产品优先级，尝试用新的路径打造AI时代的“抖音”。

《智能涌现》就此向字节求证，字节暂无回应。

字节反思AI对话类产品天花板
一位知情人士告诉《智能涌现》，豆包目前的用户活跃度并不算高，每周仅活跃2至3天，且每天用户发送消息轮次仅为5到6次，单次2分钟左右，用户人均使用时长仅为10分钟左右。上述这些数据在过去一年中的增长幅度并不显著。

字节内部有管理层提出，这可能并非豆包的问题，豆包的相关数据已经是国内产品第一梯队，类似ChatGPT这种基于文本的对话类产品，大概率不是最理想的产品形态。

根据QuestMobile的第三方监测数据，过去一年，豆包、Kimi、文小言等产品的用户日均使用频次，均在4到5次之间徘徊，人均使用时长也基本位于5到10分钟之间，没有明显变化。

实际上，过去一年，字节豆包的表现可谓亮眼。用户增长上，年初豆包仍然与Kimi和百度的文心一言接近。但据晚点披露，字节豆包App今年9月的日活已达760万，而Kimi智能助手，同期日活则在130多万。

此外，在产品功能上，豆包也快速补齐了音乐生成、图生图、图生视频、视觉识别等功能，其语音功能尤其出色，做到了全能和all in one。

但目前来看，对话轮次、时长等关键指标仍然不够理想。在规模变大，推理成本上涨的同时，AI对话类产品并未展示出可落地的商业化前景。

有知情人士透露，字节内部判断，付费订阅模式在中国不太可能走通。而时长和轮次太低，又导致潜在的广告空间较小，这都构成了这类产品的隐形天花板。

剪映即梦优先级提升
有知情人士对《智能涌现》称，字节管理层有人提出，长期看，需要找到更低门槛、更“多模态”的产品形式，剪映和即梦可能是合适的入口。

作为视频创作工具的剪映，实际上在图片、视频编辑等功能上已经大量落地了最新的模型技术。字节近期在图片生成、视频生成和理解领域取得的一些技术突破，包括推出了一致性极强的图生视频模型PixelDance，率先实现了在图片上精准生成中文的能力。这些能力都首先应用在了剪映和即梦。

如果把剪映视作一个AI产品，根据非凡资本旗下研究中心非凡产研发布的2024年10月全球AI产品月活榜，剪映月活高达1.7亿，仅次于ChatGPT的2.5亿，排名全球第二。

即梦是前抖音集团CEO张楠到剪映后推出的AI创作工具和社区。她此前曾在内部信中表示看好AI前景，因此决定再次内部创业，打造新的AI工具。

除了AI 工具属性外，即梦同时还具备强内容社区属性，并通过剪映获得了相当数量的AI创作者。很多AI设计师都会在即梦平台，发布自己的AI作品。随着AI工具创作效果在未来的提升，预期可以看到更多的普通用户创作出高价值的AI内容。同时，即梦对应世界模型是一个可能面向游戏、视频、Metaworld的大应用，并且很多AI功能在剪映上已经体现一些收入趋势。

字节计划后续把更多资源向更多模态的产品形态转移，即梦会承担更大的希望。比如，字节视觉生成相关的大模型在围绕即梦的需求做优化，且在即梦上首发，例如生中文字、文生视频。张楠的大部分精力也都投入在即梦上。

此外，字节内部也在探索其他一些多模态、低交互门槛的尝试。比如字节的AI互动娱乐产品“猫箱”，《智能涌现》获悉，其用户平均对话轮数是豆包的近50倍。


### 47

2024-12-14

nicekate
@nicekate8888
我请 Gemini 2.0  Flash 作为英语口语老师

Gemini 2.0 Flash 对音准识别非常敏感，能精准指出我的发音错误。

相比之下，ChatGPT 的高级语音模型对我的口语评价通常过于宽松，会说我的发音正确，但不能很好地识别具体问题。

 前者真正帮你解决问题，后者能给你自信。 

参考 了 Gemini 官方代码，链接在评论



### 48

2024-12-14

向阳乔木
@vista8
AI总结非常鸡肋！
没哪个AI模型不支持文本总结，但总结的内容，读了跟没读一样。现在还是人肉总结靠谱，尤其像
@foxshuo
 这种大神。

所以，降低预期，让AI做更实用的生成任务，比如：

- 引用翻译原文信息
- 生成列点笔记
- 文字思维导图
- 文章内容问答

花一晚上时间调试了个Prompt，效果OK
Prompt见第一条评论



### 49

2024-12-14


歸藏(guizang.ai)
@op7418
Anthropic 推出了一个可以自动识别全球 Claude 使用趋势的系统 Clio

同时还公布了一些有意思的 Claude 使用数据：

前三的主要使用场景：前端开发、内容创作、学术研究

不用语言的用例差别很大，给出了西班牙语、中文和日语相较于平均值出现更高的主题

图表我用 Claude 重新做了一下。



### 50

2024-12-14

小互
@imxiaohu
TEN：一个实时语音 AI 智能体开源框架

- 多模态支持，可创建支持语音交互的 Al Agent
- OpenAl Realtime API（超低延迟，可随时打断）
- 支持OpenAI、Gemini、Qwen等主流LLM，可快速开发
- 支持天气、网页搜索等工具调用
- 内置 STT/LLM/TTS模块
-支持无缝对接coze，让bot语音交互

支持多语言交互，可以与 OpenAI 的 GPT 系列模型无缝对接。

Gemini 2.0 Multimodal Realtime API 刚发布，TEN在24小时内已经接入了...

@TenFramework

\#voiceagent #voiceAl #RealtimeAPI #conversationalAl


### 51

2024-12-14

AI Dance
@AI_Whisper_X
和AI圈内人吃了几顿饭，收获与思考

1.四小龙时代真的是圈了一波很优秀的年轻人，也很给年轻人机会。
那一代创业者的画像，都非常技术&科研。人才密度真的很高。
但当时这波优秀的人，本有机会去更好的单位（比如google等），其实在四小龙最后没赚到钱（大钱）。
不过四小龙出来了很多新一代的创业者。
上午7:42 · 2024年12月13日
·
6.9万
 查看

AI Dance
@AI_Whisper_X
·
2024年12月13日
1/8

说实话，我觉得四小龙时AI 1.0的技术决定只能以2B为主要落地场景，没充分发挥年轻人的优势。这一代AI 2.0势必以2C为主要落地场景，更能发挥年轻人的优势。

2.算力Scale的速度超乎想象，XAI搞到了10万卡（马上20万卡），meta、OpenAl也会跟，看不到国内创业公司如何赢。
AI Dance
@AI_Whisper_X
·
2024年12月13日
2/8
但创业公司分水岭的下一个点在哪里？我个人认为2年，朋友认为会更快。

国外有更好的并购生态，google 为了买Noam一个人（及小团队）可以花二十几亿美金。Anthropic也能看到至少会被一个大厂并购，但国内没有这样的生态。
有些公司的做法是在选择下限，不批评不评论，继续观察。
AI Dance
@AI_Whisper_X
·
2024年12月13日
3/8
3.相信一定会有super app

4.每个人都应该有自己的自媒体
有些小伙伴几个人搞了个公众号，有些朋友一个人搞了个公众号。
有些朋友几个人搞了个小宇宙。
有的人更新佛系，有的人沉迷涨粉。但大部分人有主业工作。
AI Dance
@AI_Whisper_X
·
2024年12月13日
4/8

但结论是，就像《纳瓦尔宝典》说的，每个人都应该有自己的自媒体。
也许它能帮你建立个人品牌和形象；
也许它能帮你成为副业；
也许它能帮你认识行业的人；
但每个人都应该有自己的自媒体，这是你除了工作赋予你的资产以外的个人资产。
AI Dance
@AI_Whisper_X
·
2024年12月13日
5/8

5.评价：只能说上班耽误赚钱
有个朋友离职后，做自媒体搞副业，挣得不比主业工资少。
有的朋友离职后，几个月认识了几百个AI圈内人（虽然他本来也是圈内的）。
最喜欢的一句经典评价：只能说上班耽误赚钱。

http://6.八卦：
某些大厂用钱砸到创业者头晕的方式做并购。
AI Dance
@AI_Whisper_X
·
2024年12月13日
6/8
某些模型真的过拟合到benchmark太严重。

7.做人做事角度
人跟人的相遇充满缘分，真诚是个很好的鉴别器。
AI 需要学和能做的事都很多，脑子和时间都不够用。
life is ajourney，做自己喜欢的事最重要。
AI Dance
@AI_Whisper_X
·
2024年12月13日
7/8
8.关于自媒体的几个认识（因为并不是每个人都感兴趣，放在最后）

①AI自媒体为什么出来了这么多号？
之前的媒体很多不懂AI、甚至很多AI公司内做运营的都不懂。
所以就出了一些懂AI 又能搞自媒体的（尤其是 gzh）。
AI Dance
@AI_Whisper_X
·
2024年12月13日
8/8

②gzh是目前科技媒体主要投流渠道为什么？因为老板看公众号（圈内人印证了我的盲目猜测）。
大厂是最主要的做投放的广告主。




### 52

2024-12-14




九原客
@9hills
AI 信息焦虑的应对

作为大模型从业者，或多或少都存在信息焦虑。每天都有无数的新模型、新产品、新文章在发布。而除了全职自媒体，普通人的时间却很有限，需要完成工作、陪伴家人、享受生活以及学习。我的应对：

1. Keep collecting：选择一个心智负担最低的全平台 Bookmark 工具，及时将感兴趣的扔进去，可以不看，但是找的时候能找到。

2. Keep focused：选定某个细分的技术主题，比如 RAG、RFT，仅深度去看对应主题的信息，其他的暂时不看。

3. Keep practicing：要动手试，包括模型、产品、库、工具，都要上手试试，别 Quick start 都没通就无责任转发。

4. Keep creating：保持输出，包括短分享、代码片段、长文章以及开源项目。输出才是真正的掌握。

### 53

2024-12-14



小互
@imxiaohu
兄弟们 这个牛P

Runway Act one 开源平替出现

HelloMeme：可以通过一张静态照片+一个视频作为输入，生成一个表情和动作都跟原视频一致视频

它能让参考图片上的人“动起来”，并且动作和表情完全同步于你提供的视频。

也就是实现视频角色的表情动作转移...

和Runway Act one的功能一样

生成的动态视频不仅保留了原始图片的细节，还能精准地模仿驱动视频的表情和动作。

### 54

2024-12-17

Bear Liu
@bearbig
草台班子，小作坊，到大厂，聊聊我的职业故事。

我的第一份工作是平面设计，加入了一家三线城市的民企，主要负责店面包装和宣传物料的制作。干了几年，升到了经理的位置，也开始带团队。

不过，因为年纪轻，感觉hold不住办公室政治。民企老板的风格又很……那个。最终选择离职。

离职后，我尝试自己创业，接了各种项目，什么婚庆策划、包装设计都做。但方向不明确，摸索了好一阵子。

直到后来接到一个网站制作的项目，才算稍微找到了点方向：与数字时代接轨。

2012年，我们开始涉足苹果App开发。当时算是赶上了行业的大趋势，业务增长还行。

不过，我和合伙人都不是那种喜欢社交或者抢资源的人，所以更多是接外包的活，生活上也图个安稳。

这样的模式维持个小日子还算不错。
  
那几年，我第一次去美国参加Macworld，之后，因为家人的打工度假签证，又去了新西兰和澳洲旅行了两次，感受了不同的文化和生活方式。

这些经历让我萌生了移民的念头。2015年，我开始研究移民的可能性。

一开始找中介，但不太靠谱。后来发现新西兰的银厥签证适合我，就开始备考雅思。

因为平时看美剧和电影比较多，英语底子没怎么丢，雅思G 类6.5分也顺利通过了。

2016年，我正式来到新西兰，第一份工作是在一家本土的电商公司。当时完全是从零开始，面对洋人同事的全英语环境，刚进去的时候一脸懵B。

磨合了好几个月，才逐渐适应。

后来公司业务重组，我决定转型做用户体验设计。5个月的求职，最终进了Les Mills（莱美，算是健身行业的中厂），正式转型为用户体验设计。

疫情期间，公司裁员，我又去了新西兰的"大厂"沃达丰Vodafone，类似国内的中国移动。

是个不错的平台，但节奏比较慢，特别注重Stakeholder Management，做事讲究"圆滑"。而且，不是真正意义上的软件或技术公司。

然后我跳槽到了Xero，主板上市的SaaS公司，全球几千员工，算是和Atlassin、Canva这些公司一个梯队的大厂了。

第一两年学到不少，后面也躲过了疫情之后席卷整个科技圈的大裁员。

现在第三年，开始觉得成长的空间有限，总觉得少了点冲劲和挑战。

这一年开始把精力投向个人项目，寻找更多发挥创意的机会。

年底回顾时开始意识到，自己的理想状态还是在主业中实现更多创造力，而不是完全依赖副业来释放热情。

如果要给年轻人一点建议，我还是觉得，毕业后最好能进大厂试试。

大厂的筛选机制会过滤掉不靠谱的人，和高标准的同事合作，会对你做事的标准和品味有很大提升。

而且，大厂的资源和框架能让你快速上手，更系统地理解工作的方法论。

不过，随着时代发展，很多大厂的框架也在慢慢失灵（草台班子理论是真的）。许多破坏性的创新都是小团队带来的，这让选择职业路径时更需要结合个人性格和目标。

如果有师傅或者导师指点，或者能有一些可以深入交流的同事，那些资源往往会成为你后续职业发展的保护伞。

我当年刚毕业时，人在八线城市，没啥眼界，也没机会进大厂，信息也比较闭塞，和现在不一样。

回头看，我觉得自己挺幸运的。当然，努力是必须的，但抓住当时市场需求的契机也很重要。

在转型用户体验设计的那段时间，我投了几十份简历，面试了十几次，才拿到第一个机会。但如果没有当时市场的整体上升，这种努力也不太可能有结果。

有了第一份像样的国外工作，算是通过了"新手村"。之后的路虽然还有挑战，但没那么难了。

语言是最大的一个障碍。但一旦突破，其实它也是一个开关，后面你的地图就会被点亮了。

语言下面其实是心理和文化，这点我也还在摸索。以后再深入聊一聊。






### 55

2024-12-17


宝玉
@dotey
推荐电子书：《Shape Up：Stop Running in Circles and Ship Work that Matters》

这是由 Ryan Singer 编写的一本电子书，讲述了 Basecamp（著名的项目管理与协作工具团队）在产品开发与团队协作上的独特方法论和实践经验，主要面向中小型软件开发团队，帮助他们高效地完成有价值的工作，而不是陷入无尽的拖延和混乱。

Shape Up 提出了一个独特的产品开发框架，专注于如何有效规划、执行和交付项目，核心分为三个阶段：

1. Shaping（塑造阶段）
在这个阶段，领导者和产品负责人会提前设定项目的 边界、问题 和 解决方案的大致轮廓。目标是将项目定义得足够清晰，同时又保持一定的灵活性，让团队有空间去实现目标。

2. Betting（下注阶段）
公司会基于业务目标和团队资源来“下注”——决定哪些项目值得团队投入时间和精力。

3. 项目会被分配一个 固定的时间周期（例如 6 周）。
如果在规定时间内完成，则项目交付；如果未完成，则项目被丢弃或重新评估。
Building（构建阶段）
这一阶段由工程师和设计师执行项目。他们专注于实际的交付，团队按照之前的“塑造”进行构建，但在实际执行中有自主决策的自由。

这种方法的核心理念有些类似于 Scrum 里的时间盒子 Time box，通过设定明确的时间边界，确保项目不会无限拖延。在时间有限的情况下，团队会优先解决最重要的部分，逐步收敛项目范围。

开发团队在预先决定的六周周期内集中精力实现成型阶段定义好的目标与界限，不接受中途变更或新增需求。完成周期后，会有约两周的“冷却期”，团队在此期间可进行回顾、维护、学习和为下一个周期做准备。这种“6周冲刺 + 2周缓冲”的节奏帮助团队持续产出有质量的功能和产品迭代。

这本书发布于 2019 年，和主流的敏捷开发还是有些不太一样，但确实抓住了精髓：谋定后动，想清楚做什么再做项目，将发布时间定死；倒逼着选择最重要的事去做；6 周的迭代中不接受需求的变更，这也让需求范围也在某种程度上不会扩大，从而能做到定时发布（或失败）。

这种开发模式可能适合Basecamp在当时的阶段，但未必适合很多团队，对于很多产品来说，6+2周的开发周期是有点长了，6周无法发布就算失败对于很多团队来说也是难以接受的，最重要的是这种开发模式要给予团队足够的空间，由团队自己决定如何实现目标，而不是对团队进行微管理。

不管怎么说，这本书还是值得一看。
英文版阅读地址：https://basecamp.com/shapeup
中文翻译地址：https://p-c8wi.tower.im/p/54rp

[Shape Up: Stop Running in Circles and Ship Work that Matters](https://basecamp.com/shapeup)

### 56

2024-12-17

小互
@imxiaohu
ChatGPT Tasks（自动化任务）更多功能曝光

通过设置可以创建很多自动化的任务。

GPT会定时自动帮你执行并通知你

这意味GPT可以主动给你发消息了？？如果是这样将是一大进步，机器人会主动联系你。

结合今天的打电话给GPT这个，以后GPT是不是可以给你打电话通知你的任务完成了？？？😅

应该是配合今晚要发布的Agent 自动代理...



### 57

2024-12-17


小互
@imxiaohu
ElevenLabs 全新语音生成模型：Flash

是目前全球最快的生成模型 

可以在75ms内生成高质量的媲美人类的语音

Flash v2 仅支持英语，而升级版 Flash v2.5 支持 32 种语言。

尽管其情感深度稍逊于内部的 Turbo 系列模型，但与竞争对手相比，Flash 的语音质量仍然领先。

该模型的使用成本为每 2 个字符消耗 1 点积分，用户可根据自身需求选择最合适的模型版本

支持通过 API 或平台直接使用




### 58

2024-12-17


歸藏(guizang.ai)
@op7418
项目主要特点：

速度：Genesis提供了前所未有的模拟速度 -- 使用单个RTX 4090显卡模拟Frana机械臂时可达到超过4300万帧/秒（比实时快430,000倍）。

跨平台：Genesis可在不同系统（Linux、MacOS、Windows）原生运行，并支持不同计算后端（CPU、Nvidia GPU、AMD GPU、Apple Metal）。

多物理求解器统一：Genesis开发了一个统一的模拟框架，集成了多种物理求解器：刚体、MPM、SPH、FEM、PBD、稳定流体。

支持广泛的材料模型：Genesis支持模拟（及耦合）刚体和铰接体、各类液体、气体现象、可变形物体、薄壳物体和颗粒材料。

支持多种类型机器人：支持机械臂、足式机器人、无人机、软体机器人等，并广泛支持加载不同文件类型：MJCF (.xml)、URDF、.obj、.glb、.ply、.stl等。

逼真的高性能光线追踪：Genesis支持原生光线追踪渲染。

可微分性：Genesis设计时充分考虑了可微分模拟的兼容性。
基于物理的触觉传感器：Genesis包含了基于物理的可微分触觉传感器模拟模块。

用户友好性：Genesis的设计理念是尽可能简化模拟的使用。



### 59

2024-12-17


歸藏(guizang.ai)
@op7418
卧槽，这个真牛批了，无限画布AI计算机

tldraw computer，一台AI计算机，没有代码，只有自然语言和流程组件。

支持流程分支、切换和循环，而且项目还能变成模版跟其他人共享。

Andrej Karpathy 也给了很高评价

试了一下没找到地方交钱，还是免费的？




### 60

2024-12-17

小互
@imxiaohu
🚀 Genesis Project 正式发布！

这是一款生成式物理引擎 ，支持生成4D动态真实的物理世界 ！

允许在虚拟领域中以最高的真实感模拟整个物理世界。

✨ 核心亮点 ：

纯Python开发，速度比现有GPU加速引擎（如Isaac Gym、MJX）快10-80倍，模拟速度比实时快约43万倍。

在单张RTX4090上仅需26秒 完成可转移到真实世界的机器人运动策略训练！

经过24个月、由20多个研究实验室的大规模合作研发！

🌍 目标 ：

构建一个统一的生成式物理世界模拟框架，自动生成各种环境、机器人任务、奖励函数、交互式3D场景等，助力机器人与物理AI领域的全面发展。


小互
@imxiaohu
完全开源 ，代码地址：https://github.com/Genesis-Embodied-AI/Genesis

项目地址: http://genesis-embodied-ai.github.io


### 61

2024-12-17


宝玉
@dotey
在让 Cursor 写代码时，通常我会给出充足的上下文代码参考，给出清晰的指令，一次只是完成一个相关的任务，这样生成的代码一般相对来说就比较可控，质量也不错。
引用
宝玉
@dotey
·
2024年12月19日
我日常用 Cursor 写代码的场景之一：“请参考代码 @ XXX1 @ XXXn 做 YYY 事。”
简单来说就是让 AI 照葫芦画瓢，重要的是给出充足的上下文，让 AI 可以学习和模仿。剩下的就是 Review + Accept，很简单高效。
特别要注意的是第一个“葫芦”要打磨好，这样后续的“瓢”才不会画歪。


### 62

2024-12-17



小互
@imxiaohu
深度评测| 豆包全新视觉理解模型 

能跨模态和你一起协作

字节跳动正式发布豆包视觉理解模型，该模型可以识别和理解图像中的丰富信息，包括图像知识、动作情绪、图像中物体的位置状态、文化背景和OCR文字信息。

例如能够识别理解图像中的数学公式或图表信息并提供相关的推理和解答。

随着全新视觉理解模型的发布，目前豆包AI已经具备了自然语言交互、实时语音交互、图像生成和编辑、音乐生成、视频生成、视觉理解等多种能力。

成为国内领先的能与OpenAI能力一致的，具有全知全能全模态能力的模型家族！


### 63

2024-12-17

宝玉
@dotey
阿里巴巴通义实验室开发的新一代语音合成系统CosyVoice 2，可以将文字转换成自然、流畅的语音，速度快，音质好。

它是支持流式输入输出的，延迟只有 150 毫秒，比如可以配合 LLM 一边生成文本一边输入音频，从官网上的演示来看，模仿的效果很好，参考的声音是中文的话输出英文，音色保持的不错，也比较自然。

官网：https://funaudiollm.github.io/cosyvoice2/



### 64

2024-12-17

宝玉
@dotey
简单说一下 GitHub Copilot 和 Cursor 的差别，以及为什么我觉得 Cursor 要更好。

最开始 GitHub Copilot 是 VSCode 插件形式，只能在当前光标位置自动完成，当然现在越来越多的功能融合到 VSCode 内核中了，比如 CMD + I 就可以弹出对话框，比如有专门的聊天侧边栏。VSCode 也在提供更多的原生 AI 编辑器的支持。

Cursor 最开始不是基于 VSCode，但后来直接基于 VSCode 魔改了，是基于 VSCode 集成了 AI 功能的编辑器。VSCode 用户几乎可以无缝切换到 Cursor，Cursor 的成功一大半得归功于 VSCode 的开源。

功能上有几点主要差别（GitHub Copilot 最近更新很频繁，我写的一些内容可能已经或者将会过时）

第一个常用的是自动补全、修改功能。

这个功能是你在正在修改代码、写代码的时候，编辑器自动给出智能提示，猜测你要做什么修改，如果猜对了你只要按 Tab 键，就可以自动修改。

GitHub Copilot会在你的光标后用灰色显示，但是一次只能提示一个位置；Cursor 可以提示多个位置同时对多个位置进行修改重构。并且 Cursor 会更准确，经常你一点光标它就能给出靠谱的智能提示。如果你用惯了 Cursor 再去用 GitHub Copilot 会觉得它很“笨”，经常猜不到你要什么，而且要一个地方一个地方修改。

第二个是通过提示词添加、重构、删除新功能

很多人在用 AI 编辑器只用了自动补全修改的功能，而通过提示词让 AI 帮你生成代码的功能用的比较少或者不会用，这就相当于让 AI 编辑器的能力只发挥了一小部分，真正体现智能的地方就是通过提示词对项目全局修改。

GitHub Copilot 和 Cursor 都可以通过两种方式唤出写提示词的窗口：CMD + I 或者侧边栏的 AI Chat。GitHub Copilot 的 CMD + I 这个快捷键功能没有太多人知道，因为 VSCode 上没有明显提示，很多人不知道，Cursor 在选中代码后有提示相对好一点。

但是 Cursor 又有两个功能键 CMD + K 和 CMD + I，有一些细微差别，建议默认选择 CMD + I 这个，也叫 Composer。

这个提示词撰写窗口对于 GitHub Copilot 和 Cursor 来说，有个根本性的差别，包括 Windsurf 也没有的，就是上下文内容的手动选择。对于 GitHub Copilot 来说，它是根据你打开的 Tab 标签来“猜测”你的上下文，但这很难猜准，而 Cursor 可以让你手动选择你想要的上下文，在Composer中通过+号或者 @ 去附加代码。对于专业程序员来说，手动控制上下文这非常非常重要！因为在修改代码时，肯定少不了要引用现有的代码，参考其API，参考其代码结构等等，虽然你也可以手动复制进去，但是如果你可以方便的选择那是最好的。

回归到提示词工程，要让提示词效果好核心有两点：
1. 指令清晰
2. 上下文充分

如果你自己作为专业程序员不能精确控制上下文，寄希望于 AI 帮你选择上下文，现阶段还是不靠谱的，这点 Cursor 是做的非常好的。如果你还没有用过 Cursor 的 Composer 或者 Composer 的手动选择代码作为上下文的功能，一旦你习惯了，你再也受不了 GitHub Copilot 和 WIndsurf 这些帮你“猜”上下文代码的 AI 编辑器。

第三个是 Agent 或者说智能体的功能

GitHub Copilot 的 Chat，如果你用过就知道，它只能给出修改建议，生成参考代码，无法帮你直接应用修改，你需要手动去复制粘贴创建代码。

Cursor 的 Chat，默认也不会，但是你可以在代码上点击“Apply”链接应用代码到相应的文件。

GitHub Copilot 的 Composer，只能修改当前文件代码，不能应用到其他文件位置。

Cursor 的 Composer，它可以在项目全局添加、删除和修改代码，你只要review一下修改就可以应用这些修改，不满意也可以拒绝或者局部拒绝。

Cursor 的 Composer，现在有两个模式：Normal 和 Agent，Normal 就是简单的根据指令和上下文生成代码、应用修改。Agent 则可以像一个机器人一样，根据你的指令去分析代码，去安装需要添加的包，当然需要你自己确认。这个 Agent 功能在你创建新项目达环境的时候特别实用，一步步帮你把包都安装好了，直接就可以运行。

Agent 功能 Windsurf 做的非常好，Cursor 可能是借鉴的 Windsurf，GitHub Copilot 据说也要推出了。

综合下来，我觉得还是 Cursor 最好用，但最重要的是，你自己得试试用一用，适合自己的能最大化提升效率的才是最好的。



### 65

2024-12-20


小互
@imxiaohu
NVIDIA 发布 Jetson Orin Nano 超级开发者套件

售价只有249美金 

相比上一代的499美元大幅下降

性能比上一代提升1.7倍，每秒70万亿次运算

具有67 INT8 TOPS的推理性能，内存带宽提高了50%，达到102GB/s

Jetson Orin Nano Super 支持生成式AI应用，可用于小型的AI计算机，机器人或者工作站。

Jetson Orin Nano搭载了 NVIDIA Ampere架构的GPU 和 6核Arm CPU，能够提供更强大的计算支持，尤其适用于并行计算和图形处理任务。

Jetson Orin Nano Super 完全兼容 NVIDIA CUDA、cuDNN 和 TensorRT 等软件库，使得开发者可以高效利用 GPU 加速进行深度学习和推理任务。


### 66

2024-12-20

小互
@imxiaohu
OpenAI 明星研究员Alec Radford辞职

他是 GPT-1、GPT-2、CLIP 和 Whisper 论文的第一作者

他的学术论文总计被引用超过 18 万次

Radfordadford因在生成式预训练模型（GPT）方面的开创性工作而获得传奇声誉。

他还参与了后续GPT版本的开发、语音识别模型Whisper以及图像生成模型DALL-E的研发。

Radford于2016年加入OpenAI，成为公司发展历史中资历最深的员工之一。

Alec Radford辞职于周四向同事宣布将离开公司，表示将独立开展研究。

据一位知情人士透露，Radford表示计划继续与OpenAI及其他AI开发者合作。



### 67

2024-12-20


Leonie
@helloiamleonie
Got myself a little early Christmas present.

Although this book is from 2017, I heard so many good things about it this year.

Can't wait to dig into this over the holidays.

I will be back in the new year with some learning from the book.

And with that being said, I hope you have some nice and relaxing holidays yourself!

See you in the new year!

《Designing Data-Intensive Applications》


2019013Designing-Data-Intensive-Applications

### 68

2024-12-20



宝玉
@dotey
当我用 Cursor 和 ChatGPT o1 辅助写程序的时候，把它当副驾驶（Copilot），自己设计好分解好，效率是很高的，当我想偷懒完全交给 AI，如果要写的东西是简单的，也很好，如果是复杂的，那么我其实效率是大幅降低的，因为我要花时间去搞懂 AI 是在做什么，并设法让它正常工作，如果它思路不正确，最终可能还是要自己重写。

使用 AI 辅助编程，上限在于使用者的编程水平。还是不能偷懒当甩手掌柜，也不能不学习积累编程知识，否则很难在复杂的任务上驾驭好 AI。


### 69

2024-12-20
歸藏(guizang.ai)
@op7418
Anthropic 几个核心创始人罕见的一起录了一个播客

详细介绍了他们如何认识然后产生共识最后迫不得已创建公司的事情

整理了一下核心内容笔记：

- 创始历程与动机
- 公司文化特点
- 几个联创展望未来
- 有趣的AI历史细节

里面很多以前没说过的事情，强烈建议看看




### 70

2024-12-20


小互
@imxiaohu
微软开源了一款金融市场预测模型：MarS 

它基于订单级别的真实历史金融市场数据训练，能够实现逼真的金融市场模拟

在市场趋势预测中，MarS的模拟显著优于传统的直接预测模型，体现了其对市场动态的深刻理解。

用户可以通过注入特定的订单或描述目标场景，控制模拟过程，以分析特定条件下的市场行为。

还提供一个交互式环境，用户可以在其中测试不同的交易策略，观察其市场影响。


### 71

2024-12-20


小互
@imxiaohu
Apptronik 与Google DeepMind 达成合作

其Apollo 机器人将植入Google的Gemini 2.0模型

Apollo身高 5 英尺 8 英寸，体重 160 磅，能够适应多种环境和任务。

机器人采用模块化设计，方便根据不同应用场景进行硬件升级或功能调整。

设计用于执行重复性、高风险或复杂任务，例如搬运、装配、检测等。

能够通过智能感知和决策系统应对动态环境。

Apptronik计划通过与 Google DeepMind 合作，结合先进的人工智能算法，赋予 Apollo 更强的学习和适应能力。

- 感知与导航：具备环境感知能力（摄像头、传感器），能准确识别障碍物、目标物体并进行交互。

- 云连接：支持与云端连接，实现远程监控和任务优化。

Apptronik 起源于德克萨斯大学奥斯汀分校的人本机器人实验室，现有 150 名员工。


### 72

2024-12-20


小互
@imxiaohu
OpenAI O3 模型详解 🧵

OpenAI 将 O3 和 O3 Mini 定位为 推理能力的里程碑，标志着 AI 在复杂任务处理中的巨大进步。

不仅是生成文本，还能进行复杂推理，包括数学问题求解、代码生成、逻辑推断和实时适应新任务。

推动 AI 从单一任务扩展到多任务处理。

模型的代号为 α，也就是之前传说的猎户座

O3 模型：

• 定位为 OpenAI 的旗舰推理模型。
• 在多个技术基准测试中表现优异，超过O1 模型的大多数性能指标。
• 更高的计算能力支持更复杂的任务处理。

O3 Mini 模型

• 定位：O3 的轻量化版本，专注于 高性价比 和 任务高效完成。

• 可调推理时间：支持低、中、高三档推理时间设置，用户可根据任务复杂度选择适配的模式。

• 更快的响应时间：低推理时间模式下，响应速度接近即时，特别适合低延迟应用场景。


### 73

2024-12-20

宝玉
@dotey
从截图还原网页，Claude sonnet 3.5 最强，o1 都比不上。
图一：Claude
图二：GPT-4o
图三：o1
图四：Gemini Flash 2.0




### 74

2024-12-23


宝玉
@dotey
曾经很多人认为“提示工程师”会是未来一个重要的职业，但现在看来，提示工程会是一个重要技能，很多现有工种都需要学会这种技能，但是不太需要成为一个独立的工种。这就像英语，是一种基本语言能力，我们在各个行业都有大量应用，都需要掌握英语，但是只有少数人需要以此为专业。



### 75

2024-12-23

宝玉
@dotey
OpenAI 的 GPT-5 据称未能达到预期

OpenAI 为开发其下一代重要模型 GPT-5 的工作进展滞后，且目前的成果尚不足以证明巨额成本的合理性。据报道，OpenAI 已完成至少两次大规模训练运行，这些运行旨在通过对模型进行海量数据训练来实现改进。然而，首次训练运行的进展比预期缓慢，这暗示更大规模的训练运行将会耗时且昂贵。据称，尽管 GPT-5 的性能可能优于其前代模型，但其进展尚未达到足以证明维持模型运行成本的水平。



### 76

2024-12-23

宝玉
@dotey
我的看法恰恰相反，如果 OpenAI 发布的是GPT 4.5 或者 GPT-5，大概率要翻车了，现在算不上太好，但是也符合预期。OpenAI 最大的价值在于在前面开路指明方向，ChatGPT 之后大家知道LLM这条路是可行的，于是能加大投入一起搞；Sora 也让大家知道文本生成视频是可以靠谱的，于是可灵这样的也做起来了；o1 让大家看到推理模型的前景，也可以往这个方向投入了。

o3 则将“智能”推到了一个新高度，给未来提供很多想象空间和可能，也指明了方向，下一步就是降低成本和提升速度，这不会太远，最怕的是已经到了智能天花板，哪不仅OpenAI要完，这波AI热潮都要完！

有了 o3，用它训练出 GPT 5 不会远了



### 77

2024-12-23


宝玉
@dotey
2025 会被 AI“平替”的行业？程序员真的会被取代吗？

在 2024 年底，OpenAI 发布了全新的推理模型 o3，表现相当惊艳：它在世界级编程比赛中能拿到第 175 名，也就是可以打败 99.9% 的参赛者。于是很多人又开始讨论：程序员是不是要凉了？2025 年，真的会有大批程序员被 AI 替代吗？除了软件行业，AI 会不会也让其他行业进入“平替”危机？

接下来，我想结合自己对软件行业的观察，谈谈 AI 发展的最新动态，以及它对初级程序员、在校学生、中高级工程师和管理者各自带来的影响，希望给你一些启发和思考。

一、AI 与软件行业：到底谁会被取代？

软件行业和 AI 的结合是最紧密的。从近几年 AI 在编程能力上的突飞猛进来看，软件领域确实“首当其冲”地感受到冲击。  
- AI 能力提升：模型的推理和生成代码能力越来越强，像 Claude Sonnet 3.5、OpenAI o1 等都已经能大幅帮助开发者减轻负担。  
- 自动化程度：一些初级、重复性的开发工作更容易被 AI 覆盖，甚至出现了类似 Devin 这样的“自动修 Bug”工具。  

那么问题来了：“程序员会不会彻底失业？”或者稍微谨慎一点：“初级程序员会被取代吗？” 先别急着得出结论，让我们一步步看下去。

二、AI 助力编程：能提高多少效率？

AI 带来的效率提升

- 借助 AI 代码编辑器（Cursor、Windsurf、GitHub Copilot 等），在很多场景可以显著加快编程速度：  
  - 自动补全代码  
  - 写单元测试  
  - 从设计稿直接生成前端 UI  
  - 搭建项目脚手架  
- 从我的实践来看，有些环节效率可提升 50% 以上，整体则能稳稳提高 20% 左右。

为何企业还没大规模使用？

尽管效率提升诱人，但要想真正享受 AI 编程红利，需要满足几项条件：  
1. 使用最强的模型：例如 Claude Sonnet 3.5 或 OpenAI o1。如果模型本身的编程能力不够，就难有质的帮助。  
2. 工具配套完善：要搭配先进的 AI 代码编辑器，而不是仅凭网页版的简单调用。  
3. 代码数据安全合规：很多企业担心源代码上传到云端会带来安全隐患，需要等待自部署或开源模型能力成熟后再应用。  
4. 团队熟练使用：要学会写提示词、掌握如何拆分复杂任务，让 AI 能更好地产出正确代码。  

另外，还有一个容易被忽略的人性层面：  
- 公司当然希望通过 AI 提升效率，但员工不一定愿意学，毕竟对个人而言，“省时”并不等于“涨工资”；甚至还会担心“学会 AI，岂不是我自己给自己挖坑？”。  
- 与之相反，一些独立开发者、自由职业者更乐于拥抱 AI，因为效率提升带来的收益立刻能反映到个人收入上。  

不过，这种保守态度不会持续太久。到 2025 年，AI 辅助编程大概率会成为常态，就像我们如今用高级 IDE 而不是用记事本写代码一样。在“内卷”的压力下，团队里不用 AI 反而会掉队。

三、AI 会让程序员失业吗？

编程只是软件开发的一部分

AI 写代码并不等于程序员就被取代。软件开发是一个系统工程：  
- 需求沟通：产品经理需要和客户或市场沟通，确定需求；  
- 架构设计：程序员要抽象需求、搭建框架；  
- 测试与部署：写完代码还要经过测试、上线和维护；  

眼下，AI 在编码阶段确实可以替代一部分人力，但其他流程仍需要人工主导。就算有像 Devin 这样的工具，能自动执行简单任务或修小 Bug，但在面对复杂模块时，AI 也常常陷入“卡死状态”，无法完成所有工作。

影响初级岗位

AI 在编程能力上的进一步提升，确实会让“初级程序员”面临更大竞争，因为很多简单任务可以让非专业开发者借助 AI 来完成，或者由高级工程师通过 AI 工具直接“前置”搞定。  
- 一旦企业意识到可以省掉部分简单的编程人力，初级岗位会被“削减”或合并，导致毕业生或技能不够扎实的人员就业更困难。  
- 不过这并不代表“程序员”这个职业消失。工程师依然要负责架构、需求抽象、测试和维护等更高层次的工作。  

四、AI 正在重塑软件开发范式

我在文章 《AI 辅助编程给软件工程带来的需求开发范式变化》 中提到：AI 对传统软件开发模式影响深远，主要体现在：

1. 简单需求不再依赖完整研发流程  
   - 不少原型级别的小功能，通过 AI 就可以一次性搞定，甚至让产品经理直接生成初步版本。  

2. 专业程序员“和 AI 结对”  
   - 程序员不再从头手写全部代码，而是更像“指挥员”，负责需求拆分、提示词编写、审核并调试 AI 生成的代码。  
   - 简单、重复的部分丢给 AI，自己腾出精力思考更高级的设计问题。  

3. 团队规模可能缩小，效率却不降  
   - 人数减少，分工精简；但是“人 + AI”的效率不一定比原来更低。  
   - 由此带来的连锁反应是：管理层级变少，对纯管理岗位需求减少。  

4. 初级岗位大量减少  
   - 一些原本需要由初级程序员完成的简单需求，正被“非专业编程者 + AI” 或“更资深程序员 + AI” 抢走。  
   - 对新人来说，如果没有核心竞争力，可能很难找到合适机会。

五、计算机专业还值得学吗？

很多人担心：“既然 AI 能把初级程序员的活儿都干了，那学计算机还有前途吗？” 我认为：  
- 岗位少了，但需求并没有减少：软件开发整体需求还是在持续增长，只是对初级能力的依赖度降低了。  
- 竞争会更激烈：低水平刷题可能已经不够，需要真正掌握软件工程知识，也要学会用好 AI。  
- 学习速度更快：  
  - 以前遇到问题需要自己上论坛“求大佬解答”；现在大部分技术难题可以直接问 AI。  
  - AI 在代码生成时，也会呈现出“高质量范例”，对初学者来说，这比“屎山代码”可好太多。  
  - 有了随时可问的“AI 导师”，从初级跨越到中级的时间可能只需要 2~3 年，比过去的 3~5 年要快。  

所以如果你是计算机专业的学生，反倒是“最坏的时代，也是最好的时代”：竞争升级，但你的学习效率也在加倍提升。只要充分利用 AI，提早动手做项目、实习，提前累积实战经验，依然能在就业市场上具备很强优势。

六、给不同群体的建议

对初级程序员/在校生

- 尽快拥抱 AI 工具，学会写 Prompt，借助 AI 辅助开发。  
- 尽可能多参与真实项目（可由 AI 帮忙起步），提早获取工作经验。  
- 刷题依旧重要，但更重要的是掌握软件工程全流程，能够独立解决问题。

对中高级程序员

- 角色转型： 从“纯手动写代码”转向“设计 + 指挥 + 审核”AI 产物。  
- 深耕架构和需求分析： 让 AI 处理具体逻辑，自己负责更高层次决策。  
- 保持学习热情： AI 迭代速度很快，经常尝试新工具和新模型，别被新一波浪潮冲走。

对管理者/项目负责人

- 正视 AI 潜力与挑战：积极推动企业内部的 AI 转型，调整流程和考核方式。  
- 注重数据安全和合规：想要大规模使用 AI，就需要考虑隐私和知识产权问题。  
- 重新评估团队结构：在团队规模和人才培养上做出更灵活的布局，别盲目追求“人海战术”。

七、AI 不会取代程序员，但会重塑软件开发

每次 AI 模型能力突破，总有人会喊“程序员要失业了，人人都能写代码”。但现实是：软件工程从需求到运维的复杂链路，让 AI 还没法一条龙包办。尽管未来或许会出现 AGI（通用人工智能），真正实现“全自动开发”，但起码眼下还差得远。

然而，AI 已经在重塑软件开发：  
- 2024 年，我们看到了 AI 编程显著提升效率、完成简单原型的可能性。  
- 到 2025 年，越来越多企业和团队会把 AI 编程融入正式流程。初级需求由产品经理或资深工程师与 AI 一起完成，更复杂的任务依然由专业工程师主导。  
- 初级程序员需要快速晋级，中高级程序员要善用 AI 发挥最大价值，管理者需要思考如何拥抱这一趋势。

如果你是计算机专业的学生，记得别因为“AI 抢饭碗”而焦虑，而要善用 AI 工具加速成长；如果你已在岗位上多年，也别轻言“AI 编码不过如此”，要紧跟技术步伐，把自身定位从“搬砖”转向“策划与管理”。只有这样，才能在这股浪潮里生存乃至领跑。

结语

2025 年，AI 会进一步改变软件行业，绝不会一夜之间让程序员整体“下岗”，但眼前会影响初级程序员的就业是正在或者即将发生的事情。与其害怕被“平替”，不如两手一起抓：既掌握如何使用 AI 辅助开发，又借用 AI 快速学习，提升自身竞争力。


### 78

2024-12-23

小互
@imxiaohu
Hume AI 推出全能文本与语音引擎 OCTAVE 

OCTAVE能够从简单的文本描述或5秒语音录音中生成或者克隆逼真的语音和人格特质。

包括性别、年龄、口音、情绪语调及职业特定说话风格等。

能在毫秒级别完成语音生成，实现真正的实时对话，还允许实时动态调整生成内容。

OCTAVE结合了EVI 2模型以及 OpenAI 的语音引擎、Elevenlab 的 TTS 语音设计和 Google Deepmind 的 NotebookLM 等系统的能力。

支持多个虚拟角色的语音生成，角色之间的语音风格、情绪和口音可以完全不同，可以生成完整的播客内容。




### 79

2024-12-23

宝玉
@dotey
“李飞飞：我认为自艾伦·图灵以来，人类还没有完全理解智能背后的基本计算原理。如今我们使用AI这个词，我们使用AGI这个词，但在一天结束时，我仍然梦想着一组简单的方程式或简单的原理，它们可以定义智能的过程，无论是动物智能还是机器智能。这类似于物理学。例如，很多人已经引用了飞行的类比。我们是在模仿鸟飞行还是在制造飞机？很多人问到AI与大脑之间的关系。对我来说，无论我们是建造一只鸟还是复制一只鸟或者建造一架飞机，在一天结束时，空气动力学和物理学就是支配飞行过程的规律，我相信总有一天我们会发现这一点。”
引用
宝玉
@dotey
·
2023年5月21日
今天给大家翻译的是最近吴恩达采访李飞飞的一期视频“Andrew Ng and Fei-Fei Li Discuss Human-Centered Artificial Intelligence - Stanford



### 80

2024-12-25

宝玉
@dotey
一个 ChatGPT 的知识：ChatGPT 是不会抓取 URL 的网页的。OpenAI 以前支持直接抓取网页，后来被人告了还是怎么，就自我阉割了，所以你问它，它不会去抓网页，只用自己的知识库或者会去搜索必应，所以你就一个 URL 去问问题，它没法给你靠谱的回复，最多根据 URL 去必应搜，必应也只会返回一些不太靠谱的结果，尤其是中文结果更糟糕（参考图1）

靠谱的办法是：是手动去复制粘贴一下网页内容，最好先粘贴到markdown编辑器，把 HTML 转成 markdown，然后把 markdown 提交过去。如果不是Markdown，粘贴纯文本也没关系。



### 81

2024-12-25

小互
@imxiaohu
重磅💥

Meta AI提出了一种新的语言模型架构“Large Concept Model (LCM)  

让模型更像人类思考，先从大框架入手，再填充细节。

与传统语言模型（比如GPT）逐字生成不同

LCM基于“概念”（concept）进行语言处理，把每个句子看作一个“概念”，在句子级别进行推理和生成，而不是在token级别操作。

在LCM中，一个概念通常对应一个完整的句子，它是语言和模态无关的高级语义表示。

让模型从更高的抽象层次进行推理和生成，超越现有模型局限，处理更复杂的任务。

- 思考方式像人类，从“概念”出发，逻辑更清晰。

- 能处理多语言、多模态任务，直接支持文本、语音甚至手语。支持200种语言的文本输入。76种语言的语音输入。

- 适合长文本处理，速度快，生成内容更连贯。

- 具备强大的零样本泛化能力，不用额外训练也能完成新任务。



### 82

2024-12-25


小互
@imxiaohu
Fireworks AI推出了一种叫“Document Inlining”功能

这是一种复合AI系统，能够将非结构化的文档（如PDF、截图、图像等）转化为LLM（大语言模型）可理解的结构化文本，变成能直接用于聊天机器人或者AI模型的文字内容。

它能自动识别和解析文档中的多种内容，包括文本、表格、图表以及嵌套布局。

简单易用，无需复杂的设置

兼容OpenAI API ，在 Fireworks 中，启用Document Inlining功能仅需在现有的 API 中添加一行代码即可实现。

1. 高质量输出

•  Document Inlining 提供的文本质量能够匹配甚至超越传统的文本型 LLMs 输出，尤其是在推理和生成任务中表现优异。

•  相比 VLMs，LLMs 使用经转换的文本后，生成更准确、更专业的结果。

2. 多种文档格式支持

•  成功测试了包括 PDF、图片在内的多种文档格式。

•  例如：从 PDF 文档（如简历）中提取候选人的学术信息（如 GPA），结果显示解析清晰、准确。

3. 复杂文档解析能力

•  通过测试，Document Inlining 能够解析含有表格、图表和多段文字的复杂文档，并将其成功转换为 LLMs 可理解的文本。



### 83

2024-12-25



歸藏(guizang.ai)
@op7418
这个好玩，AI 3D 动画场景生成器

输入提示词就可以用 Three JS 生成对应的 3D 场景和动画

作者还用他做了一个赛森林中漫步写日记的小工具



### 84

2024-12-25


歸藏(guizang.ai)
@op7418
AI 搜索公司 Exa CEO 的年底长文

对 AGI 到来的前的一段时间社会变化做了一些预测

首先受到严重影响的是数学家，然后是开发人员

每个开发人员都会变成技术主管，专门的前端开发可能会在三年内消失，之后是理论物理学。

推荐看看写的很好，完整翻译和总结在下面
引用
Will Bryk
@WilliamBryk
·
2024年12月25日
Thoughts on the eve of AGI

I talked to several friends about o3 this week. Their summarized response is basically "holy crap is this actually happening?"



### 85

2024-12-25


宝玉
@dotey
“有什么、做什么、怎么做” 确实是提示词的精髓👍
有什么：给模型的上下文
做什么：给模型指令
怎么做：【可选】思维链

我现在和 o1 对话时，大多数时候不会加“怎么做”，因为模型有时候比我聪明，方案比我更好，如果我加了“怎么做”反而约束了模型的发挥。当然如果结果不好，可以进一步引导“怎么办”


### 86

2024-12-25


宝玉
@dotey
李想不想造车了？理想AI Talk访谈实录01

AI Talk嘉宾：

理想汽车董事长兼CEO 李想

腾讯新闻科技主笔 张小珺

“消失”在公众视野九个月后，李想回来了！

和从前大家熟知的理想汽车产品“天花板”形象不同，这一次，李想对AI侃侃而谈，他将人工智能视为“未来的全部”，认为大模型的出现让会人类发生根本性的改变，也聊了聊理想汽车智能驾驶和理想同学应用人工智能技术的最新进展。

从车企CEO转变为人工智能企业CEO，他真的懂AI吗？有AI的理想汽车未来会是怎么样？以下为2024理想AI Talk第一集的访谈节选，让我们从这场深度对话，看透李想和他对AI的“野心”。

01AI意味着未来的全部

Q：别人都在做纯电的时候，你开始做增程，现在很多人开始做增程了，你怎么又不想造车了，要做人工智能企业？

A：造车肯定是要造的，电动化是上半场，智能化是下半场，但我认为，这个智能化讲的不是传统的软件智能，而是真正的人工智能，这是造车往下延续的一个必经之路。汽车将从工业时代的交通工具，进化成为人工智能时代的空间机器人。

Q：你第一次对内说要做一个全球领先的人工智能企业这句话的时候，是在去年1月份，是ChatGPT刚好诞生了两个月之后，你这是跟风吗？

A：不是跟风。在2022年9月，我们就已经确定了，要把人工智能作为真正重要的一个方向，并且我们认为这是未来竞争的关键。

在2023年年初发布战略（愿景）的时候，我们做了一个根本性的变化，把人工智能从一个隐藏的战略，变成一个开放的阳谋的战略，因为这样我们才能吸引到足够多的人才。

Q：但是你也可以说，你现在要做的，是一个人工智能技术驱动的电动车企业，或者是一个，拥有人工智能技术的自动驾驶企业，为什么一定要说是一家人工智能企业呢？你觉得他们之间的本质区别是什么？

A：其实做汽车之家，有我人生中最大的一个遗憾。

我们在移动互联网时代，选了一个非常垂直的领域，虽然你做得很好，但是某种程度你可能为了一棵树，错过了一个森林，所以在选择进行第三次创业的时候，我很重要的一点是，我要选择一个森林，我要做那个森林里最大的，无论它需要我经历什么样的困难，我绝对不只做一棵树了。

Q：所以你是觉得把它叫做人工智能企业，这是一个更大的故事，这是一个更大的梦想？

A：我觉得不是更大的故事，如果你看到我们到底在做什么东西，你就会相信了，我们一年超过100亿的研发投入，有接近一半是投在了人工智能方面。

我们是自己做基座模型，端到端和VLM（Vision Language Model 视觉语言模型）的，从最开始的论文到技术的研究，到最后研发和产品的交付，也是全世界非常早做出来的，我们不仅仅在做智能驾驶，我们还有理想同学，智能商业和智能工业，我们真的是这么在做的。

当大模型出现后，我最大的感觉是，人类会发生根本性的改变。

Q：怎么变呢？

A：一定会变得更好。互联网实现了信息的平权，人工智能开始帮助大家实现知识认知和能力的平权。我们通过人工智能将物理世界和数字世界进行融合，让有限的空间实现无限的延伸。

Q：你觉得AI对于理想意味着什么？

A：（在愿景上）意味着未来的全部。

02让用户用上体验一致的人工智能产品

Q：你既然说AI这么重要，在你创业之初就已经决定要做了，那为什么你们开始做智驾，是同行里最晚的？

A：作为一个连续创业者，一个最大的好处是知道整个企业发展的节奏，就是从0到1先解决什么问题，有了收入以后，从1到10要做什么事情，这个其实是我跟新进入行业的创业者，一个根本性的不同。

理想汽车在早期的时候融资能力是最差的，在我们只有很少的钱的情况下，第一个步骤是想着如何把产品做好，我们也获得了非常好的市场的认可，在2020年和2021年，我们分别在美国和香港进行了IPO，有了更多的钱，所以我们从2020年初开始，就开始来做整个技术的平台化，像我们的自动驾驶的平台AD Max 和AD Pro ，包括我们的座舱平台SS，也包含我们整车的域控制器XCU ，再往后，我们还会去做模型和电机的碳化硅，这是我们演进的过程。

它是一个创业公司往上成长、资源有限的情况下，和资源增长以后，你分别去投资什么的一个进展。

Q：乔布斯说，如果硬件是产品的大脑和肌肉，软件就是灵魂，你表达的也是这个意思对吗？

A：当然是了，我最开始创业的时候，投资人经常问我一个特别有意思的话题，就是凭什么你能做出来。因为那时候我们还没有产品出来，我当时讲了一个重要的观点，我说我会比传统的汽车企业，更懂得怎么做互联网和大型软件，我会比这些互联网和大型软件公司，更懂得怎么去制造一辆车，这是我当时认为自己的优势。

Q：理想同学以前是一个车机的个人助手，现在要进入手机，变成一个App，未来还会上更多的终端，那这意味着，你们一个电动车企业，要进入通用个人助手这场红海战役了，是这样吗？

A：如果我们是一家纯硬件公司，是符合你刚才说的这个定义的，但就像苹果不是一家只卖Mac的公司，所以它才有了后边的可能性，今天的这些企业也不能以一个硬件来定义。

我们之所以去做很多的硬件，其实很多时候，是为了更好地控制硬件体系，以及性能再高一点点，但是大型软件是不一样的，不是所有人都能做操作系统，不是所有人都能做大型的云服务，这个就变成一个更大的挑战了。

回到人工智能也是一样的，今天你能看到几百家电动车企业，是因为中国有非常完善的供应链，但是这几百个企业里边，未来有哪些企业能去做基座模型？

Q：你觉得基座模型是一个分水岭是吗？

A：当然是。

Q：现在谁做了？

A：至少我们做了，至少我们一直在做基座模型，无论多么难，而且这是非常坚定的，我认为基座模型是人工智能时代的操作系统加编程语言，你就知道它有多么重要了。

Q：它是一个新入口的可能性？

A：我觉得基座模型所构建出来的，是人工智能的超级产品，是新一代的入口，它会在所有的设备之上，会在所有的服务之上。

Q：理想同学从车机进入手机，这是一个战略级的决定，还是你们只是想试试看？

A：我觉得没那么复杂，还是两方面。长远来看，在掌握基座模型前提下的，一个真正的大模型产品，一定是能够去自主使用所有的设备，会拥有所有的服务，这才是真正的人工智能。

在用户需求角度，很多理想用户的孩子，第一个接触的人工智能产品就是理想同学，在和理想同学对话的过程中，帮助他们解决一些问题，比如用理想同学来画画，或者和理想同学聊作业......我们希望可以让理想汽车的100多万用户，再加上这些用户的家庭，大概300-500万的人，不仅可以在车上，还可以在手机、电脑，甚至后边还可以在眼镜上，都体验到一致的人工智能产品，我觉得这是我们必须要做的。

03相信有生之年，我们能实现人工智能的第三个阶段

Q：很多人说你是超级产品经理，能不能从产品的角度来讲讲，随着人工智能的能力演进，它的产品形态会发生怎么样的迭代？

A：我觉得做产品很重要的一点，是把用户的需求和你所有的能力进行结合。

人工智能AGI（通用人工智能）实现到最终阶段，我经常用三种方式来描述。第一个阶段，叫“增强我的能力”，意味着其实它是我的一个辅助，但最后的决策权在我这里。包括L3的自动驾驶，我们叫有监督自动驾驶，其实还是需要我在车上进行监督，和最后的兜底，核心的原因是，第一个阶段能力还不够，负责任的是我，所以叫增强我的能力，但它确实会让我变得非常方便，让我的效率变得非常的高。

到了第二个阶段，就是智能体所描述的一个阶段，我称之为“成为我的助手”，就是我只要给它发任务，甚至可以发连续的任务，它就可以独立完成，并对结果承担责任。比如我可以跟一辆L4的车讲，你去帮我接孩子，我不需要坐在车上，它就可以到学校帮我接孩子，并进行面部识别打开门让孩子上车。这个阶段比较好的是它会变成大规模的应用，是真正的iPhone 4的阶段。汽车企业，只有实现了L4，才是真正的iPhone 4的阶段，但今天还不是。

第三个阶段是我想的AGI的终极阶段，因为理想汽车的使命是“创造移动的家，创造幸福的家”，所以我称之为“硅基家人”，就是我不需要再给它任何的指示了，我也不需要给它分配任务了，它就是我们的家庭成员，甚至是家庭重要的组织者，它不但了解我，它还了解我的孩子，了解我身边的朋友，甚至比我还了解。

它会主动去干很多事情，可以自主的衡量，帮我把这个家管理好。当AGI发展到第三阶段，是我的硅基家人后，我觉得很重要的点是说，我的记忆也会被它得以延续，可能我的肉体不存在了，但是我的记忆会变成它的一部分。

我自己最兴奋的一件事情是我认为，我和我们的团队能够在有生之年实现第三个阶段。

Q：所以你怎么看个人助手的战争呢，在这个红海市场中？

A：我觉得今天还是非常初级的阶段，大家还是要去拿AGI（通用人工智能）的L3的门票，以及自动驾驶的L4的门票，由于我们在这两个领域同时都做，我们还看到了一个更有意思，我们更相信、更坚定会去做的一个机会。

我们在做的理想同学和自动驾驶，按照行业的标准其实是分割开的，处于早期阶段。我们做的 Mind GPT，其实是大语言模型，我们在做的自动驾驶，我们自己内部叫行为智能，但是像李飞飞的定义，叫空间智能。只有你真正大规模去做的时候，你才知道，这两个之间，有一天一定会连在一起，我们自己内部叫VLA（Vision Language Action Model，视觉语言行动模型）。

我们认为，基座模型到一定时刻，一定会变成VLA。因为语言模型，它也要通过语言和认知去理解三维的世界，这个三维世界不是只有图片，因为它（图片）并不能还原真实的物理世界，它需要真正向量的，用Diffusion（扩散模型）的方式，用生成的方式。对于自动驾驶也是一样的，它真正能够变得更强，走向L4，是它要有极强的认知能力，当这些东西发生变化的时候，它能够有效理解这个世界，而不只是端到端背后的那些压缩记忆，这是我们看到的一个变化。

所以我对团队的要求，是至少在中国的范围之内，未来几年必须得保证，我们大语言模型的基座模型，要做行业前三。根据这样的要求，需要什么的训练算力，我们都愿意来投资，我们要真正去跟头部企业去PK，去竞争。核心还是说，我们得把这个能力真正构建起来，而不只是在汽车行业里比一比。

Q：如果资源有限，理想同学和智能驾驶必须二选一，你放弃哪个？

A：我会减别的，不会减这两个。

04只要所有的中国企业不放弃，一切皆有可能

Q：你们会像马斯克一样做Robotaxi吗？既做车也做Robotaxi。

A：我不想做，因为我们的使命是“创造移动的家，创造幸福的家”。

Q：那会不会Robotaxi到来以后就没有人开车了呢？

A：我们为什么要去构建一个家，我们为什么要去买一所房子，是因为我们需要高质量的陪伴，我们需要为我们的家人创造一个稳定安全和舒适的环境。车也是一样，我觉得实现L4自动驾驶以后，家庭用车也会变得更便宜，成本变得更低，所以我会相信另外一个方式，就是愿意拥有一辆车的人会变得更多。

可能5年后，10年后大家重新来看，到底是Robotaxi成为了主流，还是更多人能够拥有一辆自动驾驶的车，并且使用率很高，能够为自己的家人朋友所享用是一个主流，未来几年是个分水岭。但我相信，当一个空间变得更好，效率更高，体验更好的时候，我更应该拥有这个空间，这是我的感觉。

移动的家其实终极是L4，幸福的家是我刚才讲的“硅基家人”。

Q：很多人在问，理想会做机器人吗，特别是人形机器人？

A：概率上肯定是100%，但节奏不是现在。如果我们连L4级跟自动驾驶的汽车都解决不了，怎么去解决更复杂的？因为车是个无接触机器人，而且道路是标准化的，包括道路上的提示和参与者都是标准化的，而且每个人都受交通规则的训练，我觉得这已经是最简单的机器人了，如果车没法实现，其实其他人工智能机器人，还是非常有限的。

Q：理想汽车未来还会叫理想汽车吗？如果它要变成人工智能企业。

A：理想是一家人工智能企业，我们要做的不是汽车的智能化，而是人工智能的汽车化，并将推动人工智能普惠到每一个家庭。

我们的LOGO一直没有把汽车两个字写上去，甚至今天我们的运营公司还是叫“北京车和家信息技术有限公司”。但是硬件对我们非常重要，如果讲我们的愿景的话，一个更完整的称呼方式应该是“连接物理世界和数字世界”，从而能够成为领先的人工智能企业。

Q：你的一个00后员工想问你，在当前不利的外部环境，特别是地缘环境之下，怎么能成为一个全球领先的人工智能企业呢？

A：它是成长的一个过程，不是直达的一个过程。我觉得做一个创业者，很重要一点是我们要看不同的阶段。今天，哪怕我们做汽车不涉及人工智能，我也没有办法直接讲我会成为全球领先的汽车企业，所以我们要先在中国市场获得第一，然后再考虑下一步，在受美国限制的以外的市场，能不能做成第一。

其实人工智能也是一样的。我给团队提的要求是，我们到明年的时候，目标是要在中国的空间智能领域成为第一，在语言智能、大语言模型方面，以及所提供的服务方面进入到前三。团队按照这个要求来制定自己的目标，构建能力，以及确定我们的组织和投资，我觉得这个节奏还是非常重要的。

再往后我们看到的机会是，我们如何把语言模型和空间智能合成一个更大的VLA的模型，然后到了全面的Agent（智能体）阶段，以及到了L4自动驾驶阶段，你所具备的能力，以及站在今天还要去看我们去搞什么样的研究，匹配什么样的组织，以及怎么提前去准备一些投资，这是我们看到的解决方式。

Q：中国企业能成为全球领先的AI企业吗？

A：我觉得一切都有可能，只要所有的中国企业不放弃，一切皆有可能。过去的时候，我们也认为全世界最好的汽车都是德国人制造的，但今天大家不再有这样的一个观点了，最好的智能汽车都是中国企业制造的，是中国企业和特斯拉提供了全世界最好的智能汽车。在人工智能方面也是一样的，只要我们不放弃，我们把所有的心思和精力用在去改变和投入这些能力上面，结果一定会变得非常的好。

05体验也是本身

Q：你为什么买法拉利？它又不AI，又不自动驾驶。

A：我觉得体验对我是很重要的，因为体验也是本身，就像我做预训练的一部分。我只有通过体验，来看它到底是怎么做的，经过我自己的体验，它才能变成我的认知和能力。

Q：理想同学会上法拉利吗？

A：我觉得如果我没买法拉利之前，我会说我们永远不会上法拉利，但买了法拉利以后，我认为这是一个可能性。我能想象到当实现L4的时候，大家一定会把车做成方盒子，里面有非常好的空间，但是谁来满足乐趣，想自动驾驶就自动驾驶，想自己开就自己开，但又是非常好的智能车，人工智能的车为什么不可以？

所以我今天的想法是，可能到2030年的时候，我们会有50%的概率做一辆非常有趣的超级跑车，但它一定是人工智能的跑车。

Q：你觉得法拉利这样的车企应该拥抱AI吗？

A：我觉得最重要的还是得继续延续它了不起的设计，不受约束的设计，以及保持它的稀有。因为这些价值还是属于它独有的，我觉得哪怕到了下个时代，它应该还是会变成一个更好的法拉利，而不是变成一个科技企业，只是科技企业里，也可能会出现有意思的车型。 https://x.com/leeoxiang/stat/leeoxiang/status/1871908951643828333



### 87

2024-12-25

歸藏(guizang.ai)
@op7418
哈哈，终于来了！Deepseek V3 开源

在 aider 多语言编程测评超过了 Claude 3.5  sonnet V2 

Deepseek V2.5 的时候成功率只有 17%，现在暴增到了 48% ！

采用 685B 参数的 MoE 架构

包含 256 个专家，使用 sigmoid 路由方式，每次选取前 8 个专家 (topk=8)




### 88

2024-12-25

小互
@imxiaohu
日本发布初等高等教育阶段学生老师 AI 使用指南

非常详细和具有借鉴意义，值得学习

使用生成式AI的基本原则：

- 人类中心原则：AI的目标是扩展人类能力，而不是取代人类判断。

- 学校需认识到生成式AI的输出是“参考之一”，最终决策和责任应由人类承担。

培养学生的核心能力：

- 结合《学习指导纲要》中的能力要求，利用生成式AI培养-学生的信息素养和问题解决能力。 

- 鼓励学生使用AI工具来提炼自己的观点，提升批判性思维能力。

教师的角色：

-教师需成为学生与生成式AI之间的“引导者”，帮助学生正确使用这些工具。

-教师需要具备一定的AI知识与技能。

应用场景：

教师的校务工作：用于教学资料准备、时间表制定、活动计划等，提高工作效率。

学生的学习活动：帮助学生进行个性化学习、提供多样化的学习视角，但需注重信息真实性和道德教育。

教育委员会的指导：提供政策支持，确保生成式AI的安全使用。

安全与法律合规：

使用生成式AI时需遵守相关法律法规，特别是在隐私保护、著作权和公平性方面。

避免在生成式AI中输入敏感信息，如个人隐私和成绩数据。

道德教育和信息素养培养：

强化学生的信息素养和道德教育，使其能够正确使用AI工具，同时提高批判性思维能力。

指导学生在引用生成式AI的内容时，注明来源，避免抄袭或不当使用。

教师与AI的关系：

教师需要掌握生成式AI的基本知识，并在教学中适时引入，以支持学生学习。

AI的使用不能替代教师的人文关怀和教育职责。



### 89

2024-12-25


AI进化论-花生
@AlchainHust
做过一些尝试，长文本，比如一本书的翻译要保持一致性其实是保证两个方面的一致：1）关键词汇的一致；2）语言风格的一致。
我对前者的处理方式是先提取高频词汇，在system prompt里限定词汇翻译；对后者的处理方式是每次翻译时都把分块的前一部分chunk的原文和翻译文都放进去作为参照了，费token，但是效果不错。
引用
宝玉
@dotey
·
2024年12月27日
以最新最好大语言模型的翻译能力，其实真正的挑战不是比喻、隐喻这些，也不需要多智能体了，难点在于长上下文，如何一次性翻译超长的文本？如果是分块翻译如何保证和前面的翻译结果、风格保持一致？ x.com/aigclink/statu…


### 90

2024-12-27



宝玉
@dotey
以最新最好大语言模型的翻译能力，其实真正的挑战不是比喻、隐喻这些，也不需要多智能体了，难点在于长上下文，如何一次性翻译超长的文本？如果是分块翻译如何保证和前面的翻译结果、风格保持一致？
引用
AIGCLINK
@aigclink
·
2024年12月26日
腾讯新出的一个机器翻译项目：DRT-o1，把长链思维应用到机器翻译当中，来解决因为文化差异导致的翻译结果差异化的问题，特别是像文学作品中有一些包含比喻或隐喻的复杂句子

它用多代理框架模拟人类翻译过程，有翻译、顾问和评估，比直接翻译，能更好的处理文化差异表达、隐含含义和语言习惯等

#DRTo1
显示更多


### 91

2024-12-27

宝玉
@dotey
这种大 PDF，最好借助 PDF 先转 Markdown，人工校验一下再让 AI 或者翻译工具分页翻译比较好。

如果没有找到合适的 PDF 转 Markdown 工具，可以写代码（让 AI 帮你），将 pdf 转成图片，然后用 Gemini Flash 2.0 识别成英文，输出为Markdown。
引用
Isaac Chao
@irpstack
·
2024年12月27日
回复 @dotey
宝玉老师，我有一本美国电工教材pdf，1000页，局部文字还不清晰，用什么AI翻译好？
上午7:06 · 2024年12月27日
·
1.2万
 查看

宝玉
@dotey
·
2024年12月27日
比如微软的 Markitdown




### 92

2024-12-27

宝玉
@dotey



刚从技术转管理，第一件事就是要减少过多做具体的事情，多花精力在全局，在团队，比如项目的进度，项目计划，团队成员的工作有没有障碍。

刚从技术转管理最容易犯的错误就是还是以前一样埋头写代码，这样会耽误团队的。要学会授权，要学会把活分出去，分出去的活还要跟踪进度，出现问题及时调整。

第二件事就是对齐和管理预期，不是互联网黑话对齐颗粒度，而是 Alignment，让团队的方向和组织方向保持一致，不要偏了。你老板希望你的团队做什么，你的团队正在做什么，你老板对你的预期是什么，你对每个团队成员的预期是什么，团队成员对你的预期是什么。

具体做法上就是要很多 1:1 的会议，跟老板跟下属跟同级的其他同事。先要搞清楚他们的预期是什么，然后去调整预期。

第三件事是招人和开人，招合适的人，踢掉不合适的人。

最后，对内自始至终激发善意，让团队成员有激情，让团队成员自驱的去做事；对外多要资源多邀功少背锅。






热烤奶
@TinsFox
·
2024年12月28日
回复 @manateelazycat
对刚晋升没有管理经验的小年轻有什么建议吗？🥹


### 93

2024-12-27

宝玉
@dotey
再举一个 o1 编程能力的例子，我有一个播放器的React Hook，用到了 Jotai 做状态管理记录播放器状态，现在我需要增加一个功能，在a-b之间(rangePlay)播放视频的功能，然后交给 AI 帮我实现。基本都能实现，但差别在于：

1. Claude/GPT-4o/Gemini 都是用setTimeout来控制到b点了结束视频播放，满足要求，但是如果拖放或者加速播放就会有问题，这就是普通程序员的水平

2. o1 会基于现有Jotai状态定义增加一个rangeEnd的状态，侦听播放器的timeupdate，然后时间到了rangeEnd的时候会停止，这样不管你是拖放还是快放还是慢放，都是到时间了自动停止

我觉得 o1 做的好的地方不是能想到用 timeupdate 侦听，因为这应该是通用解决方案，Claude 多试几次或者我明确要求也能是这结果，而是在于 o1 能分析我的代码，知道我用了 Jotai 做状态管理，所以基于 Jotai 的状态管理增加了新的状态，而不是去用一个内部的 React State。
引用
宝玉
@dotey
·
2024年12月26日
o1 之前我是把 AI 当实习生的，因为它的智力和经验绝大部分时候是不如我的，所以我就需要给明确的指令，让它按照我的指令去一步步完成。但是到了 o1 的时候，智力是有明显提升的，有时候能给出比我更好的方案。

所以我现在会把 o1  x.com/dotey/status/1…



### 94

2024-12-27



Barret李靖
@Barret_China
前端解决的是人机交互层面的问题，传统的前端程序员可能会消亡，但同样还是这群人，会以新的身份和技能来适配这一层。人机交互是刚需😄
引用
熠辉 Indie
@yihui_indie
·
2024年12月26日
我猜周五的前端圈的热门标题有了！🤦🏻‍♂️
玉伯预言AI 编程：我能经历前端程序员从诞生到消亡的全过程

### 95

2024-12-27


宝玉
@dotey
推荐阅读：《使用Cursor作为AI的通用入口》
https://yage.ai/cursor-ai-entry.html


[[Agentic AI] 使用Cursor作为AI的通用入口](https://yage.ai/cursor-ai-entry.html)


### 96

2024-12-27



Nat Friedman
@natfriedman
We did it! We tested 300 Bay Area foods for plastic chemicals. We found some interesting surprises.

Top 5 findings in our test results:

1. Our tests found plastic chemicals in 86% of all foods, with phthalates in 73% of the tested products and bisphenols in 22%. It's everywhere.

2. We detected phthalates in most baby foods and prenatal vitamins.

3. Hot foods which spend 45 minutes in takeout containers have 34% higher levels of plastic chemicals than the same dishes tested directly from the restaurant.

4. The 1950s Army rations we tested contained surprisingly high levels of plastic chemicals.

5. Almost every single one of the foods we tested are within both US FDA and EU EFSA regulations.

Check out our full results below.

### 97

2024-12-27

小互
@imxiaohu
2024 年人工智能关键发展的总结分析报告

报告系统性地覆盖了语言模型、图像生成、语音技术等AI核心领域的技术进展，同时结合了市场分析和开发者需求洞察。

2024年人工智能技术取得了前所未有的进步，前沿语言模型、小型模型、开源模型和多模态模型的能力显著提升，推动了AI在实际应用中的普及和成本降低。

尤其是图像、视频、语音技术的快速发展，进一步扩展了AI在创意和生产领域的可能性。

随着技术突破和市场需求的推动，AI行业正迈向更高效、更智能、更多样化的未来，开放生态和技术整合将成为关键驱动力。



### 98

2024-12-29


宝玉
@dotey

实例演示我是如何和 AI 结对编程的

比如我要做一个功能模块，我自己有个大概的思路，然后我将需求抽象精简，包含在一个上下文中，只是一个大方向，不涉及太多细节。（参考图 1）

1、让 AI 根据需求出设计方案。

同样的需求我用 3 个不同的会话生成 3 次（参考图 2、图 3），这样可以生成不同的结果对比，看看差异，如果觉得结果都有问题，那么就调整提示词，继续生成几次，直到和 AI 的思路比较一致了。

这一步尽量不要设计太多技术细节，最好让 AI 出方案，除非你很有把握，因为有时候 AI 能提出更好的方案，就算它提不出更好的，和你想的差不多也是对你的一种肯定。

这就好比你是个经理，让下面三个资深员工就同一个需求分别出方案，然后选一个最好的，如果需求没描述清楚就完善需求。同理如果你一开始就把细节定了，那么给员工的发挥余地就小了，所以最好让员工自己提方案，说不定会有更好的方案。

2、设计方案确定后，填充细节生成代码。

方案定下来后，就可以把方案的细节都补充上，避免 AI 在生成代码时遗漏，然后交给 AI 去生成（参考图 4）。生成后简单 Review 下就知道是不是遵循了设计。

如果没有遵循设计，就完善提示词，让 AI 重新生成，指导遵循了设计。

如果有 Bug，先尝试在回复中纠正，如果 1-3 次纠正还不能修复，重新调整提示词或者提示词都不用调整，直接重头生成，或者去试试其他更好的模型。

这同样也相当于你扮演经理的角色，定好设计后让员工去写代码，如果他们没搞明白设计就重新说明，如果写的有 Bug 就告诉他们 Bug 在哪让他们修复，如果修复几次都修不好，就开除换人重写。

总结下就是像一个开发经理一样，去跟 AI 员工描述需求，让手下几个 AI 员工去设计，AI 员工设计完挑选确认方案，方案确认后继续让 AI 员工帮你生成代码，代码不好就修改提示词重新生成。

图 1：

我有一个字幕数据，需要你帮助实现字幕拆分的逻辑，要求：
1. 使用 TypeScript，假设已经有一个函数叫
 generateTextMaterialWordsText，输入是字幕的text，输 出是字幕的words，比如"Hello world!”，输出是["Hello", "world!"]
2. 根据光标位置来拆分字幕，比如segment的text是“Helloworld!"，光标位置在 Hello 的。 后面，那么拆分后的字幕 是"Hello"和" world!"
3.拆分后要同时更新 start 和 end 时间
-首先从words里面找到切分后两段文字对应的words，然 后根据第一个word的start和最后一个word的end来更新 start和end
-如果不能匹配到对应的words，先将整段文本分割成一个个 word，然后根据文本总时长和单词数量来平均分配每个单词的时长，从而得出它们在时间轴上的开始、结束位置。
- 注意边界条件检测
下面是参考的输入的Json数据。

图 3：

我有一个字幕数据，需要你帮助实现字幕拆分的逻辑，要求：
1. 使用 TypeScript，假设已经有一个函数叫
 generateTextMaterialWordsText，输入是字幕的text，输出是字幕的 words，比如“Hello world!”，输出是["Hello", “world!"]
2. 根据光标位置来拆分字幕，比如segment的text是“Hello world!”，光标位置在 Hello 的 o 后面，那么拆分后的字幕是“Hello"和” world!"
3. 拆分后要同时更新 start 和 end 时间
- 检查光标位置，如果光标位置在两个单词之间，则将两个单词都拆分出来，否则不需要拆分
- 先分别将left,right两端字符串调用generateTextMaterialWordsText拆 分成words
- 然后将left,right两端words去和原始segments的words进行比对
比对单词时过滤掉标点和空格，也不需要考虑大小写
对比left words的时候，和原始的segments的words从左到右依次比对
对比right words的时候，和原始的segments的words从右到左依次比对
- 如果left或right的words能完全匹配并且两头words的时间范围没有超 过原始segment的时间范围，则使用匹配到的last left word 的end or first right word 的start来拆分 segment
- 如果不能匹配到对应的words，先将整段文本分割成一个个word，然后根据文本总时长和单词数量来平均分配每个单词的时长，从而得出它们在时间轴上的开始、结束位置。
- 写成多个函数，尽量每个函数只做一件事


### 99

2024-12-29

宝玉
@dotey
问：低耦合设计怎么写prompt，能给我们一个小例子吗？
答：

举个例子，我在写一个字幕编辑器的App，设计的时候，播放器是一个独立的模块，字幕编辑部分也是一个独立的模块，比如说我现在要给字幕编辑模块增加一个当前播放位置的字幕高亮并自动滚动的功能，我就只需要把字幕编辑器相关的代码发过去。

所以我在写 Prompt 的时候，就只要把字幕编辑这个模块和这个功能相关的代码都选上（参考图1，用的是一个叫 RepoPrompt 的 App），然后和提示词一起发给过去。即使我这个功能需要用到播放器中当前播放的时间，但是我并不需要把播放器的代码发过去，只要让 AI 知道有这么个播放器的状态我可以直接调用即可。




### 100

2024-12-29

Leo Xiang
@leeoxiang
用Cursor分别用js(通过浏览器) 和 golang 实现了 Realtime API with WebRTC 的通信过程：

1、在浏览器中WebRTC 资料比较多，完全依赖Cursor就能实现。
2、用golang在实现的过程中涉及到音频的采集和播放，遇到portaudio的编译 以及 pion的版本问题，这个时候需要人来一步步来debug，cursor 作为那个实施的人，不过效率也高了很多。



### 101

2024-12-29

宝玉
@dotey
网友分享：

你好宝老师，我想投稿大模型的使用体验。我是理工科，国内土博，材料专业。使用强度不是很高，但是集中分析的时候会连续追问和讨论。

关于推理模型，我想说说我的使用体验。我使用的较多的时gpt o1，O1mini，还有谷歌的新出的thinking。
我想说o1目前还是当之无愧的第一，因为具有很庞大的知识库。我使用都是在分析化学的情况下，比如红外图谱和核磁图谱的分析。然后O1是说的最靠谱。我结合文献和O1聊我的推理，基本就能把图谱分析的七七八八差不多。但是o1mini不精通化学结构导致理解不了复杂化学结构，谷歌的thinking也一样对化学不够精通，比如今天核磁分析时就弄混了ppm高低和上下场的关系。而o1可以一直正确的分析推理。

以我的认知我认为，知识库的丰富程度极大程度决定了好用与否。最近新出的推理模型，由于缺乏知识库，测试发现推理的化学结果大部分都不对。目前我只有用o1的时候很少发现错误。所以可能高成本的模型还是更有实际价值，而针对推理方面雕花的可能还是炫技更多一些。



### 102

2024-12-29



宝玉
@dotey
问：如果是在国内的程序员普通的后端java开发，能怎么往llm的方向靠呢？自己很想转，但不知道该怎么做比较好

答： 往 llm 方向靠没想的那么难，第一是有想法；第二是行动。行动了最好马上有正反馈，这样才能让自己坚持下去。想让自己马上有正反馈也不难，按照下面去做你一定会有正反馈，不需要交 ¥999 去报个班。

如果要学习 LLM 方向，我建议可以先学 AI 辅助编程再去学习 LLM 方向，磨刀不误砍柴工，一方面你可以借助 AI 编程熟悉 LLM，另外未来可以借助 AI 提升效率，以及遇到问题可以随时问 AI。

所以建议你可以：

用 AI 编程，先注册个 Cursor 账号，有 2 周免费使用，0 成本起步，使劲的用，用它自动完成代码，用它聊天，用复杂的 Prompt 生成代码，写规则定制化，看它能做什么不能做什么，做着做着你就感受到 LLM 是什么，有什么价值。

辅助 AI 编程做 LLM 相关的 Side Project。不要指望在公司能一边拿着工作一边学你想学的技术，这其实很难的，但是 Side Project 不一样，你可以做任何你想做的项目。比如你想做 LLM 相关的，那就可以去做起来，比如做个简单的翻译工具、AI 聊天、文档对话，也许以前是很难的事情，如果你已经上手了 AI 辅助编程，那么很快你就可以做一个原型出来。

把 AI 当老师，写代码、做 Side Project 的过程中，不明白的，让 AI 给你讲解，给你加注释，有问题随时问它，你会发现你多了个随时解答问题的好老师。

有了上面的这些正反馈，你很快就会成为一个熟练掌握 LLM 的程序员，不再是一个 Java 或者某个领域的程序员。

行动起来，找到正反馈，坚持用，就这样！
引用
chaosMax
@ChaosXmas
·
2024年12月29日
回复 @fi56622380
如果是在国内的程序员普通的后端java开发，能怎么往llm的方向靠呢？自己很想转，但不知道该怎么做比较好


### 103

2024-12-29


宝玉
@dotey
Prompt：宝玉老师，我在组里强推某种固定格式的开发设计文档，要求组员按格式补充写完，再借助o1或则别的模型实现代码细节，是否可行。等代码出来工程师再进行一定的修改或则调整。

Repsonse：
对于这种先设计再开发，辅助 AI 编程的方式，我觉得非常赞，如果我做的话，可能会做一点调整：

1. 组员的主观能动性很重要，如果是组长把事情都想了都做了，他们的作用就成了工具人，积极性就没有那么高，所以我可能只是把需求沟通清楚，大的设计方向定下来，任务分下去，让组员各自设计，然后review，最终对齐，以组员自己设计为主，但是在过程中多引导多辅助，达成一致。

2. 采用 AI 编程是很好的，但写文档的方式不见得是最佳方式，比如说有时候几句话辅助代码可能效果更佳，另外既然是要组员去用 AI 沟通，那不如完全交给组员自己去做，让他们去找到和 AI 结对的最佳方式，组长就是组织好经验的交流，让大家一起交流好的经验，但还是发挥组员自己的主观能动性。

我最近大量借助 AI 编程，经验就是用好 AI 编程，设计很重要，并且模块之间耦合度不要太高，不需要太过于追求设计的形式，只要设计清晰，能让 AI 理解你的设计，能在一次会话中获得足够的上下文，就容易让 AI 生成好的代码。


### 104

2024-12-29

宝玉
@dotey
让 o1 pro 帮我实现一个 undo、redo 管理的功能，它的方案是设计了两个堆栈分别记录已经产生的历史、被 undo 后可能被 redo 的记录，而 Claude 给我的方案则是一个堆栈加一个索引记录在堆栈中的位置。两者方案其实都可以，但 Claude 的方案更简洁一点
引用
宝玉
@dotey
·
2024年12月28日
再举一个 o1 编程能力的例子，我有一个播放器的React Hook，用到了 Jotai 做状态管理记录播放器状态，现在我需要增加一个功能，在a-b之间(rangePlay)播放视频的功能，然后交给 AI 帮我实现。基本都能实现，但差别在于：

1. Claude/GPT-4o/Gemini  x.com/dotey/status/1…





### 105

2024-12-29


宝玉
@dotey
bolt 和 v0 这种产品的问题在于它不知道用户是怎么用的，前端还是后端还是原型，所以它只能在系统提示词里把每一种情况都考虑到，每一种情况都写针对性的提示词，所以每一次的交互其实你只需要其中 20% 左右的提示词，如果你知道自己常用场景是什么，就好针对性优化减少 Token
引用
歸藏(guizang.ai)
@op7418
·
2024年12月30日
这个 Bolt 提示思路非常牛皮 

Bolt 修改时重新生成整个文件有很大的问题

可以解决随着项目越来越大，每次修改都会不可控，提示词无法准确描述需要修改的部分，就会频繁出错

这个提示会创建项目的时候就新建一个项目地图，然后每次输入提示词的时候先去让 Claude 润色提示词

能大幅减少 Bolt Token  x.com/nkgoutham/stat…
显示更多


### 106

2024-12-29




宝玉
@dotey
o1 pro 重构代码（仅限单个或者少数几个文件）效果是挺好的，提示词可以很简单：

请重构下面的代码：
1. 更好阅读
2. 更好维护
下午5:00 · 2024年12月31日
·
2.3万
 查看

宝玉
@dotey
·
2024年12月31日
o1 pro 重构的代码，挺可靠的，极少出错，错了重新生成一遍一般就没问题了，所以我一般是一遍重构一边加新功能，加完手动review和测试一下。理论上来说让它写一些测试代码更好。

### 107

2024-12-29


宝玉
@dotey
春假两周在家教孩子编程，对编程没兴趣所以以前没学过我也没教过，但明年要学编程课了想提前跟我学一点，我教编程的方法很简单直接：

1. 首先找需求，看能做点什么自己用的上的东西
学编程最好是能学以致用，做一点能自己用的上的东西是最好的。最后一起讨论定下来做一个浏览器插件，点击插件可以显示学校网站的通知，这样就不用打开网站去看通知了，随时查看。

2. 跟 AI 结对，让 AI 帮助完成第一版本
最开始先教一点最基本的，通过 Chrome Dev Tool 去看网络请求，去找到相关API请求，复制fetch的代码出来，然后就自己去向 AI 描述需求，然后遇到问题让 AI 帮助解决。几个小时后就自己借助 AI 搞定了一个可用的版本。

3. 去解释代码是如何工作的
如果只是跟 AI 结对写代码，并不会理解代码，所以最好就是去向别人解释代码是怎么工作的，因为要解释清楚得先学习搞清楚。一开始是解释不清楚的，不清楚就是去问 AI，中间我也会帮助解释一下，反复几次把每一行代码都讲一遍，中间再对代码做一些修改对比看修改后的效果加深理解。

我是费曼学习法的忠实信徒，一直坚信最高效的学习方法就是把学到的东西解释给别人听，能把代码从头到尾讲清楚就能学到东西。

4. 迭代增加新功能
最初的版本只有显示文字版的列表，基于它之上再加上显示图片、增加本地存储、显示未读条数等等功能，通过迭代，一方面让程序更实用，另一方面也是做中学。继续跟 AI 结对，继续讲解代码。

我教编程的方法总结下来就是：做点能用的上的东西，跟 AI 结对编程，不懂的让 AI 教，写出来的代码要能解释给别人听，通过版本迭代不断完善不断学习。

### 108

2024-12-29


歸藏(guizang.ai)
@op7418

Open AI 研究员 Jason Wei 说了一下过去五年他在 AI 领域意识到的一些重要的技术经验。

看来大家都对明年 Agents 的落地很有信心啊
引用
Jason Wei
@_jasonwei
·
2024年12月31日


Reflecting back, these were the biggest technical lessons for me in AI in the past five years:

2020: you can cast any language task as sequence prediction and learn it via pretrain + finetune

---


Jason Wei
@_jasonwei

Reflecting back, these were the biggest technical lessons for me in AI in the past five years:

2020: you can cast any language task as sequence prediction and learn it via pretrain + finetune

2021: scaling to GPT-3 size enables doing arbitrary tasks specified via instructions

2022: scaling to GPT-3.5/PaLM size unlocks reasoning via chain of thought

2023: LLMs themselves can be a product a lot of people will use

2024: to push capabilities past GPT-4, scale test-time compute

2025: ??? probably something like “agents work”

I feel like each one was a significant shift in what I should put effort on. I am super curious to hear what other people’s lists of things they learned each year that changed the way they view the field, and how they differ.

Looking back, these things seem obvious in hindsight but were hard to know ahead of time. I definitely learned some things slower than others and it took me time to understand things deeply. For example, some people probably deeply understood the lessons from GPT-3 in 2020 or earlier, or realized the importance of scaling test-time compute way before 2024.

2020：任何语言任务都可以转化为序列预测问题，通过预训练 + 微调来学习

2021：扩展到 GPT-3 规模后，能够通过指令执行任意任务

2022：扩展到 GPT-3.5/PaLM 规模后，通过思维链解锁推理能力

2023：LLM 本身可以成为很多人会使用的产品

2024：要突破 GPT-4 的能力边界，需要扩展推理时的计算规模

2025：?？？可能会是「智能体真的能工作了」


### 109

2024-12-31


歸藏(guizang.ai)
@op7418
由于海外的一些原因，我们国内用点先进模型是真的难

而且很多企业也有非常多的 AI API 需求，需要有监管集中采购还会进行一些二次开发，这种服务市面上就更少了

前几天突然发现了 302 .AI 这个平台，他们真的离谱！

同时面向 B 端和 C 端，真的搜罗了市面上几乎所有前沿模型



### 110

2024-12-31


歸藏(guizang.ai)
@op7418
Pixverse V3.5 模型发布真的起飞了

玩了好几天看一下测试结果

现在 Pixverse V3.5 应该是第一档模型中速度最快的，Runway 唯一的优势也没了

V3.5 的 Turbo 模型一条视频只需要 10 秒以内，快的话 5、6 秒就可以生成！

重要的是这个快速模型生成质量除了分辨率之外吊打 Runway

下面有详细的介绍：


### 111

2024-12-31


辉小志
@imvihv
哇，这个cline插件配合deepseek，真是又快又好，哪还需要什么cursor、windsurf，这套开源组合强无敌



### 112

2024-12-31


宝玉
@dotey
如果不懂技术，可以先：
1. 优先用所见即所得的 AI 工具，比如 v0，Claude 的Artifacts，直接就可以看到 UI 效果，避免了自己搭环境
2. 借助图形化的内容截图、设计稿、草图去描述你要做的功能、UI
3. 不知道如何描述可以先在 ChatGPT 这样的聊天机器人中去沟通，让 AI 帮你写提示词描述
4. 如果遇到 Bug，重点是描述清楚问题：
- 相关的代码是什么？（上下文很重要）
- 如何重现 Bug？
- 期望结果和实际结果？错误信息？日志？
5. 让 AI 在代码中写注释，给你解释代码是如何工作的

最后，新手学习一点基础知识还是有必要的，多练多试，有问题可以随时去请教 AI。


### 113

2024-12-31




GitHubDaily
@GitHub_Daily
一款开箱即用的翻译和 OCR 工具：STranslate。

- 支持划词、截图、鼠标划词等多种翻译方式
- 支持离线使用 OCR，效果好且响应迅速
- 支持 OpenAI、DeepL、Google 等 10 多家翻译服务
- 支持全局 TTS、写作、自定义 Prompt 等

GitHub：https://github.com/ZGGSONG/STranslate/ 

看起来挺不错的，值得安装试用下。

### 114

2024-12-31


歸藏(guizang.ai)
@op7418
这网站的数据可视化也太强了

用一张图展示 1500 年以来的技术演化和他们的关系

纵坐标是时间横坐标是技术分类，四个主题：通信、计算、分类和控制
上午11:27 · 2025年1月2日
·
7万
 查看

歸藏(guizang.ai)
@op7418
·
1月2日
地址在这里：
来自 calculatingempires.net
