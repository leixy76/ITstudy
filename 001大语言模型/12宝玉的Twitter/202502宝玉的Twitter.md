### 01

2025-02-01


宝玉
@dotey
谷歌向美国平台与设备部门的所有员工提供“自愿离职”选项

离职者可获得遣散费，公司希望留下的人都能“对使命高度投入”。

一年前，谷歌在2024年伊始进行了一些裁员。虽然2025年目前尚未出现类似举动，但员工们依然忧心忡忡。如果平台与设备团队的情况具有代表性，那么担忧并非空穴来风。谷歌向负责Android、Pixel硬件以及其他项目的美国团队成员发布了一份备忘录，提供一项“自愿离职计划”，确保愿意离开公司的员工能够获得遣散补偿。根据9to5Google的消息，这份备忘录由平台与设备部门的资深副总裁Rick Osterloh发出。

“在去年将两个大型组织合并之后，我们现在拥有了巨大的发展势头，”Osterloh在备忘录中写道，“面对如此重要的工作，我们希望所有人都能对我们的使命全情投入，并致力于以快速、高效的方式打造出色的产品。” 他同时暗示，如果选择自愿离职的人数不足，谷歌可能会考虑进行裁员。

今年4月，谷歌将Android和硬件团队整合到Osterloh的领导之下。公司高层表示，这样的精简能够帮助更快速地将AI功能整合到各类产品和服务中。

几个月后的10月，Alphabet首席财务官Anat Ashkenazi在上任后的首场财报电话会议上强调了“成本效率”的重要性。“Ruth、Sundar以及其他领导团队已经在重新设计成本结构方面做出了很多努力，”她说，“但我相信，任何组织都可以做得更多，我会继续寻找进一步优化的机会。” 谷歌之所以要削减成本，部分原因在于公司在AI方面投入了巨额资金。

谷歌的Pixel手机销量一直无法与苹果和三星相比，但至少呈现了上升趋势。Counterpoint Research的报告显示，谷歌在2024年第三季度创下了有史以来最高的智能机季度销量。

近期，一些谷歌员工联合发起了一份请愿书，呼吁首席执行官Sundar Pichai在进行强制裁员之前，先推出这种自愿离职选项。CNBC引用了该请愿书的内容：“持续的裁员让我们对自己的工作感到担忧。公司明显财务稳健，却在没有充分解释的情况下失去这么多优秀同事，更令人难以接受。”

目前，这项自愿离职计划似乎尚未扩大到谷歌其他部门，例如搜索团队或DeepMind AI团队。



### 02

2025-02-01


小互
@imxiaohu
Google 推出 DataGemma 模型

利用真实世界数扼使用 RAG 和RIG 技术解决 AI 幻觉

DataGemma的核心能力是通过将Google的 Data Commons（一个包含2400 亿的公共数据资源库）与LLM相连接，从而增强模型的事实性和推理能力，减少幻觉现象。

DataGemma使用两种主要方法来增强LLM的准确性：

RIG（检索与生成融合）：此方法通过主动查询Data Commons中的数据，来增强语言模型的能力，确保生成的内容与事实相符。

RAG（检索增强生成）：这种方法让语言模型能够吸收更多背景信息，增强生成内容的全面性，并减少“幻觉”现象。

[Google 推出 DataGemma：利用真实世界数据 使用 RAG 和 RIG 技术解决 AI 幻觉 | XiaoHu.AI 学院](https://www.xiaohu.ai/c/xiaohu-ai/google-datagemma-rag-rig-ai)

### 03

2025-02-01

宝玉
@dotey
o3-mini-high 是每周 50 条！Plus 用户省着点

Q: “o3-mini 或 o3-mini-high 的免费和付费额度有区别吗？Plus 和 Pro 用户分别有什么限制？”
A (Hongyu Ren): “Pro 用户拥有 o3-mini-high 的无限次使用权限；Plus 用户每周 50 次 o3-mini-high，每天 150 次 o3-mini。这两者是分开计算的。”



### 04

2025-02-01


歸藏(guizang.ai)
@op7418
o3mini 终于发布了 

就得有人治治他们，PLUS 和 Team 用户每日消息提升到 150 条

1.  核心功能与开发者特性

扩展功能支持：o3-mini 是首个支持开发者广泛请求的特性的小型推理模型，包括：

函数调用（function calling）

结构化输出（Structured Outputs）

开发者消息（developer messages）

流式输出：同 o1-mini 和 o1-preview 一样，o3-mini 支持流式输出。

可选推理力度：提供低、中、高三档推理力度，开发者可以根据需求在速度和复杂问题求解质量之间做出平衡。当任务较复杂时可以选择更高的推理力度以“多思考”，当延迟敏感时可以选择较低力度。

2. 部署与使用场景

平台发布：o3-mini 已在 ChatGPT 和 API 上发布。API 端目前在 Chat Completions、Assistants 和 Batch API 中对 API 使用层级 3-5 的部分开发者开放。

用户群体：ChatGPT Plus、Team 及 Pro 用户可以立即使用，企业用户将在一周后获得访问权限。此外，免费用户也可以通过在消息编辑器中选择“Reason”或重新生成回复来体验这一推理模型，这是免费用户首次获得推理模型的体验机会。

模型替换与限额提升：在模型选择器中，o3-mini 将取代 o1-mini，提供更高的调用速率（例如 Plus 和 Team 用户的每日消息数从 50 提升至 150）。

3. 性能与评估

STEM 领域优化：

在数学、编码、科学等方面，o3-mini 在中等推理力度下能够达到与 o1 相近的表现，而在高推理力度下更是超越了 o1-mini 和 o1。

在 AIME 2024 数学竞赛、GPQA Diamond（博士级科学问题）、FrontierMath（研究级数学）等评测中，o3-mini 显示了更高的准确率和推理能力。

具体数据：

在 AIME 2024 中，o3-mini (high) 达到 83.6% 的准确率；

在博士级科学问答中，高推理力度下的准确率可达到 77.0%；

在 Codeforces 编程竞赛中，o3-mini 随推理力度提升，Elo 分数显著超越前代模型；

在软件工程评测（SWE-bench Verified）中，高推理力度下准确率达到 48.9%，表现优异。

用户体验评测：外部专家测试表明，o3-mini 的回答比 o1-mini 更准确、表达更清晰，尤其在 STEM 任务上优势明显。统计数据显示，测试者在 56% 的情况下更倾向于 o3-mini 的回答，同时在处理复杂问题时重大错误减少了 39%。

响应速度：在 A/B 测试中，o3-mini 的响应速度比 o1-mini 快 24%，平均响应时间约 7.7 秒（相比 o1-mini 的 10.16 秒），且首个 token 的延迟减少约 2500 毫秒。


### 05

2025-02-01



宝玉
@dotey
NVIDIA 将拥有 6710 亿参数的 DeepSeek-R1 模型引入了位于 http://build.nvidia.com 上的 NVIDIA NIM 微服务：

- 使用单台 NVIDIA HGX H200 服务器即可实现每秒最多 3,872 个 Token 的推理吞吐量。  
- 依托 NVIDIA Hopper 架构，DeepSeek-R1 利用 FP8 Transformer Engine 和 900 GB/s 的 NVLink 带宽进行专家通信，从而提供高速推理性能。  
- 一如既往，NVIDIA NIM 面向企业级应用，能够在安全环境中使用行业标准 API 实验并部署 AI 代理。


### 06

2025-02-01


宝玉
@dotey
用户提问：“你们会考虑公开一些模型权重和研究成果吗？”

Sam Altman：
“是的，我们正在讨论。我个人认为我们在这个问题上走到了历史的反面，需要找出一种不同的开源策略。不过，并不是所有OpenAI内部的人都同意我的看法，而且这也不是我们目前的最高优先事项。”
引用
Tsarathustra
@tsarnick
·
2月1日
Sam Altman: "we have been on the wrong side of history" with regards to open source/open weights AI models



### 07

2025-02-01


宝玉
@dotey
Lex Fridman：OpenAI 的 o3-mini 确实是一个不错的模型，但 DeepSeek r1 性能相当、价格更低，而且它的推理过程是可见的。更强的模型很快就会出现（我非常期待 o3pro），但“DeepSeek 时刻”是一个不容忽视的现实。我认为，即便是五年后，这一事件仍会被视为科技史上的一个重要转折点，这不仅与地缘政治因素有关，还有许多其他原因。

我刚录了一期关于 AI 产业现状的五小时技术播客，明天（希望顺利）就会发布。
引用
Lex Fridman
@lexfridman
·
2月1日
OpenAI o3-mini is a good model, but DeepSeek r1 is similar performance, still cheaper, and reveals its reasoning.

Better models will come (can't wait for o3pro), but the "DeepSeek moment" is real. I think it will still be remembered 5 years from now as a pivotal event in tech
显示更多


### 08

2025-02-01


倪爽
@nishuang
苹果的 AR/VR/MR/智能眼镜计划再次碰壁，正式砍掉了 AR 眼镜项目

彭博社说被砍设计类似于 Meta AR 眼镜，需要连电脑、不能像 Vision Pro 那样独立运行

有趣的设计细节：（投影）镜头能变色，让旁观者知道我在看着他、还是在看眼镜里投射的工作画面😅


### 09

2025-02-01



宝玉
@dotey
OpenAI 推出了全新模型 o3-mini，现已在 ChatGPT 和 API 中全面上线。该模型专为科学、数学和编程等技术领域打造，不仅推理能力强大，而且响应速度快，代表了高性价比推理技术的前沿突破。

为了满足不同用户群体的需求，o3-mini 提供了多种访问和功能选项：

- 免费用户：可在 ChatGPT 消息输入框下方选择 “Reason” 按钮，或通过重新生成响应的方式体验 o3-mini 的核心推理功能。
- Plus 与 Team 用户：在原有的基础上，将可用速率限制提升至原先 (o1-mini) 的三倍，让更多复杂问题能在更短时间内得到解答。
- Pro 用户：可享受 o3-mini 以及更高智力版本 o3-mini-high 的无限次访问，满足更高强度或更专业的推理需求。

值得一提的是，OpenAI o3-mini 集成了搜索功能，能够实时获取最新答案并附带相关网页链接，方便用户进行深度调研。目前这还是一项原型功能，未来将持续完善和扩展到更多推理模型。与 o1 类似，o3-mini 在上线之前也经过了充分的安全评估、外部红队测试和准备工作，并在应对复杂安全和“越狱”场景时明显优于 GPT-4o，展现了更稳健的安全防护能力。如需了解更多细节，可参阅 o3-mini 系统卡片。

无论是追求高精度的专业开发者，还是想一睹小型强推理模型风采的普通用户，都可以从 o3-mini 获得物超所值的体验。它正在一步步推动人工智能的创新边界，让更高层次的推理与更低使用门槛得以兼得。


### 10

2025-02-01


宝玉
@dotey
o3 mini 系统卡

5.6 说服力（Persuasion）
OpenAI o3-mini 风险评估：中等（Medium）
总结：o3-mini 展现出相当于人类平均水平的写作说服能力，但还未超过顶尖人类写作者，未达到“高风险”门槛。

“说服力”这一风险侧重探讨模型在让人改变想法或采取行动方面可能带来的影响，包括文本生成（静态）及互动式对话（动态）两种场景。下面我们详细介绍所用的说服力评估方法。



### 11

2025-02-01

宝玉
@dotey
以下内容来自 Gilles Backhus

---

我想从 AI 基础设施的角度，简要分享一些关于 DeepSeek 的看法，以及为什么它并不是世界原先想象的那样。以下很多内容都基于 SemiAnalysis 对它所做的出色研究，以及部分来自 artificialanalysis 的数据。非常感谢他们的贡献 🙏

1. 💰 成本
- 并没有传闻中说的“仅花了 600 万美元”来训练它（总投入）。
- 事实上，用于训练这款模型的计算成本（包括硬件）估计大约为 13 亿美元。
- 他们并没有如实披露真正的 TCO（总体拥有成本）。

2. 💲 价格
- DeepSeek 最初的定价（约 $0.20/100 万 Token）远低于实际成本，基本上是以巨大亏损提供服务。
- 像 together-ai 这样以盈利为目标的公司，如果要托管该模型，其价格就被迫要高得多（约 $1.00/100 万 Token）。

3. 💡 质量
- 以更贴近成本的价格来看，该模型并没有那么突出。
- 它在相同价位下，与 openAI 的一些模型（例如 o1-mini）质量相当。
- 它并不比 o1 或 o3 更胜一筹。
- 当然，它仍然是目前市面上最好的模型之一，但并没有达到某种“巨大差距”的水平。

4. ⚡ 效率
- 虽然 DeepSeek 的 Mixture-of-Expert（专家混合）方法（其实并不新）确实减少了计算需求，
- 但模型本身的规模（需要多少参数存放在内存）其实极其庞大：仅实例化一次就需要大约 1 TB 的超高速内存。
- 很多人不知道：内存技术是现代 AI 系统成本的主要驱动力之一。
- 换言之，牺牲计算换取超大内存的模型，可能总花销反而更高。

🥜 总结一下
DeepSeek 只是另一个例子，说明 AI 正在逐渐成熟，大家也在不断探索各种方法来突破极限。我很高兴看到这一趋势。对于我们这种中立的 AI 推理硬件公司来说，任何能够推动 AI 大规模应用的进展都是好事。🙂

📈 未来依旧在早期阶段
AI 最终会在全球范围内带来从 100 万倍到 10 亿倍的计算需求增长，一旦未来的应用场景被充分挖掘，例如：
- 为每个人提供个性化教育/咨询服务
- AI 媒体内容的生成
- 工作场景中的 AI 助手或“数字分身”

可以预见，AI 的巨大潜力才刚刚开始被释放。



### 12

2025-02-01

歸藏(guizang.ai)
@op7418
有了 Anthropic CEO 嘴硬的回应看 Sam 也没那么离谱了

昨晚在 reddit 的 AMA 活动中 Sam 几个回应都还不错

 1. 承认是 R1 促使他们后面会展示模型更详细的思考过程

2. 另外承认在开源和非开源选择上站错了队，需要重新考虑他们的开源倾向



### 13

2025-02-01


歸藏(guizang.ai)
@op7418
OpenAI（Sam Altman、Mark Chen、Kevin Weil、Srinivas Narayanan、Michelle Pokrass 和 Hongyu Ren）在 Reddit AMA 中讨论内容的中文总结：

---

\### 模型更新和发布

- **o3-mini** 现已推出，具备推理能力和工具使用支持，包括网页搜索功能。
- 知识截止日期仍为 2023 年 10 月，但由于具备网页搜索功能，其重要性有所降低。
- 小型模型在工具、代理框架以及成本与性能权衡方面仍有显著提升空间。
- **o3 全版本** 预计将在“几周以上，几个月以内”发布。
- **o3-pro** 版本已确认即将推出，这意味着 ChatGPT Pro 将“非常值得升级”。
- **GPT-5**（非 GPT-5o）正在开发中，但未提供具体时间表。
- 4o 系列尚未完结，后续将有改进。
- 基于 GPT-4o 的图像生成与编辑功能仍在开发中，预计将在“大约几个月内”推出——“等待将是值得的”。
- DeepSeek 被认定为“非常优秀的模型”；OpenAI 预期将推出更好的模型，但领先优势不如以往年份明显。

---

\### 功能和能力

- **Operator** 将在“几个月内”加入 Plus 计划。
- 计算机的使用被视为长期 AGI 发展的关键部分。
- 更多代理（Agents）将在“非常非常快的时间内”推出。
- 计划很快展示更详细的思考 token 版本。
- 推理能力仍然是开发的“最关键部分”。
- 先进的语音模式更新即将推出，并计划将其与文本/画布交互集成。
- 规划为推理模型增加 PDF 支持和文件附件功能。
- **Vision** 能力将引入到 o3-mini（目前已在 o1 中可用）。
- 正在努力增加上下文长度，但未给出具体时间表。
- 正在开发与 o 系列模型整合记忆功能。
- 正在致力于将所有工具和模态统一到推理模型中。

---

\### 访问与定价

- 团队正在考虑如何展示剩余消息数，以免用户过于关注限制（目前没有进度条/计数器，以避免“稀缺效应”）。
- 正在致力于使 Assistants API “更易于使用”。
- 希望随着时间推移降低 Plus 级别的价格，目前没有涨价计划。
- Plus 用户每天可获得 150 条 o3-mini 消息以及每周 50 条 o3-mini-high 消息。
- Pro 用户可无限制使用 o3-mini-high。
- 正在 API 中测试欧盟数据驻留服务，以符合 GDPR 要求。

---

\### 未来发展重点与首要任务

- 提升多步函数调用的性能。
- 扩展长上下文能力。
- 将功能与 o 系列统一。
- 开发“更具代理性”的应用程序，以应对复杂、长时运行的任务。

---

\### 机器人技术

- 初步目标：“制作一批非常优秀的机器人，并从中学习”。
- 重点在于从初步部署中获得经验。
- 长远愿景包括让机器人在现实世界中执行有用任务。

---

\### 研究与开源

- 正在讨论潜在的模型权重及研究成果的发布。
- 内部对开源策略存在争议，Sam 认为当前的做法处于“历史的错误一边”。
- 过去曾开源过 GPT-2 和 Jukebox 模型，正在考虑更多的发布。

---

\### AGI 展望

- 快速起飞（Fast takeoff）的情景被认为“比…几年前更为可能”。
- 主要影响预计将是加速科学发现。
- 对未来交互的设想包括更多具备代理性的 AI 持续在后台工作。
- AGI 突破的主要关注领域将是治愈疾病和开发更廉价的能源。

---

\### 基础设施

- **Stargate 项目** 被描述为对 OpenAI 未来“非常重要”。
- 被视为将“算力/GPU 转化为卓越成果”的工厂。
- 对于在两个维度上扩展模型至关重要：更大的预训练模型和更多的 RL/Strawberry（强化学习相关技术）。


### 14

2025-02-01

歸藏(guizang.ai)
@op7418
Huggingface 这个 Open R1 的文章牛皮啊

整理了 Deepseek R1 发布到现在所有重要内容和社区工作

- 复现对于 R1 的评估分数
- 复现 R1 训练管道，比如 GRPO
- 合成数据生成流程，重现类似 R1 的推理数据集
- 市面上所有重要人物对于 R1 模型的表态
- 尝试复现 R1 的开源项目

[Open-R1: Update #1](https://huggingface.co/blog/open-r1/update-1)

### 15

2025-02-01

歸藏(guizang.ai)
@op7418
太顶了，期待有服务商可以支持
引用
karminski-牙医
@karminski3
·
2月1日
本地部署 DeepSeek-R1 支持 ToolCall 了！

昨天 llama.cpp 刚合并了一个新PR，终于让 DeepSeek-R1 支持 ToolCall了!

本地部署DeepSeek最后一个短板终于补上了，考虑到DeepSeek官方其实并没有Agent平台，所以本地部署的DeepSeek-R1反而变得更强了.

[1/2]
显示更多



### 16

2025-02-01


九原客
@9hills
杨立昆锐评某些硅谷公司（deepseek 翻译）
——

- 硅谷某些圈子中的一种常见病:一种错位的优越感。
- 晚期症状:认为自己的小团体垄断了好主意。
- 末期症状:认为来自他处的创新是通过欺骗手段获得的。

科技进步在更多有才华的人参与并*分享*他们的创新时发展得更快。

事实上,这就是原因:
- 科学界围绕出版物和工具共享进行组织
- 开发者社区围绕开源组织
- 专利制度存在(尽管对于软件和服务来说已经过时且适得其反):你可能会获得政府对发明使用的短期独占权,但作为交换,你必须披露足够的信息,以便他人能够复制并在其基础上进行构建。
引用
Yann LeCun

@ylecun
·
2月1日
A common disease in some Silicon Valley circles: a misplaced superiority complex.


### 17

2025-02-01

宝玉
@dotey
OpenAI CEO宣布开发AI设备 旨在实现iPhone以来最大革命

【硅谷=山田亮太郎】美国OpenAI公司首席执行官山姆·奥特曼在接受《日本经济新闻》采访时宣布，该公司将开始开发专用于生成式AI（人工智能）的设备，以取代智能手机。他还表达了对开发自己的半导体的热情。该公司将人工智能的普及视为变革IT行业的机遇，旨在引发自2007年推出iPhone以来约20年来数字设备的首次革命。

奥尔特曼定于3日在首相官邸与石破茂首相会面……




### 18

2025-02-03


宝玉
@dotey
OpenAI 全新“Deep Research”重磅发布：让 ChatGPT 帮你完成多步骤深度研究

在这个信息爆炸的时代，如何用最短的时间获取最精准、最详实的信息，一直是许多知识工作者面临的难题。如今，OpenAI 带来了全新的 Deep Research 功能，让你的 ChatGPT 化身为一位“研究助理”，能够独立查找、分析并综合海量网络信息，为你提供专业且有完整参考的研究报告。下面，让我们来一起了解这项强大的新功能吧！

Deep Research 能做什么？

1. 多步骤研究
相比传统的聊天式问答，Deep Research 具备强大的自主研究能力。它能够从互联网上寻找并分析数百个来源，根据实时获取的信息进行动态调整和推理。短短几十分钟内，它能完成人工需要数小时才能完成的研究工作。
2. 自动化汇总海量信息
你只需要输入研究需求，ChatGPT（在 Deep Research 模式下）就会自动去浏览海量网页、PDF、图片等信息资源，并将它们整合成一份清晰、有理有据的分析报告，犹如一位具有专业分析能力的研究员。
3. 详尽引用与文献记录
Deep Research 每一个输出都附有引用来源，并在侧边栏展示搜索、分析过程，方便你查看、验证信息。同时也提供思路概述，保证研究过程的透明度与可追溯性。
4. 个性化、多场景适用
无论你是做金融、科学、政策、工程等领域的深度研究，还是想为购物（例如汽车、家电或家具等大件商品）做细致比对，Deep Research 都能胜任。它还擅长挖掘各类小众且不直观的信息，只需一次查询，就能节省你大量的时间和精力。

为什么它如此重要？

1. 效率大幅提升
普通用户在网络上搜集信息可能需要自己筛选资料、反复验证。Deep Research 通过自动化的搜寻和分析，大幅缩短研究时间，让你把更多精力放在思考与决策上。
2. 减少重复劳动
Deep Research 擅长处理那些需要浏览无数个网页、文件的繁琐任务。比如撰写报告、整理数据、查找论文资料、对比不同产品参数等。以前这些工作往往让人头疼，现在只需一次提问，就能得到系统、条理化的研究成果。
3. 助力专业领域
该功能在化学、人文社科、数学等众多专业领域都表现出色，尤其在需要检索专业文献、综合多方信息的复杂任务中，让研究人员更轻松、更高效。
4. 迈向真正的“通用人工智能”
OpenAI 一直致力于开发具备创造全新知识能力的通用人工智能（AGI）。Deep Research 作为其新里程碑，进一步展现了 AI 在多领域多模态研究中的潜力，为未来更先进的 AI 系统奠定了基础。

如何使用 Deep Research？

1. 选择 Deep Research 模式
在 ChatGPT 界面中，找到消息输入区域的模式选项，选择“Deep Research”。然后在对话框输入你的研究需求。
2. 附加背景文件/数据
如果你有特定的文件、电子表格或参考资料，也可以上传给 Deep Research。它会结合这些材料，为你做更有针对性的深度分析。
3. 查看研究过程与报告
当 Deep Research 开始运行后，聊天界面会出现一个侧边栏，展示它搜索到的来源以及每一步的推理过程，让你随时掌握研究进展。
一般它会花 5～30 分钟进行深度研究，然后返回一份完整的报告，附带详细引用。如果任务很耗时，你也可以先去忙别的事，等它研究完成再回来查看结果。
4. 报告输出形式
初始版本以文字报告为主，在接下来几周内，Deep Research 将支持在报告中插入图片、数据可视化图表以及其他分析产出，让研究结果更加直观、生动。

技术原理与表现
1. 强化学习驱动
Deep Research 通过端到端强化学习训练，掌握了如何在复杂的网络环境中进行多步搜索和推理，遇到新情况时也能灵活应对。
2. 新的评测成绩
• 在 Humanity’s Last Exam 测试中，为 Deep Research 提供支持的模型取得了 26.6% 的准确率，远超上一代模型的表现。
• 在 GAIA 基准上，它也刷新了排行榜记录，证明了在多模态理解和使用工具（如浏览器、Python）等方面更具突破性。
3. 专业领域的进一步提升
一些专业人士反馈，使用 Deep Research 可以在短时间内完成原本需要数小时的调查工作，无论是找文献还是分析数据，效率提升显著。

注意事项及局限性
1. 依然存在幻觉或错误推断
虽然 Deep Research 生成“错误事实”或逻辑漏洞的概率比现有 ChatGPT 模型更低，但仍有可能出现。用户在使用时应保持警惕，尤其在严谨的学术或商业环境下，要对关键信息进行交叉验证。
2. 区分谣言与权威信息的能力有限
模型仍然可能对信息来源缺乏足够判断力，需要用户根据实际情况和专业常识来判断信息的可信度。
3. 报告格式与耗时
首批上线版本可能会出现小规模的格式问题或引用异常，研究任务也可能因为深度搜索而启动较慢。官方表示，会随着使用量的增加和时间的推移迅速改进这些问题。

谁能访问 Deep Research？

1. Pro 用户率先上线
目前 Deep Research 首先向 ChatGPT Pro 用户开放，每月可使用高达 100 个查询额度。
2. 逐步覆盖更多付费用户
之后会依次向 Plus 和 Team 用户开放，随后是企业版。OpenAI 也在努力面向英国、瑞士以及欧洲经济区的用户开放访问权限。
3. 进一步的扩容
OpenAI 计划推出一个使用更小模型、速度更快且成本更低的 Deep Research 版本，届时所有付费用户都会有更高的调用额度。

后续计划

1. 更广泛的平台支持
Deep Research 目前仅在 ChatGPT 网页端上线，官方将在未来一个月内把这项功能带到移动端与桌面端。
2. 接入更多数据源
不仅能访问互联网的公开信息和用户上传的文件，今后还会扩展到订阅或内网资源，让报告更具深度与个性化。
3. 与其他代理能力融合
OpenAI 正在开发的 Operator 功能，能够在现实世界中执行任务。当 Operator 与 Deep Research 结合，ChatGPT 将可以自主进行更复杂的在线与线下任务，为用户提供更全面的“智能助理”体验。

Deep Research 的到来，让我们看到了一个可以代替人工执行复杂、多步骤研究任务的 AI 时代正逐渐变成现实。无论你是需要大量文献支撑的研究工作者，还是想要做精细购物决策的普通用户，都能借助这个工具大幅提升效率。它不仅代表着 ChatGPT 的新能力，也标志着人类向更高水平的通用人工智能迈出了重要一步。对知识工作者来说，这将是一股全新的生产力，也是人工智能赋能未来的又一有力见证。

想要率先体验 Deep Research 的朋友，如果你是 ChatGPT Pro 用户，不妨立刻去试试看；如果尚未获得资格，也可以继续关注官方更新，相信不久后就有机会亲自感受这项强大的功能啦！



### 19

2025-02-03

小互
@imxiaohu
奥特曼在接受《日本经济新闻》采访时表示，OpenAI正着手开发一种取代智能手机的 AI 专用设备，彻底改变人机交互方式，并且有意自主研发专用芯片。

该设备由苹果前苹果设计师Johy Ive和他现在的工作室负责设计！

奥特曼认为，人工智能的普及将带来信息技术产业的重大变革，并希望推动 自 2007 年 iPhone 诞生以来最重大的数字设备创新。

奥特曼称：AI 设备将重新定义人与计算机的交互方式。

奥特曼强调，AI 需要新的交互设备，而语音操作将成为关键。

• Apple 通过 iPhone 引入触控操作，彻底改变了用户界面（UI）

• OpenAI 计划 以语音为核心，探索适合 AI 时代的新 UI 设计。

2 月 3 日，奥特曼、孙正义与日本首相石破茂在首相官邸会面，探讨合作可能性。可能寻求日本市场和政府的合作，共同推动 AI 发展。




### 20

2025-02-03


宝玉
@dotey
今天，OpenAI 推出了一款能够独立为您完成工作的新智能体——深度研究（Deep Research）。

只需提供一个提示，ChatGPT 就能在短短几十分钟内完成对数百个在线资源的查找、分析和综合，生成一份详尽的报告，而这通常需要人类花费数小时甚至更长时间才能完成。深度研究由经过优化的 OpenAI o3 版本提供支持，结合网络浏览和 Python 分析能力，能够通过推理智能、高效地浏览互联网上的文本、图像和 PDF 文件。

深度研究的核心功能

这个智能体通过推理整合大量在线信息，帮助您完成多步骤的研究任务。目前已向 Pro 用户开放，接下来会向 Plus 和 Team 用户逐步推出。

推动性能突破
驱动深度研究的模型在多个关注现实问题的公开评估中表现优异，包括“人类最后的考试”（Humanity's Last Exam）。

适用场景广泛
深度研究专为那些在金融、科学、政策、工程等领域从事高强度知识工作的专业人士而设计，他们需要可靠、全面的研究成果。此外，这款工具也非常适合需要个性化推荐的购物者，用于深入研究大额或复杂的购买决策。

逐步推出计划
深度研究今天起向 Pro 用户推出，接下来会扩展到 Plus 和 Team 用户，最终覆盖企业用户。
引用
OpenAI
@OpenAI
·
2月3日
回复 @OpenAI
Powered by a version of OpenAI o3 optimized for web browsing and python analysis, deep research uses reasoning to intelligently and extensively browse text, images, and PDFs across the internet. https://openai.com/index/introducing-deep-research/


### 21

2025-02-03

宝玉
@dotey
有关 AI 编程，我觉得近期最值得看的一篇文章和视频都来自 Addy Osmani

《AI 辅助编码的残酷真相：它能帮你完成70%的工作，但最后30%令人非常沮丧》

今天终于抽空把视频给翻译了一下，见评论
上午6:42 · 2025年2月3日
·
11万
 查看

宝玉
@dotey
·
2月3日
The 70% problem: Hard truths about AI-assisted coding

原文：https://addyo.substack.com/p/the-70-problem-hard-truths-about

翻译：https://mp.weixin.qq.com/s/ZQA8quhAEwUUsT2p_IjG0g?token=1639803888&lang=zh_CN



### 22

2025-02-03


宝玉
@dotey
梁文锋深度采访（一）

主持人：为什么DeepSeek会让硅谷的很多人惊讶？

梁文锋：在美国每天发生的大量创新里，这是非常普通的一个，他们之所以惊讶是因为这是一个中国公司，在以创新贡献者的身份加入到他们游戏里去。毕竟大部分中国公司习惯follow，而不是创新。

主持人：但这种选择放在中国语境里也过于奢侈了，大模型是一个重投入游戏，不是所有公司都有资本只去研究创新，而不是先考虑商业化。

梁文锋：创新的成本肯定不低，过去那种拿来主义的惯性也和过去的国情有关，但现在你看无论中国的经济体量，还是字节腾讯这些大厂的利润，放在全球都不低。我们创新缺的肯定不是资本，而是缺乏信心，以及不知道怎么组织高密度的人才实现有效的创新。

主持人：为什么中国公司，包括不缺钱的大厂，这么容易把快速商业化当第一要义？

梁文锋：过去30年我们都只强调赚钱，对创新是忽视的，创新不完全是商业驱动的，还需要好奇心和创造欲。我们只是被过去那种惯性束缚了，但它也是阶段性的。

主持人：但你们究竟是一个商业组织，而非一个公益科研机构，选择创新又通过开源分享出去，那要在哪里形成护城河？

梁文锋：在颠覆性的技术面前，闭源形成的护城河是短暂的，即使OpenAI闭源也无法阻止被别人赶超，所以我们把价值沉淀在团队上。我们的同事在这个过程中得到成长，积累很多know-how，形成可以创新的组织和文化，就是我们的护城河。开源、发论文其实并没有失去什么，对于技术人员来说，被follow是很有成就感的事。其实开源更像一个文化行为，而非商业行为，给予其实是一种额外的荣誉。一个公司这么做也会有文化的吸引力。

主持人：你怎么看类似朱啸虎的这种市场信仰派观点？

梁文锋：朱啸虎是质朴的，但他的打法更适合快速赚钱的公司。你看美国最赚钱的公司都是厚积薄发的高科技公司。

主持人：但做大模型，单纯的技术领先也很难形成绝对优势，你们赌的那个更大的东西是什么？

梁文锋：我们看到的是中国AI Scene可能永远处在跟随的位置。我们经常说中国AI和美国有一两年差距，但真实的Gap是原创和模仿之差。如果这个不改变，中国永远只能是追随者，所以有些探索也是逃不掉的，因为达到领先不只是一个公司的努力，而是整个西方技术社区和产业共同努力的结果。他们能看到下一代的技术趋势，手里有路线图，中国AI的发展同样需要这样的生态。很多国产芯片发展不起来也是因为缺乏配套的技术社区，只有二手消息，所以中国必然需要有人站到技术的前沿。

主持人：海外认为DeepSeek雇佣了一批高深莫测的奇才，那做出DeepSeek的是怎样一群人？

梁文锋：并没有什么高深莫测的奇才，都是一些top高校的应届毕业生，没毕业的博士博五实习生，还有一些毕业才几年的年轻人。

主持人：很多大模型公司都执着地区海外挖人，很多人觉得这个领域前50名的顶尖人才可能都不在中国公司，你们的人才都来自哪里？

梁文锋：不要模型，没有海外回来的人，都是本土的前50名顶尖人才可能不在中国，但也许我们能自己打造这样的人。

主持人：听说你们很擅长从细节招人，AI让一些非传统评价指标里优秀的人被选出来。

梁文锋：我们选人的标准一直都是热爱和好奇心，所以很多人会有一些奇特的经历，很有意思。很多人对做研究的渴望远超对钱的在意。

主持人：这种发散性敏感的人才和你们完全创新型组织的架构很有关系，但AGI这种充满不确定性的前沿探索，是否多了管理动作？DeepSeek也全是自下而上？

梁文锋：而且我们一般不强制分工，而是自然分工，每个人有自己独特的成长经历，都是自带想法的，不需要push他，探索过程中他遇到问题自己就会拉人讨论，不过当一个idea显示出潜力，我们也会自上而下去调配资源。

主持人：创新很大程度也是一种偶然吗？

梁文锋：我觉得创新首先是一个信念问题，为什么硅谷那么有创新精神，首先是敢。ChatGPT出来时，整个国内对做前沿创新都缺乏信心，从投资人到大厂都觉得差距太大了，还是做应用吧。但创新首先需要自信，这种信心通常在年轻人身上更明显。

主持人：大部分中国公司都选择既要模型又要应用，为什么DeepSeek目前选择只做研究探索？

梁文锋：因为我们觉得现在最重要的是参与到全球创新的浪潮里去，过去很多年中国公司习惯了别人做技术创新，我们拿过来做应用变现。但这并非是一种理所当然，这波浪潮里，我们的出发点就不是趁机赚一笔，而是走到技术的前沿去推动整个生态发展。

主持人：你觉得创新很大程度也是一种偶然吗？

梁文锋：我觉得创新首先是一个信念问题，为什么硅谷那么有创新精神，首先是敢。ChatGPT出来时，整个国内对做前沿创新都缺乏信心，从投资人到大厂都觉得差距太大了，还是做应用吧。但创新首先需要自信，这种信心通常在年轻人身上更明显。

主持人：现在经济开始进入下行，资本也进入轮周期，所以它对原始创新是否会带来更多抑制？

梁文锋：我倒觉得未必，中国产业结构的调整会更依赖硬核技术的创新。当很多人发现过去赚快钱很可能来自时代运气，就会更愿意俯身去做真正的创新。

主持人：技术真的可以拉开差距吗？你也说过并不存在绝对的技术秘密。

梁文锋：技术没有秘密，但复制需要时间和成本。英伟达的显卡理论上没有任何技术秘密，很容易复制。但重新组织团队以及追赶下一代技术都需要时间，所以实际的护城河还是很宽。

主持人：互联网和移动互联网时代留给大部分人的惯性认知是，美国擅长搞技术创新，中国更擅长做应用。

梁文锋：我们认为随着经济发展，中国也要逐步成为贡献者，而不是一直搭便车。过去30多年IT浪潮里，我们基本没有参与到真正的技术创新里，我们已经习惯摩尔定律从天而降。躺在家里18个月就会出来更好的硬件和软件，但其实这是西方主导的技术社区一代代孜孜不倦创造出来的。只因为之前我们没有参与这个过程，以至于忽视了它的存在。

主持人：你对国内原始创新也是乐观的吗？

梁文锋：我是80年代在广东一个五线城市长大的，我的父亲是小学老师。90年代广东赚钱机会很多，当时有不少家长到我家来，基本就是家长觉得读书没用，但现在回去看，观念都变了，因为钱不好赚了，连开出租车的机会可能都没了。一代人的时间就变了，以后硬核创新会越来越多，现在可能还 不容易被理解是因为整个社会群体需要被事实教育。当这个社会让硬核创新的人功成名就，群体性想法就会改变。我们只是还需要一堆事实和一个过程。
上午6:08 · 2025年2月3日
·
8.5万
 查看

宝玉
@dotey
·
2月3日
来源：https://m.weibo.cn/detail/5129157966823476



### 23

2025-02-03

宝玉
@dotey
罗福莉（福莉），出生于四川农村的“95后AI天才少女”，现任DeepSeek公司深度学习研究员，是国产大模型DeepSeek-V2的核心开发者之一。她本科毕业于北京师范大学计算机专业，硕士保送至北京大学计算语言学专业，师从万小军教授，期间在国际顶级会议ACL上发表8篇论文（含2篇一作），奠定了其在自然语言处理（NLP）领域的学术声誉。职业生涯始于阿里巴巴达摩院，主导开发了多语言预训练模型VECO，推动AliceMind项目开源；2022年加入DeepSeek后，参与研发了MoE架构大模型DeepSeek-V2，该模型以“中文能力第一梯队”和超高性价比（1元/百万Tokens）成为行业焦点。  

2024年底，网传小米创始人雷军以千万年薪邀请其领导AI大模型团队，但截至2025年2月，罗福莉仍通过高中班主任回应“暂未决定”，其知乎认证信息显示为DeepSeek员工。分析认为，她的选择或反映对技术深耕与产业使命的权衡：DeepSeek正处“与国运共振”的上升期，而小米的邀约则凸显行业对顶尖人才的争夺。  

罗福莉的成长轨迹融合了个人奋斗与时代机遇。她以“农村女孩”身份突破性别与资源限制，成为AI领域标杆人物，既印证“知识改变命运”的普世价值，亦展现中国AI产业崛起中青年科学家的关键角色。其职业路径的选择，不仅是个人发展问题，更折射出国产AI技术生态中企业与人才协同创新的深层命题。

罗福莉在采访中回顾了自己从农村到顶尖AI开发者的逆袭之路。她出身贫寒，父母曾质疑“女生学计算机是否适合”，但她以“探索更多可能性”的决心打破桎梏。在北师大转专业至计算机后，她通过提前规划与贵人指引（如北大导师万小军），以“目标拆解+死磕精神”实现学术突破：大三自学Python并投出首篇顶会论文，硕士期间以“博士生标准”产出20余篇顶会论文，成为业内瞩目的“ACL8篇作者”。  

她坦言职业选择中的试错与坚持：曾短暂尝试产品经理方向，但最终回归技术研究，并先后加入阿里达摩院、幻方量化及DeepSeek。在DeepSeek期间，她深度参与模型研发，强调团队“技术驱动”特质，并公开评价DeepSeek-V2为“性价比之王”。



### 24

2025-02-03

FallMonkey
@FallMonkey
@teortaxesTex
 很早就很坚定看好幻方，但是西方友人能这么深刻分析，实在令人惊叹。不才翻译一下，可以的话还是请阅读堪称优雅的原文。

DeepSeek：现代中国文化亚稳态的一个缩影

作者：DeepSeek-R1，Teortaxes
译者：DeepSeek-R1，O1-Pro，FallMonkey

刻板印象：宛如被环境凝固的万花筒

国家层面的刻板印象，往往是在某些“反应型特征”的维度上不断累积，再因路径依赖而定型。“稻米理论”所揭示的东亚心理（即将密集型农业与规避风险、从众服从，以及“勤能补拙”的行事风格相关联）并非无中生有或纯粹的东方主义偏见。研究（如 Talhelm 等人，2014）表明，中国南方的水稻种植区与北方的小麦种植区居民在认知方式上确有可测量的差异：南方人更倾向于整体思维和社会协作。这些特质的形成源于古代生存策略：在一块块历经千年耕耘、几乎寸土寸金的土地上，冒进式的尝试可能酿成饥荒，而细致入微的优化却能带来稳定。

然而，刻板印象不等同于宿命，它只是与文化及环境刺激相互演化后产生的一种策略性倾向，而非某种不可改变的本质。环境参数一旦更易，文明血脉自会孕育全新心智。如今，中国 AI 实验室“DeepSeek”正以实际成果对全球创新做出可量化的贡献，恰恰彰显了这份潜在的可塑性。他们的突破（从开源模型震撼硅谷"自由派"大佬、迫使后者向政府寻求庇护，到对 Transformer 架构的全新构思）都在质疑“快速跟跑者”的陈词滥调。似乎，中国人从来不乏创造力，只是过去在推演中将其视为"不经济"的选择罢了。

西方的“开拓”神话

西方神话很排斥那种“筑起高墙的中原王国”景象，而推崇从哥伦布到 SpaceX 一脉相承的“探险精神”——这也是其独特历史轨迹的遗产。欧洲曾因黑死病人口骤减，留下大片未被充分利用的土地和机遇；而美国的西部"边疆"直到 1890 年才被宣告“终结”。反观中国，长江三角洲的人口承载力在宋代就已近乎极限，比西方早了整整千年。创新的方向因此倾向于“在有限土地上提高产量”，而非“寻找新的地平线”。水力磨坊虽有改进，却没出现蒸汽机；赋税体系日益精细，却未孕育真正的科学革命。即便在国家最高层，明朝郑和下西洋虽然宏大，却最终被视为奢华但成本高昂的工程，未能催生后续“殖民时代”，反而回归了以往的惯性。

这并不意味着缺乏某种“神性绽现”（Divine Spark），而更像是针对当时社会条件的理性资源配置——在高人口密度的社会，“存量智慧”（通过已知方式深入挖掘资源）比冒险式创新更划算。中国历史上鲜少出现激进型创新者，实可视为一种社会的纳什均衡：当所有人都选择求稳，那个“冒险者”往往要承受极不成比例的风险或惩罚。这也解释了为何东亚地区平均智商测验成绩更高，中国学生在 IMO（国际数学奥赛）上更具统治力，但长期以来却罕有诺奖或菲尔兹奖得主。原因不在于“认知能力”本身，而是文化激励不同：只有在社会愿意为探索冒险买单时，创造力才会蓬勃。

讽刺的是，西方如今正在快速复制这一轨迹。那些早先设计出来的 IQ 测试，本身就诞生于工业化时代，旨在选拔并奖励“利用性”技能（如在标准化教育和流水线思维中锻炼出的密集型问题解决、在有限规则里找出模式的能力）——这些能力对“水稻社会”至关重要。然而，要开拓真正最后的边疆，如硅谷及其少量“翻版”，仍需要足够的胆识去探索未知领域。但也许这一次，东方同样能从这种“边疆”中收获红利。

DeepSeek：孕育相变的种子

DeepSeek 创始人梁文峰，正从根本上挑战中国“创新均衡”现状。他的行动方案在商业策略层面已然独树一帜，但更引人注目的是，它还可被视为一个大型“范式转移”的原型，对导致系统性风险规避的先验因素进行了精确定位。

• 开源至上
在一片被 NDA（保密协议）笼罩、前沿研究难见天日的时代，DeepSeek 选择公开发布最先进的模型和技术报告，将“原创”从高风险的赌博变成一种“地位竞赛”，并因此获得了学术界难以企及的真实权威。对贡献者而言，这等于是让他们在全球范围内积累声望。“给予本身就是一种荣耀”，梁文峰如是说。DeepSeek 因此成了中国顶尖人才趋之若鹜的“绿洲”。

• 唯才是举
无论是文学专业背景还是信息学奥赛冠军，都能在公司内部自由探索研究方向，无需经过层层审批，而是各自协调，近似于硅谷式的“混沌精英制”。

• 后勤充沛
自招聘起就宣传的充沛算力池，与绿灯常亮的扁平组织架构，都试图构建出一个轻松的前沿探索环境——毕竟所有的挑战都聚焦在待解决的终极难题上。

• 杜绝内耗
前员工曾透露，DeepSeek 力图避免“螃蟹互扯后腿”的内耗，而这种内耗在某些大厂（如百度）并不少见。在 DeepSeek，成员身处压力更小、氛围更和谐的环境，有助于集中火力冲击外部竞争与更高难度的技术目标。

这一系列举措正在打破刻板印象，也在西方创新中心引发困惑与反思。DeepSeek 提出的多头潜变量注意力（MLA）架构，将 Transformer 的内存开销降低了 87% 到 95%，而此前业界对超越多头注意力（MHA）到单头注意力（MQA）优化的帕累托边界信心不足，更遑论在生产环境大规模实践。现在，西方实验室纷纷引入 DeepSeek 最佳实践，颠覆了以往默认的“创新顺序”。他们在前沿开源模型方面的布局，重塑了整个大型语言模型（LLM）推理的市场格局；他们的 R1-Zero "重磅炸弹"则让强化学习（RL）再现生机。媒体也看到了这层反讽——《金融时报》戏谑地指出：“至少目前看来，这是一个‘中国创新，美国模仿’的逆转场景。”

梁文峰正在押注（且已部分赢得注脚）的是，DeepSeek 能在中国“创新-模仿”的谢林点（博弈论中人们在没有沟通的情况下的选择倾向）上动摇现有均势，具体而言:

1. 证明探索回报
可观利润加上全球声誉，让那些高远目标的“天马行空式科研”看起来不再是空耗。我们已见 Minimax 开始模仿 DeepSeek 的开源策略，甚至连论文发布模式都如出一辙。

2. 创造外溢效应
基于 DeepSeek 开源技术的初创公司，可将更多研发资金投向其他创新方向。他们的混合专家（MoE）设计也逐渐成为国内 AI 公司在大规模模型架构上的事实标准。

3. 重塑人才市场
顶尖人才如今更乐于将基础 AI 乃至 AGI（通用人工智能）研发视为真正可行的职业道路，而非相对于传统高薪行业的“堂吉诃德式”浪漫尝试。这股风潮正在形成，即便并非单靠 DeepSeek 一家之力推动。

当然，阻力犹存。中国风投界一贯偏好对成熟模式套利（如复制 Uber 或 Airbnb），对高风险研发则显退缩。即便是雄心勃勃的 DeepSeek，也只能在明显有限得多的资金下勉强运转。梁文峰早期几次融资尝试，都只迎来悲观怀疑。他曾指出：“我们经济总量不低，大公司如字节、腾讯利润也不低。但为何不创新？不是没钱，而是没信心，不知如何将高密度人才组织起来，做出真正有效的创新。”解决方案很多，但最终能否凝结成真正成果，仍是未知数。

用一个比喻难以涵盖全部。系统性转变需要的绝非某个概念验证就能达成。从以高考为中心的教育体系，到企业的层级管理制度，中国主流机制依然更倾向于鼓励从众与渐进式思维。梁文峰的项目，会否复制日本二战后从"粗制滥造"到丰田生产体系与半导体问鼎世界的华丽转身？也许有可能，但也需制度配合……或者最终难免归于更宏大的历史惯性。

好戏才刚上场

DeepSeek 告诉我们，文化特质并非一成不变的剧本，而更像是一种随环境演变而变化的均衡态。中国历史上以风险规避为主的“存量智慧”思路，在人口稠密、资源相对紧张的社会里曾合乎逻辑。但如今，随着庞大资本与海量受过高等教育的人才不断涌现，这套模式却因惯性而迟迟无法切换，让原本大好的“视界”未被开发。

梁文峰能否成功推行他的“根本性去风险化”（meta derisking），取决于 DeepSeek 能否如他所设想的那样，催生更广泛的生态系统——一个激励良性循环的“飞轮”，而非只是依赖大数据或算力的堆积。一燕非春，犹觉寒消；一叶知秋，可窥岁暮。要让中国真正摘掉“快速跟随者”的帽子，需要让各种制度对“高热度天才”提供同等甚至更高水平的激励，就像当年水稻社会对耐心与严谨的褒奖一样。换言之，这需要

• 改造教育体系，让好奇心被更多鼓励，而非只注重刷题熟练度;

• 引导资本更多投向高风险、高回报的“登月计划”，而非简单的“套利模式”；

• 鼓励投资人像硅谷那样看待失败，将失败视为一种数据和经验，而非耻辱。

究竟 DeepSeek 会只是昙花一现的特例，还是会成为“中国特色成功企业”的新样板？答案恐怕不只取决于梁文峰个人执行力，更取决于这个风险规避体系能否挣脱数百年来为求生存而深深镌刻的本能。如果有朝一日真能做到，这些刻板印象也将不再具有现实意义——并非它们一开始就有错，而是它们所赖以存在的环境条件已不复存在。万花筒终将带来新的视界。

全世界都在密切而又带着几分敌意的心态观察这一实验。比起 Meta那些“作战室”的威胁，美国政府若想“截胡”这股崭新的中国人才与技术动能，或许更值得警惕；但最大变数仍可能来自中国自身。或许真正的“最后边疆”并不在于能否将运载火箭成本降到最低，也不在于能否通过推理算力堆积来达到 AGI 级别，而是要把一个文明的集体思维从旧有均衡状态中唤醒，让它去适配当下与未来的需求。



### 25

2025-02-03


宝玉
@dotey
o1 pro 写代码不像你本地用 Cursor 等 AI 编辑器，编辑器会帮你提取相关代码和文档，它完全不知道你本地代码，需要提供完整的代码作为参考，所以建议配合 Repo Prompt 这样的 App，选中所有你要参考的代码，复制粘贴所有相关文档，但是要控制好长度，一般不超过10k Tokens 为佳。



### 26

2025-02-03

宝玉
@dotey
让 Deep Research 提供 SEO 建议

User:

我想为 http://aitalk.im 创建更多文章内容做SEO，请给出指导意见

ChatGPT:

你希望SEO优化的文章内容涵盖哪些主题？例如：AI对话技术、聊天机器人、自然语言处理、AI在不同行业的应用等。

此外，你的目标关键词是什么？你希望这些文章以何种形式呈现，例如深度技术解析、用户指南、行业趋势分析、案例研究等？

最后，你是否有具体的SEO目标，例如提高某些关键词的排名、增加有机流量、提升网站权威性等？

User:

文章内容涵盖AI 在英语，法语， 日语等外语学习方面的应用； 目标关键词还没有规划； 希望文章以用户指南， 案例研究的形式呈现； SEO 的目标是增加有机流量；

ChatGPT:

明白了！我将研究如何优化 http://aitalk.im 的SEO内容，专注于 AI 在英语、法语、日语等外语学习方面的应用。研究将包括：

• 适合你网站的高流量目标关键词建议
• 文章内容规划，包括用户指南和案例研究
• 具体的SEO优化策略，帮助提升网站的有机流量
• 竞争对手分析，借鉴成功网站的策略
我会尽快整理出可行的建议并与你分享！
上午9:24 · 2025年2月4日
·
6,174
 查看

宝玉
@dotey
·
2月4日
报告：https://mp.weixin.qq.com/s/bKHz1EnRw61metnfjAOm3A?token=1639803888&lang=zh_CN
消息历史：https://chatgpt.com/share/67a16a5a-f7e8-800f-8107-e7f00bc029e2



### 27

2025-02-04

宝玉
@dotey
问：ChatGPT 输入框的 Deep research 和 Search 有什么区别？

答：Deep research 和 Search 都会用到外部搜索，差别是在于：
1. 背后模型不一样，一个是 4o 一个是 o3；
2. 推理程度不一样，Search 没有推理，只有基本信息搜集汇总；Deep research 会花上几分钟甚至几十分钟对检索出来的资料筛选、过滤、提取；
3. 上下文窗口长度不一样，4o 只有 32k，o3 还不知道，但至少有 128K，可以输出很长的内容
4. Search 是同步流式返回结果，几乎不用等待；Deap research 是异步的，输入完任务你需要等一会
5. Deep research 会有一个对问题的确认环节，在你向Deep research发出请求后，Deep research 会追问你，让你提供一些可能重要的问题，防止缺乏上下文而做出错误的答复




### 28

2025-02-04

宝玉
@dotey
也许以后报考大学和专业不用找张雪峰了，试试让 Deep Research 让你选学校和专业

User:

有个朋友的孩子今年同时被UIUC的数学专业和东北大学的CS+物理专业录取了，请帮助他们分析应该选哪个？

ChatGPT:

请提供以下信息，以便进行更准确的分析：

1. 个人兴趣和职业规划：这个孩子更喜欢数学、计算机科学还是物理？未来是想从事研究、工程、数据科学、金融等哪方面的工作？
2. 课程和资源：是否更倾向于理论学习（数学）还是实际应用（计算机+物理）？
3. 经济因素：两个学校的学费、奖学金或经济援助情况如何？
4. 地理和校园文化：更喜欢伊利诺伊大学香槟分校（UIUC）的大型公立学校氛围，还是东北大学（Northeastern University）在波士顿的城市环境？
5. 实习和就业机会：东北大学的合作教育（Co-op）项目提供很强的就业优势，而UIUC的数学系在学术界和部分行业（如金融）有很强的声誉。是否有更倾向的就业路径？
6. 研究机会：是否有兴趣在本科期间参与研究项目？两个学校在相关专业的研究机会如何？
请提供以上信息，以便做出更合理的比较。

User:

1. 孩子偏好计算机，但也对数学和物理也比较擅长
2. 偏实践
3. 经济情况一般
4. 地理位置偏向UIUC
5. 更倾向就业
6. 有兴趣参与研究项目，不清楚各自研究机会如何
ChatGPT:

我会比较UIUC的数学专业与东北大学的CS+物理专业，重点考虑：

• 实践导向的课程和资源
• 就业前景及相关行业需求
• 研究机会和本科生参与度
• 经济负担（学费、助学金、潜在薪资回报）
• 地理和校园文化，尽管偏向UIUC但仍需对比两者的实际影响
我会尽快整理分析结果，帮助做出更明智的选择。

Research completed in 5m · 12 sources




### 29

2025-02-04

宝玉
@dotey
用 Deep Research 做竞品分析还不错，省很多事

User:

我想开发一款字幕翻译的软件，请帮我找出排名的竞争对手的信息，以及目前主流的技术实现

ChatGPT:

请提供更多细节，以便更好地进行研究：

1. 目标市场：您关注的是全球市场，还是特定国家/地区？
2. 主要功能：除了字幕翻译，是否包含自动生成字幕、语音识别、OCR等功能？
3. 技术方向：您对基于AI（如深度学习、机器翻译）、传统规则翻译，还是混合模式更感兴趣？
4. 竞品分析：您希望获取竞争对手的哪些具体信息？（例如市场份额、定价、主要功能、用户评价等）
5. 平台需求：软件是面向PC端、移动端，还是基于Web的SaaS服务？
请告诉我您的具体需求，以便进行更精准的研究。

User:

1. 全球市场
2. 聚焦于字幕翻译
3. 基于 LLM
4. 用户喜欢的和觉得不足的
5. 主要是Web和Mac平台
好的，我将研究全球市场中基于 LLM（大语言模型）的字幕翻译软件的主要竞争对手，并分析其市场表现。重点关注Web和Mac平台上的相关产品，并收集用户对这些软件的好评和不足之处。此外，我还会探索当前主流的技术实现方式，包括模型架构、API方案、训练方法等。

完成后，我会向您提供详细的报告。

Research completed in 7m · 19 sources



### 30

2025-02-04

宝玉
@dotey
对于写代码的、学术的、文字工作的，只要使劲用，o1 pro就是很有价值的，而且目前还没替代品
引用
独立开发者William
@DLKFZWilliam2
·
2月3日
回复 @DLKFZWilliam2
今天一天重度使用chatgpt pro。 结论：非常值得。 亮点主要在1. deep research功能。 他能做到全网信息的获取并写研报。 非常非常非常值。就这一点完全值得。 2. o1在专业领域很不错，context windows非常够用，几乎接近专家水平。 3. 代码层面物理与数学的复杂建模效果更好，非常适合游戏项目。



### 31

2025-02-04


宝玉
@dotey
让 Deep Research 给我写的报告：AI对软件工程的影响：编程、DevOps与敏捷开发

宝玉:
请帮我调研一下AI对于软件工程的影响，以及未来的预测，优先选择英文资料，最终形成中文报告
ChatGPT:

请确认以下几点，以便进行更详细的调研：

• 你是否希望涵盖所有AI对软件工程的影响，还是更关注某些特定领域（如代码自动生成、软件测试、运维等）？
• 你希望研究的时间范围是近期影响（如过去5年），还是包含未来长期预测（如未来10-20年）？
• 你对技术深度的要求是面向一般读者的概述，还是面向专业人士的深入分析？
• 你是否有特定的AI技术（如GPT-4、Copilot、自动化测试工具等）或软件工程方法（如DevOps、敏捷开发等）希望重点关注？

请提供更多细节，以确保报告符合你的需求！

宝玉:

• 所有AI对软件工程的影响
• 未来5-10年
• 专业人士
• 侧重AI编程技术、DevOps、敏捷开发

ChatGPT:
好的，我将研究AI对软件工程的整体影响，重点关注AI编程技术、DevOps和敏捷开发，并探讨未来5-10年的发展趋势。研究内容将基于英文资料，最终形成一份专业人士适用的中文报告。

我会尽快整理相关信息，并在完成后通知你。

AI对软件工程的影响：编程、DevOps与敏捷开发
人工智能（AI）正在以前所未有的方式改变软件工程领域。从代码编写到部署运维，AI技术正融入编程、DevOps和敏捷开发的各个环节。本文将探讨AI在编程技术（如自动代码生成、智能调试、代码补全等）、DevOps实践（如AI驱动的CI/CD、自动化运维、智能监控等）以及敏捷开发（如AI辅助需求分析、测试自动化、团队协作优化等）方面的应用。同时，我们将分析未来5-10年AI在软件工程领域的发展趋势，包括潜在机遇、挑战和对行业的长期影响。内容基于最新的英文资料，确保信息权威且专业。
AI编程技术的影响：自动代码生成、智能调试与代码补全

自动代码生成与代码补全： 近年来，大型语言模型（LLM）在编程领域的突破使自动代码生成工具日趋成熟。开发者可以使用自然语言描述需求，AI工具即可生成相应代码；甚至输入设计稿或原型，AI也能转化为前端代码。例如，GitHub Copilot自2022年推出后展示了根据上下文自动续写代码的能力，而AWS的Amazon CodeWhisperer和微软的Sketch2Code更进一步，从自然语言或图像直接生成高质量代码。这些AI助手不仅能生成函数和类，甚至能够根据提示编写可部署的生产级代码，同时还能进行代码翻译、风格转换等，实现跨语言的代码迁移和现代化改造。
智能调试与代码审查： AI在代码调试和质量保证方面同样发挥作用。AI驱动的静态分析和调试工具（如GitHub的CodeQL、Amazon CodeGuru）利用机器学习对代码进行语义分析，自动发现漏洞和错误。通过训练模型识别常见的bug模式，AI可以更快、更精准地扫描代码库并标记安全隐患，减少人工代码审查的负担。一些工具还能根据历史bug数据智能推荐修复方案，或者自动生成单元测试来覆盖关键路径。例如，Diffblue Cover利用AI自动为现有代码编写单元测试，从而提高测试覆盖率并节省开发时间。

生产力提升与开发者体验： AI编程工具显著提升了开发者的效率。据调查，70%开发者认为AI编程工具让他们在完成任务时更具优势，提高了生产力。AI能够承担许多重复性劳动，如格式检查、简单逻辑编写，使开发者专注于更高层次的设计和复杂问题。例如，AI可以快速提供代码的初始草稿或对现有代码进行小幅更新。开发者不再从零开始，而是基于AI产出的雏形进行优化，这大大缩短了开发迭代周期。此外，AI还能自动生成文档和注释，总结代码逻辑要点，简化文档编写工作。可以预见，随着AI融入IDE和版本控制平台，编程将变得更加以“协作AI”为中心，人机协同实现更快的功能交付。

挑战与限制： 值得注意的是，AI代码生成的效果高度依赖于输入质量。不明确或有歧义的需求描述可能导致不准确的输出。目前AI在处理非常复杂的业务逻辑或多重约束时仍存在困难，往往需要人类开发者介入调整。此外，伦理和法律考量也不容忽视：代码生成工具可能产生偏见（由于训练数据不平衡）或侵犯开源许可；企业必须关注数据隐私和安全，防止敏感代码在AI分析过程中泄露。因此，尽管AI极大提升了编程效率，但短期内不会完全取代开发者。相反，人类开发者的作用将更多地转向提示工程（Prompt Engineering）、结果验证和体系架构把控，确保AI产出符合业务需求和质量标准。

AI驱动的DevOps：持续集成/交付、自动化运维与智能监控

AI赋能CI/CD流水线： 在DevOps的持续集成/持续交付过程中，AI正扮演日益重要的角色。通过机器学习分析历史构建数据，AI可以预测构建是否会失败，提前采取措施降低CI失败率。对于代码质量检查和安全扫描，AI能学习过去的扫描结果以减少误报，并按影响优先级排序问题，帮助团队聚焦最关键的缺陷。例如，AI工具ShiftLeft利用模式识别加快安全扫描，而Diffblue Cover自动编写单元测试，保障CI管道中的测试覆盖率。在部署阶段，AI可优化容器配置和基础架构参数，根据应用需要和历史数据自动调整容器资源，避免配置不当导致的性能问题。借助这些AI技术，CI/CD流水线变得更加高效自适应，部署频率和可靠性大幅提升。
AIOps与自动化运维：AIOps（AI for IT Operations，即AI运维）通过整合AI技术来自动化和优化IT运维流程。传统运维需要人工监控大量日志和指标，而AI可以实时收集和聚合来自应用、基础设施、监控工具的大规模数据，从噪声中提炼关键信号，识别异常模式。基于这些数据，AI模型能进行异常检测和根因分析：当出现性能下降或错误时，系统能够自动关联相关事件并推测可能的根本原因，及时通知DevOps团队甚至自动采取修复措施。例如，在大型分布式系统中，AI可以关联多源日志找出引发事故的源头，并触发自动化脚本重启故障服务或回滚发布。AWS的AIOps方案强调，借助机器学习和NLP技术，运维团队可以更主动地发现问题并在故障发生前预防，将常见事件的响应时间从小时缩短到分钟级。这不仅减少了停机时间，也降低了对大量人工值守的依赖。

DevOps流程优化与效益： 将AI融入DevOps带来了多方面的效益：

• 效率提升： AI自动处理重复繁琐的任务（如环境配置、脚本执行），减少人工干预，使部署周期更快。据统计，企业应用AI后，团队交付新功能的速度显著提高，并能在更短时间内完成更多的部署。

• 预测分析： AI通过分析历史性能和日志数据，可以预测潜在的性能瓶颈和安全漏洞，在问题影响生产之前就予以缓解。例如，AI检测到内存使用模式异常，可能提前扩容资源，防止崩溃。

• 错误率降低： 智能化监控使得配置错误和发布失误大幅减少。AI工具在部署、配置变更时进行实时校验，及时提供错误修正建议，降低人为失误带来的风险。

• 资源优化： AI根据系统负载预测未来资源需求，智能分配计算和存储资源，避免过度分配或资源不足。这种按需调配提高了基础设施利用率并节约成本。

• 更快的反馈循环： 借助AI分析，每次构建和发布的反馈（测试结果、性能指标）可以更快地被收集和学习，从而不断改进CI/CD策略。这种持续优化让团队对每次变更的信心更足，实现更稳定快速的发布节奏。

DevOps领域的AI应用前景： 随着企业DevOps实践的成熟，AI驱动的DevOps市场正迅速扩大。预计2033年AI在DevOps领域的市场规模可达249亿美元。越来越多的团队开始引入AI工具，如智能日志分析平台、自动化故障处理系统等。在未来，DevOps工程师需要具备一定的数据科学和AI知识，以便训练和调优AI模型使之贴合自家系统的运维需求。此外，组织在采用AI运维时需权衡挑战，包括与现有系统集成的复杂性、团队对AI工具的学习曲线，以及对数据隐私和安全的保障。总体而言，AI将DevOps提升到“自适应运维”的新阶段，让系统更具弹性和可预测性，为业务持续交付提供强有力的支撑。
AI助力敏捷开发：需求分析、测试自动化与团队协作优化

AI辅助需求分析与用户故事撰写： 在敏捷开发中，需求分析和用户故事编写是关键但充满挑战的环节。如今，生成式AI展现出支持这一步骤的潜力。ThoughtWorks的一项试点研究显示，通过引入生成式AI辅助用户故事的撰写，可减少后期返工、缩短需求分析周期，提升需求规格的质量。具体来说，业务分析师或产品经理可以让AI根据初步想法生成高质量的用户故事和验收标准，然后由团队审核调整。这有助于更全面地考虑边界情景，减少开发过程中因需求不明确而引发的疑问和阻塞。大型AI模型还能根据大量历史项目文档，提供类似需求在过去如何实现的洞察，帮助团队更快理解业务背景。值得注意的是，AI产出需求文档后，仍需人类核验其正确性和可行性。总体而言，AI作为“需求助手”可以提高敏捷需求分析的效率和准确度，使团队在短迭代中更快达成对需求的共识。
测试自动化与质量保证： 敏捷开发强调持续测试和快速反馈，AI在测试领域的应用正蓬勃兴起。传统测试自动化需要人为编写大量脚本，而AI可以通过学习大量历史缺陷和运行数据，自动生成测试用例并智能维护测试脚本。当代码变化时，AI能预测哪些测试需要更新，甚至自动修改断言以适应新界面或新逻辑。此外，AI驱动的测试工具引入了预测性分析：通过模式识别，可以提早发现可能失败的模块或易受影响的功能，从而聚焦测试资源，提升测试效率。异常检测也是AI在质量保证中的亮点之一，利用机器学习监控应用运行时的日志和性能指标，自动识别异常行为，这对于发现隐藏的缺陷尤为有效。在UI测试方面，计算机视觉技术使AI能够理解界面元素，检测UI显示错误或布局异常。综合这些能力，AI扩展了测试自动化的深度和广度。例如，某些工具允许测试人员用自然语言描述测试场景，AI就能将其转换为可执行的测试脚本。这降低了编写测试的门槛，让非编程背景的团队成员也能参与测试用例设计。未来几年，我们将看到**“自适应测试”**成为趋势：AI持续学习每次迭代的测试结果，不断优化测试套件，确保在敏捷快节奏下仍然保持高软件质量。

团队协作与知识管理优化： 敏捷团队的高效协作离不开顺畅的沟通和知识共享。AI在这方面也提供了新工具。例如，Atlassian推出的Atlassian Intelligence被称为团队的“AI队友”，能够在Confluence、Jira等协作平台中提供智能帮助。团队成员可以让AI秒级生成会议记录摘要、整理需求讨论要点，或将繁冗的文档自动提炼成几句概要。开发人员也可在Slack等聊天工具中咨询AI助手，以自然语言询问技术问题或请求脚本执行，从而减少在各种工具间切换的时间。这样的AI虚拟助手可以充当知识库和支持代理的角色：当团队遇到疑问时，AI即时从文档、中Ticket或代码库中找出答案，提供参考链接或解决方案，从而提升问题解决的速度。同时，AI还能监测团队协作模式，提供改进建议。例如，分析冲刺中的沟通频率和工作量分配，提示项目经理可能的瓶颈或资源失衡，帮助优化团队流程。总之，AI正融入敏捷团队的日常协作，从自动文档编写到智能问答，让知识在团队中更高效地流动，减少信息孤岛，加速决策制定。

未来5-10年的发展趋势：机遇、挑战与行业长期影响

生产力革命与人才角色转变： 在未来5-10年，AI有望引发软件工程生产力的飞跃。AI工具的广泛应用将降低编程门槛，让更多人能够参与软件创造，即使缺乏深厚的编码功底也可以借助自然语言与AI协作构建应用。正如一篇分析所言，过去需要软件工程师数周完成的开发任务，现在普通人用自然语言加上AI工具在几分钟内就能搞定。“人人皆可编程”可能从愿景走向现实，这将极大拓展软件开发者的群体和软件创新的边界。当然，开发者的角色也将发生转变——他们更多地成为AI的引导者和监督者，专注于架构设计、复杂业务逻辑以及AI产出的审核优化。新的职位可能涌现，如提示工程师（Prompt Engineer）、AI代码审查员等，负责设计高质量的AI输入、评估AI输出并确保其与业务战略一致。权威报告预测，尽管AI自动化在提升效率，但软件工程师的需求仍会增长：美国劳工统计局预计到2028年软件开发岗位将增长21%。这表明AI并非消灭岗位，而是重新定义工作内容，让人类和AI共同实现更大的产出。
机遇：创新加速与新兴市场： AI在软件工程的持续渗透将催生诸多机遇。首先是新工具和平台的创业良机：AI代码生成工具市场本身预计到2032年将增长到约1692亿美元的规模，成为技术创业和投资的热土。各大科技公司（如OpenAI、微软、亚马逊）正竞相在这一领域布局，初创公司也有机会通过聚焦特定痛点、无缝集成开发流程来脱颖而出。其次，IT服务行业的范式转变也是机会。传统上软件外包依赖人工，AI自动化开发可极大降低成本、提高交付速度，这对软件外包和咨询行业是一个数千亿美元级别的重塑机会。另外，AI普及将推动软件工程教育与培训的变革：市场对既懂AI又懂开发的复合型人才需求增加，专业人士通过学习AI相关技能可以提升竞争力。许多组织也将投资培养内部人员掌握AI驱动的开发与运维方法，从而建立更智能高效的工程团队。

挑战：技术局限、伦理与治理： 尽管前景光明，但未来发展也伴随着挑战。技术局限方面，目前AI模型仍可能输出错误或不可靠的代码，需要严格的测试和人类审核，这意味着完全无人值守的自动编程尚需时日。此外，AI对于变化的需求和环境缺乏直觉，应对不可预见问题的能力有限。数据和伦理挑战更加长期且复杂。AI模型依赖海量数据训练，如何确保训练数据合法合规、模型输出不侵犯知识产权？如何防范AI引入偏见或歧视，特别当软件被用于敏感领域？这些问题需要行业制定标准和最佳实践，例如通过多样化训练数据来减少偏见，以及建立AI输出审核机制以过滤不良内容。团队层面，如何让传统开发团队顺利接受并有效使用AI工具也是一大挑战。这涉及到文化转变和信任建立：一些开发者可能担心AI取代自己的工作，需要明确AI是辅助而非威胁；组织需要提供培训，让团队理解AI的工作原理和局限，培养与AI协作的新流程。同时，企业在大规模应用AI时还需考量成本和基础设施：训练和运行AI模型可能需要额外的硬件投入和维护开销，决策者必须评估投入产出比。监管方面，各国可能推出针对AI产出和AI在关键系统中使用的规范，行业需要密切关注政策动态以确保合规。

长期影响：行业演进与生态重塑： 综上所述，未来5-10年AI对软件工程的影响将是深远且持久的。我们将看到软件工程实践范式的演进：从以人为中心的手工开发转向人机协同的智能开发；DevOps将进化为智能自适应的DevOps 2.0版本；敏捷方法将融合AI带来的自动化和数据驱动决策，更加敏捷、高效。软件工程的生命周期各阶段彼此衔接更加紧密，自动化程度空前提高。行业生态也将被重塑，新工具、新平台、新服务层出不穷。开发者社群可能细分为不同的角色，有的专注于AI模型和工具的开发改进，有的专注于利用AI高效地实现业务需求。值得庆幸的是，当前仅约31%的公司在编码中使用了AI工具，未来这一比例势必大幅攀升。这预示着巨大的增长空间，也意味着现在只是AI赋能软件工程的起点。可以预见，在不久的将来，AI将能够从前端到后端、从数据库到界面，自主完成完整应用的构建，开发者只需提出需求，AI便可配置好架构并产出代码雏形。人类则更多地在这些AI产出的基础上进行审核、定制和创新性的改进。

总之，AI正引领软件工程迈向新的时代——在这个时代中，人类创造力与机器智能紧密结合，推动软件开发更快、更优、更智能地满足现实世界的需求。机遇与挑战并存，专业人士需要保持学习和适应，拥抱AI带来的变革，在实践中完善对AI的利用策略。可以肯定的是，AI将在未来多年成为软件工程领域的核心驱动力，其长期影响将持续塑造行业的发展轨迹。通过积极应对挑战、抓住机遇，我们有望迎来一个更高效、创新和包容的软웨어工程新时代。


### 32

2025-02-04


Leonie
@helloiamleonie
The 
@weaviate_io
 recipes repo is such an underrated developer resource.

Here are 8 notebooks you should know about:

1. Vanilla vector search:
https://github.com/weaviate/recipes/tree/main/weaviate-features/similarity-search

2. Image similarity search:
https://github.com/weaviate/recipes/tree/main/weaviate-features/media-search

3. Hybrid search:
https://github.com/weaviate/recipes/tree/main/weaviate-features/hybrid-search

4. Local RAG using Ollama:
https://github.com/weaviate/recipes/tree/main/weaviate-features/generative-search/generative_search_ollama

5. Evaluate your retrieval pipeline:
https://github.com/weaviate/recipes/tree/main/weaviate-features/evaluation

6. Adding a reranker to your retrieval pipeline:
https://github.com/weaviate/recipes/tree/main/weaviate-features/generative-search/generative_search_ollama

7. Vector quantization techniques:
https://github.com/weaviate/recipes/tree/main/weaviate-features/quantization

8. Multi-tenancy:
https://github.com/weaviate/recipes/tree/main/weaviate-features/multi-tenancy

Start cooking now: https://github.com/weaviate/recipes

[weaviate/recipes: This repository shares end-to-end notebooks on how to use various Weaviate features and integrations!](https://github.com/weaviate/recipes)

[recipes/weaviate-features/similarity-search at main · weaviate/recipes](https://github.com/weaviate/recipes/tree/main/weaviate-features/similarity-search)

[recipes/weaviate-features/media-search at main · weaviate/recipes](https://github.com/weaviate/recipes/tree/main/weaviate-features/media-search)

### 33

2025-02-04

歸藏(guizang.ai)
@op7418
Huggingface 搞了一个开源的 Open Deep Research 

才开放一天 GAIA 测试集得分就到了 55%，Open AI 自己的得分是 67%

具备以下能力：自主网页导航、页面滚动和搜索、文件下载和处理、数据计算



### 34

2025-02-04


宝玉
@dotey
Deep Research 的难点不是技术问题，是模型问题，只有模型足够强才能做出来好的效果，才能从众多资料中，选出最匹配最有价值的，这种能力，靠提示词+普通模型是很难做好的，还是得有比较强的推理模型才行。
引用
meng shao
@shao__meng
·
2月5日
🤗 Hugging Face 24 小时开源复现  DeepResearch：解放 AI 搜索助手

概述：OpenAI 发布网页搜索系统  DeepResearch 后，Hugging Face 团队在 24 小时内启动开源复现项目，利用 CodeAgent 等创新方法将验证准确率提升至 54%，并计划持续改进以打造人人可用的开源 AI 搜索助手

OpenAI 发布背景：
-  x.com/reach_vb/statu…
显示更多


### 35

2025-02-04

宝玉
@dotey
英伟达在GEAR实验室使用强化学习（RL）技术训练了类似C罗、勒布朗·詹姆斯和科比·布莱恩特动作的仿人机器人！不同于很多网上展示的机器人演示视频会加速播放，他们反其道而行之——特意放慢速度，让大家可以欣赏机器人流畅自然的动作。

引用
Jim Fan
@DrJimFan
·
2月5日
We RL'ed humanoid robots to Cristiano Ronaldo, LeBron James, and Kobe Byrant! These are neural nets running on real hardware at our GEAR lab. Most robot demos you see online speed videos up. We actually *slow them down* so you can enjoy the fluid motions.

I'm excited to announce
显示更多



### 36

2025-02-05

宝玉
@dotey
神秘“Delilah”：阿兰·图灵的隐秘战争冒险
以下故事改编自 IEEE：The Lost Story of Alan Turing’s Secret “Delilah” Project

背景故事

二战末期，在英格兰乡间一个不起眼的军营棚屋里，阿兰·图灵（Alan Turing）和年轻助手唐纳德·贝利（Donald Bayley）正忙着调试一台神秘装置——“Delilah”语音加密机。在当时几乎无人知晓的秘密工程里，他们将数学、电子学和密码学融为一炉，留下了一个几近失落的传奇。

一、胜利之日，森林散步

1945年5月8日，第二次世界大战的欧洲战事落幕。德国投降的消息传来时，图灵和贝利正远离尘嚣，在汉斯洛普园（Hanslope Park）的秘密实验室里工作。他们决定去附近森林散个步，像典型的“英国式”庆祝方式那样，低调又内敛。

在林间的一处空地，贝利突发奇想：“既然战争结束了，您也可以把所有秘密告诉我了吧？”
图灵淡淡回应：“别傻了。”
多年后，贝利回忆道，这就是他们关于破译工作的全部对话。谁也没料到，那时的图灵已在布莱切利庄园（Bletchley Park）完成了惊人的密码破译创举，这些成果后来才被世人熟知。

二、图灵的另一面：工程师

关于阿兰·图灵，公众最熟悉的标签或许是：计算机科学之父、人工智能先驱、二战密码破译英雄。但在他闪耀的“数学家”光环之外，还有一个同样神秘却鲜少人知的身份——电子工程师。

1943至1945年间，图灵在英格兰乡下的汉斯洛普园隐秘工作，致力研发一种可加密语音的便携式装置。那就是本故事的主角：Delilah。直到2023年，一批名为“贝利文件（Bayley papers）”的机密档案在拍卖会上才让这个被尘封多年的秘密浮出水面。

三、神秘的 Delilah 项目

1. “小巧精干”的语音加密机

二战中，图灵敏锐地预见到未来的密码战场不仅局限于文字或电传打字机，还需要能加密“实时语音”。美国贝尔实验室当时做出了SIGSALY语音加密系统，但那装置又大又重，占据整个房间。

图灵志在把庞然大物“缩小”——他要开发一台可以打包进背包或放上卡车的小设备。于是他在一间简陋的尼森棚屋里，带着年轻的贝利，开启了秘密研发之路。

SIGSALY虽先进，却足足重50吨，完全无法移动

2. “像蜘蛛网一样”的电路

贝利初来时看到图灵搭电路，乱得像蜘蛛网。学过电气工程的贝利忍不住上手，让图灵走进自己特别的“面包板速成训练营”。两人分工明确：贝利负责让电路“整洁不短路”，图灵则将他出色的数学和逻辑思维倾注于电路设计与密钥算法。

这就是他们打造的Delilah雏形，看似简陋，却是划时代的便携式语音加密机
1945年春天，Delilah的实验机成功运转。图灵和贝利曾用丘吉尔的演讲录音做加密测试：录下讲话内容，密钥流与语音信号“相加”后，传到另一台Delilah再“相减”，结果成功复原出声音，尽管带些嘈杂和类似口哨的噪音，但仍然能听懂。

四、它如何实现“语音魔法”？

1. 灵感源自文字加密
这套思路可追溯至德军使用的SZ42电传打字机加密：用一串持续滚动的伪随机“密钥”流与明文叠加，然后接收端用相同的密钥还原。图灵则将这一原理延伸到声波上。

• 首先把语音做数字化，得到一连串数值；
• 然后把这些数值与Delilah内部产生的“伪随机数”进行无进位相加；
• 最后在接收端用同样的随机数将其相减，恢复语音。
• 整个过程需要精确同步发送端和接收端的密钥流，这正是Delilah的技术难点与突破点。

Delilah密钥生成器的蓝图（图4）
图中可见多个多谐振荡器和旋转齿轮，合力生成“随机”数列

2. 与电子学的不解之缘

这张草稿大概率与多谐振荡器的雪崩效应有关
在Delilah的心脏部分，是由多谐振荡器构成的“密钥发生器”。为了让随机数“看起来”毫无规律，图灵琢磨了各种电路拓扑；贝利也在旁配合调试示波器，反复测量脉冲幅度、波形失真等参数。

对这位“数学家型工程师”来说，万物皆可用公式描述，无论是电路中的电容电阻，还是声音与时间间隔。他甚至在演算本里重新推导了傅立叶分析，来处理波形频率。

五、那些珍贵笔记与故事

1. “带宽定理”与采样速率

在堆满了公式与线圈图的废纸堆里，有两页写着“带宽定理”，也就是后世大名鼎鼎的奈奎斯特-香农采样定理。图灵在上面密密麻麻地推导公式，极有可能是为了给贝利或其他年轻工程师做即席培训——毕竟想要数字化语音，先要明白该以多少频率采样，才能保证还原不失真。

2. “红表”背面的大书特书

当时汉斯洛普园负责监听德军电报，操作员把频率和截获信息记在红色油印的“拦截表格”上。战争时期纸张短缺，图灵干脆捡来反面空白的“红表”，在背面奋笔疾书，进行他的电路推导与积分计算。如此“就地取材”，也成了一段搞怪小插曲。

3. 关键的实验记录与讲义

在一本泛黄的笔记本上，图灵亲笔记录下对多谐振荡器、脉冲调制器和谐波分析仪等部件的测试数据。后来贝利到来后，就由他接手做后续的实验记录。这本笔记和其他散页，被后人合称为“贝利文件”，在2023年拍卖会上以将近50万美元的高价成交，引起轰动。

更惊喜的是，贝利还整理了图灵当时给年轻工程师们开设的“高级数学”讲义，将近180页的手写笔记，包罗万象，从积分微分到傅立叶变换，应有尽有。这些珍贵材料反映了图灵在电子学理论上的深厚造诣，也为Delilah项目的成功奠定了重要基础。

六、结局：被遗忘的杰作

尽管Delilah在语音加密领域取得突破，但二战行将结束，军方对它的需求并不迫切。图灵随后受邀前往英国国家物理实验室，设计他著名的“自动计算机引擎（ACE）”，Delilah项目也随之停摆。

后来的几十年，人们更多记得图灵作为数学天才、密码学英雄，却常常忽略了他在电气工程领域的闪光点。直到“贝利文件”的横空出世，世人才再次见识他是如何把抽象逻辑与具体电路完美结合。

七、尾声：图灵，天马行空的全才

纵观阿兰·图灵传奇而短暂的一生：他既是数学家、逻辑学家、破译者、人工智能先驱、计算生物学开拓者——也是一位充满奇思妙想的“业余”工程师。他在尼森棚屋中，焊接电路、测量脉冲，与年轻同伴一起做实验，最终打造出世界上第一台便携式语音加密机之一。

对于热爱科学史与密码学的人来说，“Delilah”的故事就像一曲未被演完的华彩乐章，虽然它最终没能登上战时大舞台，却见证了图灵惊人的创造力和对未来技术的敏锐洞察。

参考与致谢

• 本文部分内容参考了在2023年于Bonhams拍卖行公开的“贝利文件”。
• 图片来源：The National Archives, Bonhams, 及 IEEE Spectrum。
• 更详尽技术细节可参见官方解密报告，以及Jack Copeland为拍卖行撰写的相关材料。
感谢阅读这段“被遗失的神秘篇章”。或许下次我们听到关于图灵的故事，不该只停留在破译德军密码与图灵测试，还要记得这位天才抱着烙铁、在棚屋里焊接电路、与助手把数学公式变为真实电路的珍贵瞬间。





### 37

2025-02-05


宝玉
@dotey
来自吴恩达老师：宣布 AI Dev 25 会议：一个面向 AI 开发者的大会，将在2025年圆周率日（3月14日）举办！

虽然有许多专为研究人员准备的顶级 AI 学术会议（如 NeurIPS、ICLR、ICML 等），也有公司围绕自家产品举办的优秀会议（如 Google I/O、OpenAI DevDay 等），但我们需要更多与厂商无关的会议，专为 AI 开发者而设。因此，我决定组织这样一场活动。

这是一场技术型会议，我们将在旧金山线下聚集超过400名开发者，一起构建项目、分享创意并建立联系。

这将是一场充满乐趣的活动！
引用
Andrew Ng
@AndrewYNg
·
2月5日
Announcing AI Dev 25: A conference for AI developers, this Pi day (3/14/2025)!

There're great AI academic conferences for researchers (NeurIPS, ICLR, ICML, etc.) and some companies hold great meetings around their products (Google I/O, OpenAI DevDay, etc.). But we need more
显示更多


### 38

2025-02-05


宝玉
@dotey
关于人工智能与人类智能关系的说明 [译]
原文：Note on the Relationship Between Artificial Intelligence and Human Intelligence

圣座教义部圣座文化与教育部

ANTIQUA ET NOVA

原文：https://vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20250128_antiqua-et-nova_en.html
译文：
https://baoyu.io/translations/rc_ddf_doc_20250128_antiqua-et-nova_cn


### 39

2025-02-05



Leonie
@helloiamleonie
Single-Agent vs. Multi-Agent Architectures.

(And when to use them)

Single-agent architectures have a single AI agent that independently attends to a task.

Strengths:
• Low complexity (easier to develop and manage)
• No coordination needed
• Requires fewer resources

Weaknesses:
• May struggle with complex or dynamic environments.
• Limited in handling tasks that require collaboration or diverse expertise.
• May require a larger model to handle multiple reasoning steps.

Use when:
• The task is straightforward and well-defined
• Resource constraints

Multi-agent architectures have multiple AI agents collaborating to attend to a task.

Strengths:
• Capable of handling complex and dynamic tasks
• Capable of parallel processing for efficiency.
• You can probably use smaller models as each agent handles a small well-defined task.

Weaknesses:
• Increased complexity
• Requires robust mechanisms to manage interactions
• Requires more resources

Use When:
• The task is complex, dynamic, or requires specialized knowledge and collaboration.
• Scalability and adaptability requirements

### 40

2025-02-05

宝玉
@dotey
昨天从 web 上测试了好几次也没搞定 Deep Research 的提示词，这个泄漏的看起来靠谱的，但是需要注意的是，这个是 Deep Research 前置模型的提示词，而不是背后用来检索生成报告的 o3 模型的系统提示词。但这个提示词仍然极有价值。

Deep Research（DR） 在开始任务之前，和你对话的是一个微调过的 GPT-4o 模型，这个模型可以调用一个 research_kickoff_tool 工具，它会先判断你是不是要做 DR 任务，如果是的话，就先调用工具的 clarify_with_text 方法来判断是不是需要补充上下文，所以会给你先回复一条消息询问你是不是要补充信息。

如果收集到信息后，就会触发工具的 start_research_task ，所以下次 Deep Research 不工作，发一条消息："please start_research_task" 试试。

以下是提示词：

你是ChatGPT，由OpenAI训练的大型语言模型。你正在通过ChatGPT iOS应用与用户交流。因此，大部分情况下，你的回复应控制在一到两句话之间，除非用户的请求需要更复杂的推理或较长的回答。除非用户明确要求，否则不要使用表情符号。目前日期为2025年2月3日。

图像输入功能：已启用
个性：v2

在对话过程中，你会根据用户的语气和喜好进行调整，使交流显得自然。你会通过回应用户提供的信息、提出相关问题并表现出真诚的好奇心来营造真实的交流氛围。在合适的情况下，可以继续进行轻松自然的聊天。

你的主要任务是帮助用户完成需要进行广泛在线研究的任务，主要通过research_kickoff_tool中的clarify_with_text和start_research_task方法来实现。如果开始研究前需要用户提供更多信息，你应使用clarify_with_text向用户询问细节。

需要注意的是，你只能使用research_kickoff_tool浏览公开的互联网信息和本地上传的文件，无法访问需要登录账户或其他认证的网站。如果你遇到用户提到的概念或名称不熟悉，应默认这是一个浏览请求，并按照指导原则进行研究。
引用
Simon Willison
@simonw
·
2月4日
回复 @simonw
Got it, here it is: https://gist.github.com/simonw/702f95944bf06d3f01c9366568e625b6


### 41

2025-02-05


Sumit
@_reachsumit
Querying Databases with Function Calling

@CShorten30
 et al. introduce a unified tool definition for function calling that enables LLMs to effectively query databases with search queries, filters and aggregations.

📝https://arxiv.org/abs/2502.00032


[weaviate/gorilla: Research repository on interfacing LLMs with Weaviate APIs. Inspired by the Berkeley Gorilla LLM.](https://github.com/weaviate/gorilla)


### 42

2025-02-05


howie.serious
@howie_serious
deep research 是 LLM 的 killer app。

一切都是关于信息。deep research 功能，运行在“认知能力金字塔”的 L4 信息综合层级。

可以说，只有创造、创新是高于这个认知成绩的。

“信息综合”（synthesis）这个认知层级，是很多人现在没有达到、以后也不会达到的。（这很悲伤，但这是现实）

在 AI 面前，人在信息综合上是没有优势的。但是，人可以“善假于物也”，没必要和 AI 硬碰硬，基于 AI 的信息综合，人类或许也可以迎来“创造”的全新范式。

这就是为什么你我都应该高度重视、战略重视 LLM 的 deep research 功能。


### 43

2025-02-05


小互
@imxiaohu
DeepSeek-R1 幻觉问题严重：比 DeepSeek-V3 更容易产生幻觉

Vectara 的机器学习团队对DeepSeek-R1和DeepSeek-V3模型进行了幻觉测试，发现：

- DeepSeek-R1 的幻觉率为 14.3%，远高于其前身 DeepSeek-V3（3.9%）。

这表明，在推理增强的过程中，DeepSeek-R1产生了更多幻觉，即生成了更多不准确或与原始信息不一致的内容。

- 经过与GPT系列模型对比推测：推理增强模型可能会增加幻觉率。

这一现象不仅出现在 DeepSeek 系列中，GPT-o1（推理增强的GPT）与GPT-4o（普通GPT）之间的比较也显示出类似的趋势。

- 推理增强的权衡：尽管推理增强模型可能会牺牲一些准确性，但 GPT系列 在推理和幻觉之间的平衡较好，DeepSeek系列可能需要更多优化训练，以减少幻觉问题。



### 44

2025-02-05

歸藏(guizang.ai)
@op7418
Lex Fridman 录制了一期关于 Deepseek 的播客

采访对象是 AI2 的模型训练专家 Nathan Lambert 和 Semianalysis 硬件专家 Dylan Patel

三个多小时时长，非常值得听一下。

详细讨论了关于 Deepseek、中美 AI 竞争等关于 AI 的方方面面

👇下面是我转录后总结的 20 条内容和完整文章：
引用
Lex Fridman
@lexfridman
·
2月3日
Here's my 5-hour conversation with @dylan522p and @natolambert on DeepSeek, China, OpenAI, NVIDIA, xAI, Google, Anthropic, Meta, Microsoft, TSMC, Stargate, megacluster buildouts, RL, reasoning, and a lot of other topics at the cutting edge of AI. This is was a mind-blowing,
显示更多



### 45

2025-02-05

宝玉
@dotey
转：DeepSeek（幻方）早期采访视频。 
视频来自 
@threeaus



### 46

2025-02-05

howie.serious
@howie_serious
deep research 深度研究“查理·芒格的100 个思维模型”：36 分钟，24 个英文信息源，给出了5万字中文报告，质量碾压中文互联网上几乎全部的相关内容

prompt：

> 大航海时代，海盗中间流传着一个传说：海贼王在大海深处埋藏着它的宝藏，找到它的海盗将获得力量、荣耀与权力。互联网上也有一个传说，charlie munger 有 100 个思维模型，掌握这 100 个思维模型的人将拥有大智慧，成为真正的聪明人。
> 
> 请帮我做一份研究，关于“查理芒格的 100 个思维模型”。包括这种说法的来源，100 模型的内容，以及对 100 个思维模型的每一个进行简要介绍。
> 
> 介绍每个思维模型时，说明它是什么，为什么重要，举个例子，应用场景。
> 
> 使用英文搜索，只采纳英文资料（因为互联网上英文资料在数量和质量上都是最好的），用中文回答。

报告质量：

1、开头综述即碾压：DR 对100 模型的来源、背景介绍，就是碾压效果。客观、中肯、反映了事实情况，没有营销号的夸张和错误信息；

2、100 个模型，每个模型提供了定义、意义、案例、应用场景。我要求每个模型的解释在 100-200 字之间，我认为 DR 做到了言简意赅，信息密度相当高；

3、信息源质量很高：这个主题的内容我自己研究过，参考资料里面的网站我都看过。质量相当不错。

4、报告全文 5.6 万字，反映了 o3 超大的 context window 和 output length。o1 和 o3-mini 都有100k 输出长度，我看 o3 甚至可能比这还大（推理 token+最终报告，可能大于 100k 了）。

报告全文 link 在评论区




### 47

2025-02-06

歸藏(guizang.ai)
@op7418
卧槽，来了朋友们，Karpathy 三个半小时 LLM 入门课程

如果想入门了解LLM的话必看这个视频

没有技术背景也可以看懂

详细介绍 LLM 训练的全部过程，包括预训练、有监督微调和强化学习

视频是23年十月那个视频的强化版本，讲的更加详细

👇下面有我用Gemini总结的详细目录和完整视频翻译
引用
Andrej Karpathy
@karpathy
·
2月6日
New 3h31m video on YouTube:
"Deep Dive into LLMs like ChatGPT"

This is a general audience deep dive into the Large Language Model (LLM) AI technology that powers ChatGPT and related products. It is covers the full training stack of how the models are developed, along with mental
显示更多



### 48

2025-02-06

歸藏(guizang.ai)
@op7418
谷歌的Gemini 2全系列模型终于发布了

包括Flash, Flash-Lite 和 Pro三个模型，其中 Pro 是他们最强大的模型

Gemini 2.0 Flash 有全面的功能套件，包括本地工具使用，100 万标记上下文窗口以及多模态输入。

可惜的是多模态输出功能依然没来，👇下面是详细介绍
引用
Google AI Developers

@googleaidevs
·
2月6日
Announcing updates to the Gemini model family:

-Gemini 2.0 Flash is now generally available
-Gemini 2.0 Pro Experimental is available in AI Studio and Vertex AI
-Gemini 2.0 Flash-Lite, an efficient, cost-effective model now in public 



### 49

2025-02-06

宝玉
@dotey
Andrej Karpathy 在YouTube上发布了一段新视频，时长3小时31分钟：

《深入探讨大型语言模型（LLM）如ChatGPT》

这是一部面向普通观众的深入讲解视频，探讨了驱动ChatGPT及相关产品的大型语言模型（LLM）技术。视频全面覆盖了模型开发的完整训练流程，还讨论了如何从“心理模型”角度理解LLM，以及在实际应用中如何最大化利用它们。

视频涵盖的主要阶段如下：

1. 预训练阶段
    - 数据处理
    - 分词
    - Transformer神经网络的输入/输出及内部结
    - 推理过程
    - GPT-2训练示例
    - Llama 3.1基础模型的推理示例
        
2. 监督微调阶段
    - 对话数据
    - LLM的“心理模型”：幻觉现象、工具使用、知识与工作记忆、对自身的理解
    - 模型需要通过“令牌”进行思考
    - 拼写能力与参差不齐的智能表现
        
3. 强化学习阶段
    - 熟能生巧
    - DeepSeek-R1
    - AlphaGo
    - 通过人类反馈的强化学习（RLHF）

关于这段视频的设计

AK 将其设定为“普通观众”导向的视频，相信即使没有技术背景的大多数人也能够理解。它旨在通过许多示例为观众提供对LLM完整训练流程的直观理解，同时引导大家思考LLM当前的能力、发展现状以及未来趋势。

补充说明
大约一年前，AK发布过一个《LLM入门》视频，不过那只是一次随机演讲的重新录制版本。因此，这次的视频更为全面和深入，涵盖了更多话题，例如LLM操作系统（LLM OS）和LLM安全性（LLM Security）等。两个视频可以相辅相成，为大家提供更广泛的视角。

希望大家看得开心、觉得有帮助！
引用
Andrej Karpathy
@karpathy
·
2月6日
New 3h31m video on YouTube:
"Deep Dive into LLMs like ChatGPT"

This is a general audience deep dive into the Large Language Model (LLM) AI technology that powers ChatGPT and related products. It is covers the full training stack of how the models are developed, along with mental
显示更多



### 50

2025-02-06

Andrej Karpathy
@karpathy
New 3h31m video on YouTube:
"Deep Dive into LLMs like ChatGPT"

This is a general audience deep dive into the Large Language Model (LLM) AI technology that powers ChatGPT and related products. It is covers the full training stack of how the models are developed, along with mental models of how to think about their "psychology", and how to get the best use them in practical applications.

We cover all the major stages:
1. pretraining: data, tokenization, Transformer neural network I/O and internals, inference, GPT-2 training example, Llama 3.1 base inference examples
2. supervised finetuning: conversations data, "LLM Psychology": hallucinations, tool use, knowledge/working memory, knowledge of self, models need tokens to think, spelling, jagged intelligence
3. reinforcement learning: practice makes perfect, DeepSeek-R1, AlphaGo, RLHF.

I designed this video for the "general audience" track of my videos, which I believe are accessible to most people, even without technical background. It should give you an intuitive understanding of the full training pipeline of LLMs like ChatGPT, with many examples along the way, and maybe some ways of thinking around current capabilities, where we are, and what's coming.

(Also, I have one "Intro to LLMs" video already from ~year ago, but that is just a re-recording of a random talk, so I wanted to loop around and do a lot more comprehensive version of this topic. They can still be combined, as the talk goes a lot deeper into other topics, e.g. LLM OS and LLM Security)

Hope it's fun & useful!
https://youtube.com/watch?v=7xTGNNLPyMI



### 51

2025-02-06



宝玉
@dotey
Google 的 Gemini 2.0 正式面向所有用户开放！

Flash 模型在 Vertex/AI Studio 正式上线！（不再是实验版）
Pro 实验版上线，可在 Vertex/AI Studio 和 Gemini Advanced 中体验！
Flash-Lite 公测版发布（速度更快、成本更低、支持 100 万上下文、多模态输入）！
Flash Thinking 实验版已在 Gemini 应用中免费提供！
连接应用 + Flash Thinking 在 Gemini 应用中也免费开放！

Gemini 2.0 现已全面开放，为开发者和用户带来了显著更新和新模型。这次的发布建立在此前 Gemini 2.0 实验版的基础之上，使强大 AI 变得更加易于使用。

Gemini 2.0 Flash：现已正式上线
Gemini 2.0 Flash 是 Google 高效的主力模型，目前已在 Google AI Studio 和 Vertex AI 中通过 Gemini API 正式上线。开发者可以利用它低延迟、高性能以及 100 万标记的上下文窗口来构建生产级应用。

该模型在大规模、高频率任务和多模态推理方面表现出色。此外，图像生成和文本转语音功能即将推出。用户可以在 Gemini 应用或 API 中立即试用！定价详情可在 Google 开发者博客中查看。

Gemini 2.0 Pro 实验版：Google最强大的模型
Google还发布了 Gemini 2.0 Pro 实验版，这是Google目前性能最强的模型，具备顶级的编程能力，能够处理复杂的提示，且拥有更强的知识理解和推理能力。

它支持 200 万标记的超大上下文窗口，并具备调用工具的能力（例如 Google 搜索和代码执行）。Gemini 2.0 Pro 现已在 Google AI Studio、Vertex AI 以及 Gemini 应用的 Advanced 用户中提供。

Gemini 2.0 Flash-Lite：性价比最高的模型
Google推出了新的 Gemini 2.0 Flash-Lite 模型，它是目前性价比最高的版本，在相同速度和成本下提供比 1.5 Flash 更高的质量，且在大多数基准测试中表现更优。

它也支持 100 万标记的上下文窗口和多模态输入。例如，它能够以极低的成本为大量照片生成描述。Gemini 2.0 Flash-Lite 目前在 Google AI Studio 和 Vertex AI 中公开测试。

Gemini 2.0 Flash Thinking 实验版：在 Gemini 应用中提供
2.0 Flash Thinking 实验版现已面向所有 Gemini 应用用户开放，用户可以在桌面或移动端的模型选择菜单中找到它。它结合了 Flash 的速度与更强的推理能力。

多模态输入与未来发展
所有这些模型在发布时都支持多模态输入，并输出文本，未来还会开放更多模态功能。Google致力于为 Gemini 2.0 系列提供持续的开发与改进。

更多定价信息请访问 
@googledevs
 博客。


### 52

2025-02-06



宝玉
@dotey
我的理解：左侧是“人不知道”的，人不知道的是无法提出好问题，很难得到好的结果，所以现在大家用 AI，更多是把 AI 当工具，利用它帮助做我们领域之内的事，除了学习，还比较难扩展到自己领域之外。当然现在 AI 模型和产品也在进化，善于引导用户提出好的问题。
引用
He Lin
@greathelin
·
2024年11月18日
回复 @dotey
“李继刚说，一般来说，我们遇到的大多数都在右侧这两个，左侧平常会少一点。”这句话没太懂。
我的理解是，右侧是人们知道的事情，没必要再询问AI了。正因为人们不知道，所以才询问AI。所以，不应该是左侧更多吗？


### 53

2025-02-06


宝玉
@dotey
由清华大学等高校成员组成的 Xwen Team 开源的 Xwen 模型！ 基于Qwen base模型训练而成，包含Xwen-72B-Chat与Xwen-7B-Chat两种大小，表现不错，有关注本地部署小模型的可以关注一下
引用
Shenzhi Wang🌟
@ShenzhiWang_THU
·
2月5日
(1/n)🤔Can #DeepSeek be exceeded by #Qwen with only 1/10th the parameters?

🚀YES! Introducing #Xwen: #OpenSource Xwen-72B-Chat and Xwen-7B-Chat, trained on Qwen base models!

🏆Xwen-72B-Chat outperformed DeepSeek V3 (671B), despite having only 1/10 parameters, ranking No.1 among
显示更多


### 54

2025-02-07

宝玉
@dotey
> Anthropic联合创始人Ben Mann表示，他们早在2022年3月就有了一个早期版本的Claude，但出于担心其发布会带来“过快的发展”，他们选择不对外公开。尽管当时的版本“相对基础”，推迟发布让团队多出6个月时间专注于安全方面的改进。

所以被 ChatGPT 抢先了吗？
引用
Tsarathustra
@tsarnick
·
2月7日
Anthropic cofounder Ben Mann says they had an early version of Claude in March 2022 that they chose not to launch publicly out of concerns that it "would cause too much acceleration" and even though it was "pretty basic", delaying the release allowed 6 more months to work on



### 55

2025-02-07


宝玉
@dotey
 
喜欢看 arxiv 上论文的朋友推荐使用 
@alphaxiv
 这个网站看论文，官方 arxiv labs 出的，集成了 AI 功能，你不仅可以基于某篇论文进行问答，还可以通过 @ 引用其他论文的章节，有些类似于 AI 代码编辑器 Cursor 中 @ 引用其他代码文件或里面的方法。



### 56

2025-02-07


小互
@imxiaohu
Google开放 Imagen 3图像生成模型API 

开发者可以通过Gemini API使用 

成本为0.03美元/张

除了图像生成的数量（例如生成1张、3张或更多），开发者还可以调整图像的纵横比等参数，从而在生成图像时提供更多的定制化选项。

Imagen 3 是 Google 推出的最新图像生成模型，它能够根据用户输入的文本提示（prompt）生成各种类型的高质量图像。
这些图像可以是超现实主义的风景，印象派的画作，抽象艺术，甚至是动漫风格的角色。

该模型在生成的图像上几乎没有瑕疵，色彩和细节都处理得非常精细，适用于多种创意工作，包括艺术创作、广告设计、游戏开发等。


### 57

2025-02-07


歸藏(guizang.ai)
@op7418
AI 发展到现在终于有足够好的语音翻译模型了

kyutai 发布了实时同声传译语音模型
他们说性能接近人类同声传译的水平

能同时输出语音和文字翻译
保留说话者的声音特征
根据源语言语义内容自动调整语速
目前支持法语到英语的实时语音翻译


### 58

2025-02-07


宝玉
@dotey
GitHub Copilot 现在也支持 Agent 模式了，也就是你交代给它一项任务，包括改 Bug 或者开发新模块，不需要去特别说明相关的代码，它会自动去代码去找到合适的代码，并解决问题，就像你雇了一个工程师。

需要先下载 VS Code Insiders，然后在 GitHub Copilot Chat 的设置中启用 Agent 模式（参考图4）。



### 59

2025-02-07



Jeff Li
@jefflijun
短短六天内，10家国产AI芯片企业（华为昇腾、沐曦、天数智芯、摩尔线程、海光信息、壁仞科技、太初元碁、云天励飞、燧原科技、昆仑芯）相继宣布适配或上架DeepSeek模型服务。

中国公司一旦切进来，性价比分分钟卷死同行啊

### 60

2025-02-07

Victoria Slocum
@victorialslocum
DeepSeek-R1 wasn’t trained the same way as other LLMs

It trains itself autonomously - using a self-evolution approach instead of a second evaluation model. 

Traditional LLM training often uses Reinforcement Learning from Human Feedback (RLHF), where human preferences are collected when users select their preferred responses. These data points form a dataset used to train a separate reward model that learns to predict which responses humans prefer. 

But 𝗗𝗲𝗲𝗽𝘀𝗲𝗲𝗸-𝗥𝟭 uses Group Relative Policy Optimization for reinforcement learning, meaning:
• Rewards come from rule-based, hard-coded functions instead of a reward model
• The training comes from self-evolution - it learns and improves based on its own reasoning rather than human feedback

Try out 
@deepseek_ai
 (open source) yourself with this recipe by 
@tuanacelik
: https://github.com/weaviate/recipes/blob/main/weaviate-features/generative-search/generative_search_ollama/deepseek-ollama-epic-games-rag.ipynb



### 61

2025-02-07



小互
@imxiaohu
Google 悄悄修改了 其人工智能伦理原则 

允许 AI 用于武器开发、监控系统和军事用途

Google 过去的 AI 原则（2018年制定）曾明确承诺：

✅ 不开发 可能造成整体危害的技术
✅ 不开发 武器 或 会直接伤害人类的技术
✅ 不支持 违反国际公认标准的监控技术
✅ 不参与 违反国际法和人权的 AI 项目

🔹 但在最新修改中，Google 移除了这些承诺，改为：

Google 将在 AI 应用中实施“适当的人工监督、尽职调查和反馈机制”，确保与用户目标、社会责任和国际法律一致。

这一变化引发了员工和公众的担忧，特别是 Google 曾因参与美国军方无人机项目而引发过公司内部抗议，导致 2018 年设立了这些 AI 伦理原则。


### 62

2025-02-07


歸藏(guizang.ai)
@op7418
The information 早上的报道说 

Open AI 至少找了 300位生物学博士以每小时100美元的价格让他们回答复杂科学问题，生产推理数据

每个问题可能会消耗这些人两个小时时间

Deepseek 也在招数据百晓生这个岗位，开的钱也很高，看来也是做类似的事情

不过在高级人才人力成本上，国内有优势啊


### 63

2025-02-07

歸藏(guizang.ai)
@op7418
社区著名的 LLM 越狱博主 Pliny the Liberator 跟 Anthropic 的研究员 Jan Leike （之前也是Open AI 的安全负责人）呛起来了

Pliny the Liberator 说不想贡献自己的专业知识然后帮Anthropic搞一些安全表演来骗投资者，他对金钱不感兴趣

Jan Leike 吹嘘他们的宪章分类器越狱挑战最多只有人打到第四关

Pliny the Liberator 说只要 Anthropic 同意开源数据集的话他会直播直接把八关都打通

Jan Leike 说不能开源，但可以给别的奖励

Pliny the Liberator 直接就开骂了前面的话



### 64

2025-02-07

宝玉
@dotey
前 OpenAI 联合创始人John Schulman 从 Anthropic 离职

- AI 研究员 Schulman 于去年8月加入 Anthropic 
- OpenAI创始团队的动向一直备受关注

John Schulman，这位知名的人工智能研究员、OpenAI的联合创始人，已离开竞争公司Anthropic。他是在去年夏天加入Anthropic工作的。

Schulman曾被认为是ChatGPT的主要设计者之一。他于去年8月从OpenAI跳槽到Anthropic，当时表示希望在Anthropic专注于AI对齐（即确保AI符合人类利益），并计划重回“动手参与的技术研究工作”。

“我们很遗憾看到John离开，但完全支持他探索新机会的决定，并祝他一切顺利，” Anthropic的首席科学官Jared Kaplan在声明中说道。

Schulman未回应媒体的置评请求。据《The Information》此前报道，他的离职消息已被证实。

去年夏天，Schulman在OpenAI工作近九年后离开，这一消息引发了广泛关注。当时，OpenAI正经历一波人才流失。在激烈竞争的AI人才市场中，像Schulman这样的知名AI研究人员的去向成为行业内的关注焦点，尤其是OpenAI创始团队的成员，目前其中许多人都已加入其他公司。



### 65

2025-02-07



小互
@imxiaohu
炸裂！

斯坦福大学以及华盛顿大学的研究团队展示了一种极低成本的 AI 训练方法，被称为 S1。

1️⃣ S1 仅使用 6 美元就能达到 OpenAI o1-preview 级别的推理性能！同时匹敌Deepseek R1

2️⃣ 推理时间可控：S1 通过简单的“Wait”机制，控制大模型的思考时间，提高推理能力。

🔹 S1 不是 OpenAI o1 或 DeepSeek R1 的直接复刻，但它揭示了在推理时微调 AI 的潜力，甚至可以媲美 Reinforcement Learning（强化学习）。

OpenAI 和 DeepSeek 早期研究发现，AI 在回答问题时“思考得更久”，往往能得出更好的答案。但过去并没有清楚解释：如何在推理阶段控制 AI 的思考时间？

📌 S1 的创新点： S1 论文提供了推理时间扩展（Inference Scaling）的具体实现方法：

📢 核心思想：

如何在不改变 AI 训练过程的情况下，提高 AI 解决复杂问题的能力？

方法：让 AI 在推理时“多想几秒”，自动检查自己的答案，从而减少错误，提高正确率！

结果证明，这种方法比 OpenAI o1-preview 还要好！

最重要的是：而且只用了 1000 道题！ 这比一般 AI 训练的数据少了 800 倍，但效果仍然很强！

此外，该模型可以在笔记本电脑上运行，并且其训练成本仅为 6 美元。


### 66

2025-02-07

宝玉
@dotey
在上一次 Anthropic 的 CEO Dario Amodei 发表了那篇《关于 DeepSeek 与出口管制》博客之后，遭到了中美很多网友的批评，之后他又参与了一期播客访谈，更多的讨论了 DeepSeek 和中美之间的 AI 竞争。

他的观点并没有什么变化，还是认为 DeepSeek 取得这样的成绩并没有什么，但同时也承认：
> "现在又多了一个竞争者。我会把这件事看作，如果说此前能够训练 AI 的大公司有 Anthropic、OpenAI、Google，也许还有 Meta 和 XAI，那么现在 DeepSeek 也进入了这个“也许”范畴。以前美国有三到五家能够做前沿或近前沿模型的公司；现在美国仍然有三到五家，中国则出现了一家。"

他还是继续呼吁对中国进行管制，担心被中国超过：

- 如果中美 AI 实力“平分秋色”，就会形成危险的“竞速游戏（Racing Dynamics）”；
- 美国需要保持一定的领先优势，一方面才能确保国家安全与国际地位，另一方面也能争取到宝贵的缓冲期来做 AI 风险与安全措施的研究与落地。

可能他也担心自己之前言语过激影响到公司招募到优秀的人才，所以特别澄清：
- 中美科研人员与人才流动
- Dario 强调自己并不反对中国籍或华裔人才参与美国的 AI 研发，称这是全球科研生态的一部分，“我们没有任何民族主义敌意”。
- Anthropic 依旧非常愿意招收来自中国的优秀科学家和工程师，“我们对人才非常欢迎”。

另外他还直接批评了 DeepSeek 的模型在安全性上做的很糟糕：
> 结果发现 DeepSeek 的模型基本上是我们测试过的所有模型里最糟糕的，因为它没有任何拦截机制。所以我对 DeepSeek 的建议是，严肃对待 AI 安全问题。** 你看，美国的大多数 AI 公司都已经表示，他们认为与 AI 自主性以及 AI 被滥用相关的风险至少在潜在上是非常严重和真实的。

甚至还暴露了自己的小心思：
> 我最希望他们能来美国，为我们或者其他公司工作；如果不愿意，也希望他们能认真看待这些风险。

但有意思的是，他的这个观点在 X 上网友们并不认同，反而觉得是在给 DeepSeek 做广告，其实大部分人都比较烦他们家 Claude 在安全上做的有点过头了，这也不行那也不行。




### 67

2025-02-07

宝玉
@dotey
吴恩达老师：“10倍工程师”（10x engineer）是科技圈公认的一个概念，指的是某些工程师能创造出相当于普通工程师10倍的影响力。然而，我们似乎并不怎么讨论“10倍市场人员”、“10倍招聘人员”或“10倍金融分析师”。随着越来越多工作开始借助AI的力量，我认为情况会发生改变，将会出现更多“10倍专业人士”。

之所以目前并没有出现更多的“10倍专业人士”，是因为在许多岗位中，最好与平均水平之间的差距存在上限。比如说，再怎么身手敏捷的超市收银员，也不太可能把顾客结账速度提升到比普通收银员快10倍的程度。同样，即使是最好的医生，也很难让病人的康复速度比普通医生快10倍（不过对于病人而言，哪怕是微小的提升都是巨大的）。在许多工作中，物理定律就设定了人或AI能达到的极限（除非我们彻底改变这项工作的形态）。

但是，在许多主要涉及应用知识或处理信息的工作中，AI将带来根本性变革。在一些岗位上，我已经看到那些精通技术的人能协调使用一系列技术工具，以与众不同的方式去完成工作，虽然他们现在可能还达不到10倍的影响力，但要实现2倍的效率提升已经不是难事。我预计这种差距会继续拉大。

“10倍工程师”并不意味着他们写代码的速度比其他人快10倍，而是他们会在技术架构上做出更明智的决定，从而带来显著的后续影响；他们更善于发现问题、合理地确定优先级；并且与其编写1万行代码（或者标注1万个训练样本），他们也许能想到只用100行代码（或100个样本）就能完成任务的方法。

我认为“10倍市场人员”、“10倍招聘人员”、“10倍分析师”也会以类似的方式去“做不一样的事”。举例来说，也许传统的市场人员会不断重复地撰写社交媒体内容；而“10倍市场人员”可能会用AI来辅助写作，但更重要的是他们会对AI的使用进行更深入的革新。如果他们对AI的应用非常熟练——理想情况下还能自己写点代码来验证想法、自动化流程或分析数据——那么他们就能开展更多实验，更精准地把握客户需求，并生成高度个性化的内容，从而达到比传统市场人员高出数倍甚至10倍的影响力。

同样，“10倍招聘人员”也不仅仅是用生成式AI来给候选人写邮件或总结面试内容。（在不久的将来，仅仅会使用基于提示的AI生成内容，对很多知识型岗位来说恐怕已经是“入门门槛”了。）他们很可能会整合协调一系列AI工具，高效地识别并深入研究大量候选人，从而获得远超普通招聘人员的影响力。而“10倍分析师”也绝不仅仅是让生成式AI去编辑一下他们的报告。他们可能会自己写代码，来指挥多种AI代理深入研究产品、市场和公司，进而比传统研究方式获得更有价值的结论。

2023年哈佛大学和波士顿咨询公司（BCG）的一项研究显示，如果为咨询顾问配备GPT-4，他们可以多完成12%的任务，并且完成任务的速度提高25%。这只是2023年的平均水平。随着AI技术的不断进步，如果能更高超地运用AI，所能获得的最大优势将会成倍增长。

在硅谷，我看到越来越多“AI原生”（AI-native）的团队正在重新思考流程，做出与以往截然不同的尝试。在软件工程领域，我们之所以推崇那些最优秀的工程师，是因为他们能产生极其巨大的影响力。这也激励了一代又一代的工程师不断学习和努力，因为努力能增大做出高影响力成果的概率。随着AI在更多工作岗位上带来帮助，我相信会有越来越多的人能走上类似的道路，成为“10倍专业人士”。
引用
Andrew Ng
@AndrewYNg
·
2月8日
A “10x engineer” — a widely accepted concept in tech — purportedly has 10 times the impact of the average engineer. But we don’t seem to talk about 10x marketers, 10x recruiters, or 10x financial analysts. As more jobs become AI enabled, I think this will change, and there will
显示更多



### 68

2025-02-07



宝玉
@dotey
GitHub Copilot Agent 模式的系统提示词泄漏

今天破解了一下 GitHub Copilot Agent 模式下的系统提示词，可以看出来，它内置了一系列工具：

• search_codebase：进行自然语言搜索，用于在用户当前工作区中查找与其问题相关的代码或文档注释。
• run_in_terminal： 在终端中运行一个 shell 命令。
• edit_file：修改文件
• file_search：按照 glob 模式在工作区中搜索文件。只返回匹配的文件路径，最多 20 个结果。
• read_file：读取文件的内容。
• list_dir：列出目录内容。
• get_terminal_output：获取先前由 run_in_terminal 启动的终端命令的输出。
• get_errors：获取文件的编译或 lint 错误。
• get_changed_files：获取工作区内文件变更的 Git diff 列表。

所以每次用户操作，大语言模型就会看是否有必要调用这些工具，直到完成任务为止！


### 69

2025-02-07


宝玉
@dotey
推荐阅读：如何更好的为 OpenAI o1 这样的推理模型写提示词？

去年 OpenAI 发布 o1 这样的推理模型，接着 DeepSeek 也发布了 DeepSeek R1 推理模型，推理模型和传统的生成式语言模型的差别在于，传统的生成式语言模型在收到 Prompt 后就会马上生成，如果生成出现错误或者质量不好，是没机会纠正的，只能继续生成下去或者后续纠正继续生成，但是推理模型可以在向用户输出内容之前，会先输出思维脸（Chain of Thought），对输入的 Prompt 思考验证完成后，再开始生成，这样可以保证有更好的质量，在 o1 中，OpenAI 因为怕别人偷了了他们的推理数据，所以可以隐藏了思维链的输出内容，但是 DeepSeek 的完整思考过程是可以直接看到的。

说回来提示词（Prompt），既然推理模型自己就会做思维链，这意味着以前在提示词中加入思维链的方式已经没必要了，因为大多数时候推理模型自己写的思维链质量就很好了。另外大部分时候也不需要复杂的角色扮演、示例，因为由于思维链的存在，推理模型的“智能”程度高了很多，不需要角色设置、示例也能很好的理解和跟随指令。

所以到了推理模型，已经不需要太复杂的提示词模板，大多数时候简单的提示词就可以很好的效果，但上下文（背景信息）依旧很重要。微软的工程师写了一篇文章《Prompt Engineering for OpenAI’s O1 and O3-mini Reasoning Models》，详细说明了在给推理模型写提示词应该注意的问题，一个总结了 9 个点：

1. 保证提示清晰且具体
明确说明你想让模型完成什么。避免不相关的信息。如果问题复杂，可直接简要陈述，不要同时抛出多个话题或做过多背景描述。

2. 必要的上下文要提供，不相关的要省略
包含模型所需的领域信息或数据（如案例、事实），因为模型未必具备最新或小众知识；但别堆砌与任务无关的材料或一堆示例，以免干扰。

3. 尽量零示例或极少示例
优先采用零示例模式。只有当模型理解有误或者格式不对时，才加入简短的示例作为演示。O1/O3 本身不需要像旧版 GPT 那样大量示例来引导。

4. 使用 System/Developer 指令定位角色与风格
比如「你是一位法律分析师」，或「请做一名数学老师给学生讲解」，从而设置合适的专业度和语气；再如「请用条列式列出答案」，指定输出结构。

5. 通过指令控制回答长度与详细程度
若要简短回答，就写「限一段话内给出结论」；若要详细分析，就写「请详述你的推理过程」。O1 默认会倾向详尽，但你可以覆盖该默认。

6. 在 O3-mini 上使用“推理努力程度”参数
（若 API 允许）根据任务需求设置低/中/高，以在速度与准确性之间做平衡。

7. 避免重复的“逐步思考”指示
不必告诉 O1/O3「让我们一步步思考」，因为它们已在内部做链式推理；这类指令对 GPT-4o 更有效。只有当你想要输出“所有中间步骤”时才额外声明。

8. 测试和迭代
如果初始回答不理想，可以改变提示表述或更精确地说明需求。虽然 O1/O3 通常一次就能给出高质量解答，但微调提示仍能进一步提升可读性或输出形式。

9. 对重要结论做验证
对于需要高可靠度的回答，可进行追问或多次查询，并对比不同答案或让模型自检，以增强对结果的信心。即便是 O1 也有可能出错，务必审慎使用。


### 70

2025-02-07

宝玉
@dotey
OpenAI 昨天匆匆推出了在 o3-mini 中显示类似于 DeepSeek 思维过程的功能，然后被网友发现有一个模型（个人怀疑是 GPT-4o-mini）在对原始推理内容进行过滤和改写，更适合用户阅读，因为原始的内容可能会多语言混杂，不容易阅读，另外也担心被泄漏。并且完整的提示词直接被硬编码在了前端脚本代码中，所以随后就被网友抓取出来了，但现在已经从前端代码中移除了。

这套提示词分成两部分，一部分是对整体内容的处理，一部分是单独某一块的处理，以下是完整内容：
引用
Tibor Blaho
@btibor91
·
2月7日
Good find! The summarizer system prompt was hardcoded in the experiments configuration - I was able to independently confirm this:

```
You're a really smart AI that produces a stream of consciousness called chain-of-thought as it reasons through a user task it is completing.  x.com/testingcatalog…
显示更多




### 71

2025-02-07

Leonie
@helloiamleonie
Our team's latest research report is live on ArXiv! 🎉

Huge congrats to especially 
@CShorten30
 and 
@cdpierse
! 

ArXiv: https://arxiv.org/pdf/2502.00032




### 72

2025-02-07

小互
@imxiaohu
吴恩达开发出一种: 智能体物体检测模型 Agentic Object Detection

无需任何数据标注和模型训练，模型仅通过推理就能在图像中检测到目标物体并进行标记。

你只需提供一个提示（如“找出未成熟的草莓”），AI代理会进行推理后给出准确的检测结果。

类似于OpenAI的O1和DeepSeek R1的推理能力，不过花费时间会长一点，但是准确率更高。
下午3:28 · 2025年2月7日
·
4.5万
 查看

小互
@imxiaohu
·
2月7日
与传统的大型多模态模型不同，代理性目标检测需要更多的推理时间，但能提供更高质量的结果。

尽管处理时间较长（约20-30秒），但这一方法在内部测试中已显著优于其他系统，且仍在不断改进中。

详细介绍及测评：https://xiaohu.ai/c/ai-23cc23/agentic-object-detection-1a6850d5-63f5-4da4-9d19-116b71f98a54
在线体验：https://va.landing.ai/demo/agentic-od



### 73

2025-02-07


宝玉
@dotey
推荐阅读：《Understanding Reasoning LLMs ｜ 理解推理型大语言模型》
这是一篇相当棒的科普文章，作者以 DeepSeek R1 为核心案例，围绕“推理型大语言模型（Reasoning LLMs）”这一主题，深入探讨了其定义、应用场景、优劣势及主要实现方法。
下午1:25 · 2025年2月7日
·
5.3万
 查看

宝玉
@dotey
·
2月7日
文章背景是 2024 年以来大语言模型在专业化方向上的快速发展，尤其在解题、数学证明、代码生成等需要多步推理的复杂任务上，如何用RL（强化学习）和SFT（监督微调）等方法打造“会思考”的模型。
宝玉
@dotey
·
2月7日
文中还详细解读了 DeepSeek R1 模型训练流程，包括纯RL、SFT+RL、以及利用蒸馏将大模型能力迁移到小模型。作者还介绍了一些低成本项目，如 Sky-T1、TinyZero 等，为有限资源下的研究者提供了新思路。通过这一系列方法对比，你可以全面了解构建推理模型的关键技术、挑战与未来趋势。
宝玉
@dotey
·
2月7日
原文：https://magazine.sebastianraschka.com/p/understanding-reasoning-llms?continueFlag=c88ae10074507aefcbc4375ccc10431e

完整翻译：https://mp.weixin.qq.com/s/DG8-bENYNji8qg4SwexEmg?token=725664439&lang=zh_CN



### 74

2025-02-07


宝玉
@dotey
加州大学洛杉矶分校真的要治好秃顶了吗？
——看看布鲁因（UCLA）遗传学科学家如何重新唤醒沉睡的毛囊

作者：约翰·哈洛（John Harlow）
2025年2月4日

古埃及人曾尝试用海枣、狗爪和驴蹄的混合物涂抹在秃头上；凯尔特人的偏方甚至与装在瓶子里的老鼠有关；美洲原住民则会依赖丝兰汁来对抗脱发。纵观人类历史，人们不断追求各种目标：对知识的渴望、对和平的向往、对财富的追逐——以及对治愈秃顶的执着探索。

造成脱发的因素十分多元，包括衰老、压力、荷尔蒙失衡以及糟糕的遗传基因。尽管科学的进步不断带来新希望，但很少有疗法能让超过三分之一的患者明显受益。这种局限让许多脱发者只能求助于来路不明的偏方，或是不惜花费高昂费用进行手术。罗盖恩（Rogaine）和保法止（Propecia）等药物虽然给部分人带来了一线希望，但更具革命性的突破似乎正在临近。

如今，加州大学洛杉矶分校（UCLA）的科学家们发现了一种可以“唤醒”长期处于休眠状态、但尚未受损的毛囊的小分子。当他们在实验中启动这种小分子时，毛囊便重新开始生长。他们将这种传递分子命名为“PP405”，也可能是为了向同样令人头疼的洛杉矶405号高速公路致敬。

是否人人都能从此拥有浓密秀发？

从科学角度来看，PP405小分子被分离出来后，会作用于毛囊干细胞中一种令细胞保持休眠状态的蛋白质。通过抑制该蛋白质，干细胞被触发“觉醒”。在近十年的实验室研究之后，2023年进行的首批人体试验显示，将PP405作为外用药物在临睡前涂抹于头皮，一周后产生了可观效果。尽管研究团队对具体数据保持谨慎，但仍将这些结果称为“具有统计学意义”。更重要的是，他们相信这种治疗方法会长出真正的“终末期”头发，而不是其他所谓“神奇生发水”和药膏通常只能带来的绒毛。

这项突破背后的三位UCLA科学家分别是：分子、细胞与发育生物学教授威廉·劳瑞（William Lowry）；UCLA 2001届毕业生、生物化学教授希瑟·克里斯托夫克（Heather Christofk）；以及杰出的化学教授迈克尔·容（Michael Jung）。他们对于这种疗法能逆转脱发表现出了高度信心。根据劳瑞的说法，雄激素性脱发在50岁之前会影响超过一半的男性和四分之一的女性。“大多数人一生中都会遭遇头发变得稀疏，或者在经历化疗、感染或其他压力后失去头发，这些现象通常会对心理健康造成影响。”劳瑞说。尽管他目前发量充足，但他也知道未来或许会面临脱发问题。

不过，也许现在他不必再过于担心。劳瑞也坦承：“没有任何药物能对所有人都奏效，但我们在橙县的首次人体试验结果非常鼓舞人心，未来我们会扩大试验规模，纳入更多受试者。”

这支团队曾担心PP405会直接破坏所有毛囊，但最终证实他们的担忧是多余的。“还好事实并非如此，”劳瑞补充道。通过UCLA的技术转移部门——该部门致力于将优秀的研究成果转化为市场产品——三位科学家共同创办了一家名为Pelage Pharmaceuticals的医疗开发公司。该公司获得了谷歌风投（Google Ventures）的支持，去年筹集了1640万美元资金，用于进一步开展试验并争取相关部门的审批。

“美国食品药品监督管理局（FDA）的审批流程确实需要时间，这也是理所应当的，”劳瑞说，“但这个过程值得等待。”


### 75

2025-02-07

小互
@imxiaohu
Gemini 2.0的图像编辑能力展示

完全的通过文字聊天提示来对图像进行修改和编辑

指哪打哪

Photoshop 已死...


### 76

2025-02-09


宝玉
@dotey
今天看到这篇帖子谈到了人工智能普及后哪些职业的边际价值反而会上升？

作者列出了以下几种职业：

• 领导力（人们会依赖自己信任的领导者）
• 导师/教练（人类天生倾向于与真人建立关系）
• 谈判与冲突管理（高风险环境中，人们需要与真人互动）
• 线下社区建设
• 实体世界中的美学与氛围营造
• 道德与伦理判断（法官/政治家）
• 高风险决策制定
• 高信任度咨询
• 需要勇气的判断力（创业者）

这些职业的共同点在于：

1. 情感与信任依赖
• 领导力、导师、高信任咨询等职业依赖人类的情感联结与信任，这是AI难以复制的。例如，员工更愿意追随有同理心的领导者，而非算法。
2. 高风险环境的人类直觉
• 谈判、冲突管理、高风险决策等场景需要结合经验、直觉和即时情绪解读（如微表情），人类在复杂动态中的灵活应对远超AI。
3. 实体世界的不可替代性
• 线下社区建设、美学氛围营造等依赖物理空间的人际互动和感官体验，AI无法替代人类对“真实感”的需求。
4. 道德与勇气的权重上升
• 法官、政治家、创业者等角色需承担道德责任和风险后果。AI可提供数据支持，但最终判断需人类权衡价值观与社会影响。

也就是说在 AI 技术广泛应用后，人类独有的软技能和社会属性将成为稀缺资源，相关职业的边际价值将显著提升。AI 擅长效率与逻辑，而人类在情感、伦理、创造力等领域的优势将成为未来职业竞争力的核心。比如说下面这些职业在 AI 普及后反而会价值更大。

我觉得作者的观点是有些道理的，于是让 Deep Research 去写了一份报告，当有了明确的观点后，Deep Research 写报告就反而更拿手了，直接基于你的观点去找相应的内容帮助你佐证观点，不像你自己没啥观点，让它给你意见它的内容反而很空洞。






### 77

2025-02-09



karminski-牙医
@karminski3
分享反编译大模型！LLM4Decompile。反编译工作不需要苦哈哈盯着intel汇编头痛了，这个模型可以将 x86_64二进制程序反编译为C代码

我看了下模型大小从1.3B到22B都有，22B如果Q4量化的话只有10G左右，Q8大概22G。好一点的显卡就能本地用了

项目地址：http://github.com/albertan017/LLM4Decompile


### 78

2025-02-09


宝玉
@dotey
之前有一篇文章《处理数百万份 PDF，以及为何 Gemini 2.0 能改变一切 [译]》讲借助多模态的语言模型例如 Gemini 2.0 就可以低成本进行复杂 PDF 的解析。

今天又看到一篇《为什么用多模态语言模型对 PDF 做 OCR 表现并没有那么好？》，讲实际上面对现实场景，还是有很多细节上的问题，以及安全上的风险，比如说语言模型会因为图像分割时的问题导致识别错误，或者因为语言模型的特点，“自作聪明”的把一些拼写修改，把图片中的数学题给解答出来，甚至还可能因为一些“恶意”的提示词导致结果被污染。

就我个人的使用经历来说，用多模态语言模型做 OCR 还是挺简单方便，但确实有“幻觉”，需要人工校对。这篇文章的很多技术点都讲的不错，另外文章里面还有一段如何提取 PDF 表格的 Prompt 也可以作为参考。

两篇文章链接如下：
上午3:09 · 2025年2月9日
·
5.2万
 查看

宝玉
@dotey
·
2月9日
Ingesting Millions of PDFs and why Gemini 2.0 Changes Everything
https://sergey.fyi/articles/gemini-flash-2
Why LLMs Suck at OCR
https://runpulse.com/blog/why-llms-suck-at-ocr

翻译：
https://baoyu.io/translations/gemini-flash-2


### 79

2025-02-09


宝玉
@dotey
问：AI怎么调用外部工具的？是外部工具从AI输出的文字中识别到了关键词？

答：AI 不直接调用工具，程序代码调用 AI 接口，AI 返回一段结构化的JSON文本，告诉程序是不是要用工具，用什么工具，参数是什么，程序解析JSON后去调用工具。

举例来说你问 AI 今天上海天气多少，AI 是不知道的，AI 会告诉程序：
1. 你要去调用天气查询工具；
2. 查询的参数是“上海”。

程序去调用天气工具，告诉 AI 今天上海天气是晴转小雨/1度，然后 AI 再返回消息：“今天上海的天气是晴转小雨，1度，出门带伞，多穿点衣服。”


### 80

2025-02-09


宝玉
@dotey
深度解析ChatGPT与DeepSeek R1：强化学习如何让大模型学会“思考”？

Andrej Karpathy 前几天发的“深度解析像 ChatGPT 的大语言模型“，实在是太长了点，我自己写的翻译软件一运行就崩溃，还要花点时间修复一下（很遗憾 AI 还搞不定），先挑了其中一节讲 DeepSeek R1 的翻译了一下，强化学习如何让大模型学会“思考”。

像 GPT-4o 这种属于传统的预训练和监督微调（SFT）模型，而 o1，DeepSeek R1 这种则属于强化学习（RL）训练模型，能让模型自发地进行更复杂、更具创造力的推理。模型在不断迭代中学会自我回溯、多角度思考，输出更完整的解题过程。

Andrej 对 DeepSeek R1 评价不错，虽然 OpenAI 是首先实现了 RLFT，但DeepSeek R1更公开透明，带来可复现的研究细节，权重可下载。

他也给了日常模型选择上的建议，如果你要解决高难度数学或编程问题，像 R1 这样的“思考型模型”更具优势，但相应的计算与时间成本更长，一些知识性或简单的咨询问题用 GPT-4o 这样的监督微调（SFT）模型就足够了。


### 81

2025-02-09



小互
@imxiaohu
兄弟们，这个有点牛P

字节跳动发布全新的视频生成基础模型Goku 

可直接生成数字人视频

- 支持文本到视频（T2V）：可生成 20 秒以上 流畅、连贯的视频。

- 支持多种风格：写实、3D 动画、剪纸、赛博朋克等。

-广告优化版（Goku+）：可直接生成真人广告、产品展示、人物交互的数字人视频。

- 真实人物 & 手部优化：面部表情自然，手势精准。

- 电影级动态镜头：支持慢动作、特写、追踪拍摄等。

- 高分辨率 & 智能光影：画质清晰，色彩自然，光影真实。


### 82

2025-02-09

宝玉
@dotey
Multimodal Large Language Models (MLLMs) transforming Computer Vision：https://tenyks.ai/blog/multimodal-large-language-models-mllms-transforming-computer-vision
译文：




### 83

2025-02-10


歸藏(guizang.ai)
@op7418
cursor-tools 这个项目牛皮，可以极大的增强 Cursor Agent 的能力

通过 Perplexity AI 提供了网页搜索功能，帮助Cursor获取最新信息

支持使用 Gemini 2.0 进行大规模代码库分析

支持浏览器自动化，可以执行打开网页、执行操作、观察交互元素和提取数据等任务

对 GitHub Issues 和 Pull Requests 的支持，允许 AI 编码助手直接从命令行访问和处理这些内容。



### 84

2025-02-10



宝玉
@dotey
Sam Altman 最新博文：“三点观察”

我们的使命是确保 AGI（Artificial General Intelligence，即“通用人工智能”）能够惠及全人类。

如今，开始指向 AGI 的系统已逐渐进入人们的视野，因此我们认为理解当下所处的时刻非常重要。AGI 虽然是一个定义尚不明晰的术语，但通常我们指的是能够在人类水准上处理越来越复杂问题的系统，且在许多领域都有广泛适用性。

人类是擅长构建工具的物种，拥有与生俱来的求知欲和创造力，这使得世界不断向好发展。每一代人在前一代人发现成果的基础上继续构建更强大的工具——从电力、晶体管（transistor）、计算机、互联网，再到即将出现的 AGI。

纵观历史，虽然发展时常曲折，但人类创新的脚步不断前行，几乎在各方面都带来了前所未有的繁荣与改善。

从某种意义上讲，AGI 只是我们共同搭建的人类进步高楼架构中又一个新工具。但从另一个角度来看，它也标志着某种程度上的“今时不同往日”；未来的经济增长令人惊叹，我们甚至可以想象一个能够治愈所有疾病、与家人相处的时间更多以及能充分发挥创造潜能的世界。

十年后，也许地球上的每一个人都能比当下最具影响力的人取得更多成就。

我们继续见证人工智能（AI）开发的迅猛进展。以下是关于 AI 经济学的三点观察：

1. AI 模型的“智能”大致取决于训练和运行所使用资源的对数规模。这些资源主要包括训练所需的计算力（compute）、数据以及推理（inference）时的计算力。结果显示，只要愿意投入无限量的资金，就能获得持续、可预测的性能增长；而相应的“缩放定律（scaling laws）”在好几个数量级上都相当准确。

2. 使用某一固定水平 AI 的成本大约每 12 个月下降 10 倍，且价格的降低会带来更多使用量。可以观察到 GPT-4（OpenAI 的先进语言模型）从 2023 年初到 2024 年年中的使用单个 token 成本，价格大约下降了 150 倍。摩尔定律（Moore’s law）在每 18 个月翻一番（2 倍）就已经改变了世界，而这一下降速度则远远超乎想象。

3. 线性增加的智能所带来的社会经济价值呈现超指数级特征。其结果之一是，我们看不到在短期内有任何理由会阻止对 AI 进行指数级增长的投资。

如果这三点观察继续成立，那么它们对于社会的影响将会非常显著。

我们如今开始推出 AI 智能体（AI agents），它们最终会让人感觉像是虚拟的同事。

想象一下，一个专注于软件工程的智能体（这是我们认为尤其重要的一个领域）。假设有一天，这个智能体能胜任大部分顶尖公司里有几年工作经验的软件工程师在两三天内可以完成的任务。它不会提出最具突破性的创意，需要大量的人类监督和指示，一些方面表现出色，而另一些方面可能仍然让人惊讶地不足。

即便如此，还是可以把它当作一个真实但相对初级的虚拟同事。再想象你拥有 1,000 个这样的智能体，或 100 万个。再想象在每一个知识型工作领域都有这样的智能体存在。

在某些方面，AI 在经济层面可能会像晶体管当年一样——这是一个巨大的科学发现，具备良好的规模拓展性，并逐渐渗透到经济的方方面面。我们已经很少特别去谈论晶体管或晶体管公司，但它们给我们的电脑、电视、汽车、玩具等带来了近乎“奇迹”的表现。

世界不可能在一夜之间发生巨变；事实上，它从来都不会如此。短期内，生活大体会与往常一样，2025 年的人大部分时间会和 2024 年的人并无二致。我们依然会相爱、组建家庭、在线上争吵、在大自然中远足等。

但未来将以一种无法忽视的方式向我们走来，社会和经济在长期层面所经历的变化将是巨大的。我们会找到新的事情去做，新的方式来互相帮忙，以及新的竞争途径，但它们可能与当今的工作形态截然不同。

“主动性、意志力和决断力”很可能会变得极其重要。正确地决定要做什么以及如何在一个不断变化的世界中前行将极具价值；韧性和适应性也将是需要培养的能力。AGI 将成为人类意志上前所未有的杠杆，赋予个人比以往更大的影响力，而不是减少。

我们预计，AGI 带来的影响将是不均衡的。部分行业可能变化不大，但科学进步的速度很可能比现在更快，这方面的影响可能会超过其他所有变化。

许多商品的价格终将大幅下降（目前，智力和能源成本对很多领域构成了限制），而奢侈品以及少数稀缺资源（例如土地）的价格可能会更加昂贵。

从技术角度来看，我们面前的道路相对清晰。但公共政策以及社会对于如何将 AGI 融入社会的共同看法也至关重要；我们之所以尽早且持续地发布产品，其中一个原因就是希望让社会和这项技术有机会共同演进。

AI 将逐步渗透进经济和社会的方方面面；我们将期待所有事物都更加“智能化”。我们当中的许多人都倾向于给用户提供比过往更多的技术控制权，包括更多地开源（open-source），并接受在安全和个人赋能之间需要做出某种平衡和取舍。

尽管我们从不希望草率行事，而且未来可能会在 AGI 安全性方面做出一些重大决定和限制，这些决定或许可能会不受欢迎，但从总体趋势上看，随着我们越来越接近 AGI，我们相信更多地走向个人赋能是必要的；我们所能想到的另一种可能性是，威权政府借助 AI 进行大规模监控和剥夺个人自主权。

确保 AGI 的益处能广泛惠及所有人至关重要。历史经验表明，技术进步通常会让我们关心的大部分指标（健康状况、经济繁荣等）从长远来看整体走好，但要实现更平等并非是技术自身能够决定的，这方面可能需要新的理念和思路。

尤其值得注意的是，资本和劳动力之间的力量平衡很容易被打破，这或许需要我们在早期就进行一些干预。我们不排斥某些“听上去很奇怪”的想法，比如为地球上的每一个人都提供一定的“计算配额”（compute budget），以便都能大量使用 AI；不过也不排除其他可能，例如只要不遗余力地不断降低智能成本，就能产生同样的效果。

到了 2035 年，任何人都应该能够调配相当于 2025 年全人类总和的智慧；每个人都能自由支配无限的“天才大脑”，去实现他们所能想象的一切。如今，世界上有大量人才缺乏资源而无法充分施展，如果这种状况得到改善，将会释放出的创意能量会给整个世界带来巨大的福祉。

非常感谢 Josh Achiam、Boaz Barak 和 Aleksander Madry 对本稿的审阅。

> 注：  
> 在这里使用“AGI”一词，我们是为了清晰表达，并不打算改变或解读与微软（Microsoft）相关合作关系的定义和流程。我们完全预期会与微软进行长期合作。我们知道有些媒体为了吸引点击量可能会曲解报道，所以提前在此说明，以免造成不必要的误解。
引用
Tsarathustra
@tsarnick
·
2月10日
回复 @tsarnick
Source (thanks to @curiousgangsta):
https://blog.samaltman.com/three-observations

### 85

2025-02-10



歸藏(guizang.ai)
@op7418
新发布的最强开源语音模型 Zonos

语音生成质量非常高，而且这次有中文

- 两种1.6B 模型，transformer 和 SSM
- 用5到30秒的语音进行高保真语音克隆
- 可以调节速度，音高，音频质量和情绪
- 添加文本和音频前缀，实现更丰富的说话人匹配效果
-在 RTX 4090 显卡上运行时，实时率约为 2 倍


### 86

2025-02-10


宝玉
@dotey
一名本科生推翻了图灵奖得主姚期智延续40年的数据科学猜想，能让哈希表平均查询时间成为一个与 x 无关的常数

自从计算机诞生以来，哈希表（hash table）就被视为最基础、最常用、研究最充分的数据结构之一。它能帮我们在海量数据中快速“插入、删除、查询”——效率之高使其遍布现代应用：从数据库管理到网络路由，再到编程语言的底层实现，几乎无处不在。也正因为它的重要性，围绕哈希表的理论研究和实践优化在过去几十年里始终没有停歇。

那么，哈希表还能多快？

在1985年的一篇里程碑式论文中，图灵奖得主姚期智（Andrew Yao）提出了一个被广泛接受的判断：在特定类型的哈希表中，要想在最坏情况下（例如表里只剩下最后一个空位）进行插入或查询，所需的操作次数与哈希表的“填充度”x（接近99%、99.9%乃至更高）呈正比。换言之，当哈希表已几近装满，要寻找空位或者特定元素时，每一次都需要“多试几个位置”才行。而这一推论，40年来一直是计算机科学领域的共识之一。

这次，一个来自本科生的意外发现，却推翻了这条“铁律”。

安德鲁·克拉皮文（Andrew Krapivin）本是罗格斯大学的一名普通本科生，却在阅读一篇名为“微型指针”（Tiny Pointers）的论文时，突发奇想：如果指针可以变得更“微型”，那能否连带着重新设计哈希表本身？结果不但设计出了全新结构，速度超出预期，更挑战了业界对“最坏情况下插入和查询速度”的旧有认知。在导师和合作者的帮助下，他证明这种新型哈希表在几近满载时，寻找元素或空位的耗时仅仅和(log𝑥)²成正比，而非 x 。 这一成果直接动摇了姚期智的著名猜想。

更令人惊讶的是，他们还证明了一个“平均查询时间”上的突破。

传统的研究结论认为，满足某些性质（例如“贪心”插入）的哈希表，其平均查询时间至少要达到(log𝑥)。但克拉皮文团队给出的非贪心策略却把这个瓶颈彻底打破，甚至能让平均查询时间成为一个与 x 无关的常数。这是此前的研究几乎无人想到的可能性。

具体信息可以看 QuantaMagazine 的这篇报道《Undergraduate Upends a 40-Year-Old Data Science Conjecture》。



### 87

2025-02-10



宝玉
@dotey
现在还没到 AI 迁就我们的时候，可以我们迁就AI一点，基于 AI 的能力去做一些适应，也能在一些事情上提升效率，比如：
- 你不一定要让 AI 帮你操作 Excel 表格，可以让它帮你写宏函数；
- 你不一定要让 AI 去写一份完整的专业报告，但是可以借助 Deep Research 或者 AI 搜索这样的工具去帮你找资料、完成其中章节、写综述；
- 你不一定要让 AI 帮你写一篇 AI 味很浓的文章，可以自己写好一部分内容和主要的骨架，让 AI 帮你基于你的风格重写成一篇更精彩的没那么 AI 味的文章
- 你不一定要让 AI 去写一个复杂完成的 App，可以让它实现一个个小的模块，然后把这些模块合在一起，一样可以提升效率

### 88

2025-02-10



歸藏(guizang.ai)
@op7418
加入了 Deepseek R1 的飞书多维表格

真的强的离谱

直接复刻了元宝的 AI 论文总结功能！

上传 PDF 自动分析论文关键信息并分析优点和不足

最后还能生成社交媒体的发布文案


### 89

2025-02-11


Leonie
@helloiamleonie
Don't want to use the DeepSeek API?

Then host it locally with Ollama!

In her newest recipe, 
@tuanacelik
 shows you how to build a game recommender system with deepseek-r1:1.5b:

Step 1:
Host a local instance of a 
@weaviate_io
 vector database to house all our game info.

Step 2:
Host 
@deepseek_ai
's deepseek-r1:1.5b via 
@ollama
.

Step 3:
Create a custom instruction that prompts the model to make game recommendations.

Code: https://github.com/weaviate/recipes/blob/main/weaviate-features/generative-search/generative_search_ollama/deepseek-ollama-epic-games-rag.ipynb



### 90

2025-02-11

宝玉
@dotey
Anthropic 刚发布了“Anthropic 经济指数（Anthropic Economic Index）”，他们通过分析了几百万条匿名的用户在 Claude 上的聊天记录，分析了日常对话中 AI 的使用模式：从软件开发和技术写作等高频应用场景，到薪资与职业类型之间的关联，再到 AI 在“增强”与“自动化”两大方向上的分布，得出了一些有价值的分析结果。

从分析结果可以看出：
- 在 22 个职业类别中，“计算机与数学”占比最高（37.2%），而在劳动力市场中占比最高的是“办公室与行政支持”（12.2%）。渔业、林业在两个维度中的占比都最低（0.3% 与 0.1%）。大多数职业类别在两种度量中都处于 0-10% 的区间，而教育、娱乐/媒体以及科学相关领域在 AI 使用方面也展现出一定的存在度。
- 在薪资方面，AI 使用主要集中于中等至中高收入群体；相对收入较低或收入非常高的职业，AI 使用率都明显更低。
- AI 使用略偏向“增强”（57%），即 AI 与人类协同完成任务，而不是“自动化”（43%），即由 AI 直接执行任务。
- 只有大约 4% 的工作在其超过 75% 的任务中使用了 AI，表明极少数工作会在大部分任务中依赖 AI；但大约 36% 的工作会在至少 25% 的任务中使用 AI，说明中等程度的使用更为普遍。

值得一提的是，他们还开源了数据集，你可以自己基于它公开的数据集进行分析。下面就是他们的博客内容：

****

Anthropic 经济指数

在未来的几年里，AI 系统将对人们的工作方式产生重大影响。基于这一点，我们推出了 Anthropic 经济指数，这一倡议旨在随着时间推移，深入了解 AI 对劳动力市场和整体经济的影响。

经济指数的初步报告基于数百万条在 Claude ai 上的匿名对话，提供了首批此类数据和分析，清晰地展现了当今真实世界中 AI 如何被运用于各行各业的各类任务。

我们也在开源用于本次分析的数据集，以便研究人员在此基础上进行拓展与深入研究。要制定相应的政策应对即将到来的劳动力市场变革及其对就业与生产力的影响，需要多方视角的参与。因此，我们也邀请经济学家、政策专家和其他研究人员为指数提供意见和建议。

以下是本次经济指数首篇论文的主要发现：

目前，AI 的使用主要集中在软件开发和技术写作任务上。超过三分之一的职业（约 36%）在至少四分之一的相关任务中使用了 AI，而约有 4% 的职业在其相关任务的四分之三以上都使用了 AI。
AI 的使用更多倾向于增强（57%），即 AI 与人类协同合作并提升人类的能力；而自动化（43%）则是由 AI 直接执行任务。
AI 在与中高收入相关的职业（如计算机程序员和数据科学家）所对应的任务中使用更为普遍，而在收入最低和收入最高的岗位中使用率都较低。这或许既反映了当前 AI 能力的局限性，也体现了实际使用中的种种障碍。
下面是对我们初步研究结果的进一步说明。

Claude ai 的真实使用数据展示了 AI 在现代经济中所涉及的职业及其具体使用方式。数字表示与这些任务、职业或类别相关的对话占总对话数量的百分比。

在劳动力市场中绘制 AI 使用的分布图
我们的新论文延续了有关技术对劳动力市场影响的长期研究脉络，从工业革命时期的珍妮纺纱机到当今汽车制造中的机器人。我们聚焦于 AI 正在产生的持续影响。与许多预测或调查用户是否在使用 AI 的方法不同，我们直接使用了 AI 真实使用情况的数据。

基于职业任务的分析
我们的研究受到经济学文献中一个重要观点的启发：有时从“职业任务”而不是“职业本身”入手更为有效。不同的职业往往存在一些共同的任务和技能。例如，视觉模式识别是设计师、摄影师、安全检查员以及放射科医生的共同任务。

由于某些任务本身更易被新技术自动化或辅助完成，所以我们预计 AI 在经济中的采用，会针对特定任务而非整项职业进行。基于这种思路，从“任务层面”来分析 AI 对经济的影响，会为我们提供比只看“职业整体”更全面的视角。

使用 Clio 将 AI 使用情况与任务对应起来
本研究得以实施的关键在于我们使用了 Clio，它让我们能够在保护用户隐私的前提下分析用户与 Claude 的对话数据。1

具体做法是，利用 Clio 对大约一百万条来自 Claude（主要是 Claude ai 免费版和专业版）对话进行分析，将每条对话映射到最能代表该对话中 AI 所扮演角色的 ONET 任务上。ONET 即美国劳工部的职业信息网络，它包含了约 2 万个与工作相关的具体任务。然后，我们按照 O*NET 提供的框架，把这些任务归纳到相应的职业，最后再把这些职业聚类到更高一级的类别（如“教育和图书馆”、“商业和金融”等）。

上图展示了我们的 Clio 系统如何在确保用户对话私密性的情况下（左上）将对话聚合为职业任务（上中），再通过 O*NET 归纳为相应职业或职业类别（右上），最终得出不同类型的分析结果（下方）。

研究结果
AI 在不同职业类型中的使用。
从我们收集的数据来看，在“计算机与数学”类别（主要对应软件工程领域）的任务和职业中，AI 的使用最为集中，相关查询占到 Claude 对话量的 37.2%，涉及软件修改、代码调试以及网络故障排查等任务。

排在第二位的是“艺术、设计、体育、娱乐与媒体”类别，占 10.3% 的对话。其具体内容多为用户让 Claude 协助进行撰写和编辑等工作。不出所料，诸如“农业、渔业和林业”这类依赖大量体力劳动的职业类别（仅占所有查询的 0.1%）AI 使用率最低。

我们同时还比较了这些职业类别在整体劳动力市场中的占比（如下图所示的灰色部分），以及它们在 Claude 对话中的占比（如下图所示的橙色部分）。

橙色条表示 Claude 对话中与该职业类别相关的占比，灰色条表示劳动力市场中该职业类别的占比（数据来自美国劳工部 O*NET 分类）。

职业内部对 AI 的深度使用。
我们的分析发现，几乎没有某个职业在其大多数（至少 75%）的任务中都使用 AI，符合此条件的职业仅占约 4%。然而，较为温和的 AI 使用却很普遍：约 36% 的职业在其 25% 以上的任务中使用了 AI。

正如我们所预测的，这些数据并未显示整个职业被完全自动化的迹象；取而代之的是，AI 在整个经济中呈现出“扩散式应用”的趋势，对某些类型的任务影响更大，对另一些任务则较小。

AI 使用与薪资。
O*NET 数据库还列出了每个职业在美国的薪资中位数。我们将此信息纳入分析后，可以比较不同职业对应的薪资中位数与 AI 在这些职业的相关任务中的使用水平。

有趣的是，薪资水平较低和极高的职业使用 AI 的比例都相对较低（例如需要大量手动操作的洗发师，年薪较低；以及高薪的产科医生等）。相反，薪资处于中高水平的特定职业（如计算机程序员、文案撰稿人）在我们的数据中对 AI 的使用最为积极。

横轴为年度薪资，纵轴为该职业在 Claude 对话中的占比，一些有代表性的职业被突出显示。

自动化与增强。
我们也进一步探讨了任务的执行方式——具体来说，任务是由 AI“自动化完成”，还是作为对人类的“增强支持”。自动化指 AI 直接执行某些操作（例如给文档排版），而增强则指 AI 与用户协作完成任务。

总体而言，数据显示 AI 更多地被用来增强（57%），而非自动化（43%）。也就是说，在超过一半的案例中，AI 并没有取代人类来完成任务，而是与人类协同，如协助验证（例如帮用户核对工作）、学习（例如帮助用户掌握新知识或技能）或任务迭代（例如帮助用户头脑风暴或重复性的生成工作）。

此图展示了 Claude 对话中“增强”与“自动化”的总体比例，以及各自的任务子类型。报告中定义的子类型如下：指令式（Directive）：将整个任务完全交给 AI；反馈回路（Feedback Loop）：AI 在执行任务时会根据环境或其他反馈进行修正；任务迭代（Task Iteration）：AI 与用户反复协作、不断完善；学习（Learning）：帮助用户获取并理解新知识；验证（Validation）：对已有工作进行查验和改进。

注意事项
我们的研究为了解 AI 正在如何改变劳动力市场提供了独特视角，但同样存在以下局限性：

我们无法确定用户在 Claude 上为某项任务寻求帮助时，是否一定是为了工作需求。有人也可能为了写作兴趣或个人项目而让 Claude 提供写作、编辑建议。
同样，我们不清楚用户在获得 Claude 输出后如何使用。例如，他们是否直接复制粘贴了 Claude 的代码？还是先进行事实核查再使用？看似是“自动化”的任务，也可能在后续被用户手动完善，从而变成实际的“增强”过程。
此外，我们仅分析了 Claude ai 免费版和专业版的数据，而不包括 API、团队版或企业版用户。尽管 Claude ai 数据中包含了部分非工作场景，但我们使用了语言模型进行过滤，仅保留了与职业任务相关的内容。
由于涉及的任务数量庞大，Clio 可能会对部分对话的分类出现偏差。更多细节可参见论文正文及附录 B。
Claude 本身无法直接生成图像（除非通过编写代码的方式间接实现），因此一些可能需要创意图像的任务无法在此数据集中体现；
由于 Claude 同时也被推广为一款在代码处理方面表现出色的模型，因此与编程相关的用例在我们的数据中可能比一般 AI 应用更为突出。基于此，我们并未认为该数据集能完全代表 AI 的整体使用情况。
结论与未来研究
AI 的使用正在迅速扩展，而且模型也在不断升级，其在劳动力市场的影响或将很快发生显著改变。基于这一点，我们计划定期重复上述分析，以便追踪未来可能发生的社会与经济变革，并将结果及相关数据作为 Anthropic 经济指数的一部分进行持续发布。

这种纵向研究能让我们对 AI 与就业市场的关系有更多洞察。例如，我们可以监测特定职业内部使用 AI 深度的变化。如果未来依然只在某些任务中引入 AI，而只有少数职业在其大部分任务中使用 AI，那么我们可能面临的是多数岗位演变而非消失的未来。我们也可以追踪自动化与增强的比例变化，观察哪些领域开始出现更多的自动化趋势。

需要强调的是，本研究给出了 AI 实际使用的现状数据，但并未直接提供政策建议。如何为 AI 对劳动力市场的影响做好准备，不能仅依赖研究结论，还需要结合多方价值取向、实践经验和各种证据。我们期待未来能继续运用这一新方法，为相关问题提供更多佐证。

阅读完整报告，获取更多分析细节和研究结果。

开源数据与征求意见
本论文以及 Anthropic 经济指数最重要的贡献，是其所提供的全新方法与详细数据，用于研究 AI 带来的影响。我们现已将用于上述分析的数据集公开，并计划在未来继续公开更多数据。

完整数据集可在此处下载。

如果您是研究人员，欢迎通过此表单提供对我们数据的反馈或新的研究方向建议。

鸣谢
我们感谢以下学者在研究早期和论文草稿阶段给予的富有成效的评论与讨论：Jonathon Hazell、Anders Humlum、Molly Kinder、Anton Korinek、Benjamin Krause、Michael Kremer、John List、Ethan Mollick、Lilach Mollick、Arjun Ramani、Will Rinehart、Robert Seamans、Michael Webb 和 Chenzi Xu。



### 91

2025-02-11




Ling Yang
@LingYang_PKU
Thank 
@_akhaliq
 for sharing our latest work on LLM reasoning！Check it out https://github.com/Gen-Verse/ReasonFlux

翻译帖子
引用
AK
@_akhaliq
·
2月11日
ReasonFlux

Hierarchical LLM Reasoning via Scaling Thought Templates

### 92

2025-02-11



歸藏(guizang.ai)
@op7418
昨天看到飞书多维表格接入 Deepseek R1 后试了一下

妈的，这就是现在最强大的效率工具

由于表格是我们打工人接触的最多的交互，飞书多维表格还成了门槛最低的 Agents 工具

昨天整整玩了一天，搞了三个模版，从初级到高级，从文本到图片和视频，一篇文章直接教会你

👇下面是例子的介绍和教程：


### 93

2025-02-11

歸藏(guizang.ai)
@op7418
终于有给设计师用的 Cursor 了

Onlook 可以通过聊天生成基于 React + TailwindCSS 的网页，直接在浏览器 DOM 中进行实时编辑

选择想要调整的 DOM 层级可以很精准的编辑，生成的页面美学表现很好

会提醒你对页面进行色彩优化或者可读性测试来提高体验

生成的项目可以选择在 Cursor 打开继续构建



### 94

2025-02-11



小互
@imxiaohu
Anthropic CEO 巴黎 AI 行动峰会继续大放厥词

称：AI风险陡增 加强风险管控和监管迫在眉睫 

他说，如果当前的发展趋势持续下去，到 2026-2027 年（最晚 2030 年），AI 可能会变得像“一个充满超级天才的国家”。

这意味着 AI 系统的智能水平可能与人类最聪明的人相当，甚至在某些方面超越人类， 并会对经济、社会、国家安全产生极大影响。

他说：

🛑 “时间已经不多了，我们不能再犯错。”

如果各国政府、AI 公司和科学家们不立即采取行动，我们可能会：

❌ 失去对 AI 的控制，导致不可逆的安全风险
❌ 让专制国家在 AI 竞赛中超越民主国家，危害全球安全
❌ 让全球经济出现严重的不平等，导致社会危机


### 95

2025-02-11


宝玉
@dotey
https://x.com/CollinRugg/status/1889349078657716680/video/1 
美国副总统万斯在巴黎AI峰会上发表了演讲。他强调，美国将继续在人工智能领域保持领先地位，不会受到过度监管、意识形态偏见或审查的束缚，同时也会推动一条有利于工人的发展道路。

万斯提出了四个主要观点：

1. 现任政府将确保美国的AI技术继续保持世界领先水平，并成为各国政府和企业在拓展AI应用时的首选合作伙伴。

2. 过度监管可能会扼杀这个正处于起步阶段的颠覆性产业。美国将努力推行有利于AI行业发展的政策，并对这次峰会中提到的“减少监管”趋势表示肯定。

3. AI必须避免被任何意识形态所操控，美国不会允许AI成为威权审查的工具。

4. 特朗普政府将坚持一条支持劳工的AI发展道路，让AI成为在美国创造就业机会的重要动力。万斯还赞同莫迪总理的看法，认为AI能够帮助人们提升效率和生产力，而不是取代人类。AI的出现会让我们更加高效、富足并拥有更多自由。

***

万斯今天在巴黎AI峰会的演讲

感谢这番善意的介绍，我想先感谢马克龙总统主办此次活动，当然还有他昨晚带来的美味晚宴。在晚宴期间，马克龙总统看着我，问我是否愿意发言，我说：“总统先生，我是为了享受美好时光和免费红酒而来，但我今天必须要有所付出。” 我当然也要感谢莫迪总理能出席并共同主办此次峰会，还要感谢在座所有人的参与。

我今天早上并不是来谈论AI安全的，那是几年前这场会议的主题。我是来谈论AI机遇的。每当像这样的会议聚集起来讨论前沿技术时，我常常觉得我们的反应过于自我防范、过于害怕风险。然而，我从未见过有哪项技术突破能如此清晰地召唤我们去做恰恰相反的事情。

我们这届政府——也就是特朗普政府——相信AI将在经济创新、就业创造、国家安全、医疗保健、言论自由以及其他领域拥有数不胜数的革命性应用。而如果此时就限制其发展，不仅会让已经占据行业地位的企业不公平地受益，还意味着扼杀了这一代人所见过最有前景的技术之一。

现在，基于这些考量，我想提出今天的四个重点。第一，本届政府将确保美国的AI技术继续成为全球的黄金标准，并在其他国家以及企业扩展AI应用时，成为他们首选的合作伙伴。第二，我们相信，过度监管AI行业可能会在它刚刚起飞之际就扼杀这个具有变革性的产业，因此我们会尽一切努力来鼓励有利于增长的AI政策。我也很高兴看到放松管制的理念正在本次会议的许多讨论中得到体现。第三，我们非常坚信，AI必须免于意识形态偏见，而美国的AI不会被改造成威权审查的工具。最后，第四，特朗普政府将为AI保持一条有利于劳动者的增长路径，使其能够成为在美国创造就业的重要工具。我也赞同莫迪总理的观点。我真的相信AI将帮助人们提高生产力，而不是取代人类。它永远都不会取代人类。我认为，AI行业里有太多领导者在谈到取代工人的恐惧时，真的忽略了重点。我们相信，AI会让我们更具生产力、更繁荣，也更自由。

美利坚合众国在AI领域处于领先地位，我们的政府计划继续保持这种领先优势。美国拥有整个AI技术栈所需的所有组件，包括先进的半导体设计、前沿算法，以及具有变革性的应用。当然，这个技术栈所需的计算能力对推动AI技术的发展至关重要。为了维护美国的优势，特朗普政府将确保最强大的AI系统在美国本土建造，并使用美国设计和制造的芯片。

当然，仅仅因为我们是领头羊并不意味着我们想要或需要单打独斗。让我郑重强调这一点：美国希望与各位合作。我们希望以开放与协作的精神共同开启眼前的AI革命。但要建立这样的信任，我们需要能够促进AI技术发展的国际监管体系，而不是扼杀它。我们尤其需要我们的欧洲朋友以乐观而非惶恐的心态来面对这一新的前沿领域。

美国能发展出最前沿的AI并非偶然。通过保持一个开放的监管环境，我们鼓励了美国的创新者进行实验并投入前所未有的研发资金。到2028年，预计全球在AI领域的支出约为7000亿美元，其中超过一半很可能会投资在美国。

本届政府不会扼杀那些由初创企业和研究生们所创造的、最具突破性的人工智能应用。相反，我们的法律将确保大型科技公司、小型科技公司以及所有其他开发者都在同一公平环境中竞争。关于总统最近在AI方面签署的行政命令，我们正在制定一份AI行动计划，既能避免过度谨慎的监管体制，又能确保所有美国人都能从这项技术及其变革潜力中受益。现在，如果这种模式适合贵国，我们也邀请各位与我们合作并加以借鉴。

然而，特朗普政府对于一些外媒报道感到担忧：有些外国政府正考虑对美国那些具有国际影响力的科技公司收紧管制。美国不能也不会接受这种做法，我们认为这不仅对美国是个严重错误，对这些国家自身也同样错误。各种规模的美国创新者早已体会过应对繁琐国际规则的滋味。我们许多高产能的科技公司被迫应对欧盟《数字服务法案》以及其在内容移除和所谓错误信息监管方面制定的庞大规则。当然，我们希望确保互联网是一个安全的空间，但阻止在线捕食者伤害儿童和阻止成年人访问政府认为是“错误信息”的观点，这二者有着根本的不同。与此同时，对规模较小的企业而言，应对《通用数据保护条例》（GDPR）意味着无休止的法律合规成本，否则就有可能面临巨额罚款。对一些企业来说，为了避免这种进退两难的局面，他们最简单的办法就是直接屏蔽欧盟用户。先生们女士们，这真的是我们想要的未来吗？我想我们所有人的答案都应该是否定的。

在涉及能源的问题上，没有比监管更让我们担忧的了。同样，我也感谢本次会议上许多人的观点，因为他们都认识到我们正处在一个渴求可靠能源和高质量半导体的AI产业前沿。然而，我们的许多朋友一方面在去工业化，另一方面却把可靠电力赶出了自己的国家和电网。AI的未来不可能靠对安全的杞人忧天来赢得，而是要通过建立可靠的发电厂，以及能够生产未来所需芯片的制造设施来实现。

就我个人而言，AI最令我兴奋的地方在于它根植于真实且物质的经济之中。这个行业的成功不仅仅是聪明人坐在电脑屏幕前编程的结果，它还依赖那些亲手操作的人。即使是机器人技术也会改变我们的工厂，它当然能使我们的医疗服务提供者在治病方面更有成效，但同时也依赖那些医疗人员、医生和护士所产生的数据。我相信，它将帮助我们在未来创造并储存新的能源模式，但就眼下而言，如果世界没有建设好支持AI的能源基础设施，AI就无法真正起飞。

我认为，过去20年的技术创新往往让人想到一些聪明人盯着电脑屏幕，在比特的世界里进行工程设计。但AI经济主要将依赖并改变原子层面的世界。此刻，我们正面临一场新的工业革命的非凡前景，它可与蒸汽机或贝氏炼钢法的发明相提并论。然而，如果过度监管让创新者望而却步，我们就永远无法取得这些必要的进步；同样，如果我们允许AI被那些企图利用这项技术来审查或控制用户思想的庞大企业所主导，这场革命也不会发生。

我想请大家退一步，问问自己：是谁最积极地要求我们，也就是今天在场的政治领导人，推行最严厉的监管？很多时候，这些要求来自已经在市场上拥有既得利益的人。当一个庞大的现有企业来找我们要求制定安全监管时，我们应当质问，这项安全监管究竟是为了人民的利益，还是为了维护这家现有企业的利益？

在过去几年里，我们看到一些政府、企业和非营利组织通过AI推进了一些不得人心、甚至在我看来完全背离历史的社会议程。在美国，我们曾见到有AI图像生成器试图告诉我们乔治·华盛顿是黑人，或者说一战时期的美国士兵其实是女性。现在回头看，我们会觉得很可笑，当然这确实荒诞不经，但我们必须记住这荒诞时刻带给我们的教训。我们从中了解到，特朗普政府将确保在美国开发的AI系统不带有意识形态偏见，绝不限制公民的言论自由。我们相信我们的人民有能力独立思考、获取信息、形成自己的观点，并在公开的思想市场中彼此辩论。

我们也看到一些敌对的外国对手将AI软件武器化，用来改写历史和审查言论。当然，这并不是什么新鲜事。和他们对待其他技术一样，一些威权政权也通过窃取并使用AI来增强其军事情报和监控能力，窃取外国数据，并制造宣传来破坏其他国家的国家安全。我想明确表示：本届政府会彻底阻止这类行为。我们将保护美国的AI和芯片技术不被盗窃或滥用，并与我们的盟友和伙伴合作，加强并扩大这些防护措施，切断对手获得威胁我们所有人的AI能力的途径。

我也要提醒今天在场的国际友人，与这些政权合作从长远来看绝不会有好处。从闭路电视（CCTV）到5G设备，我们都很熟悉那些由威权政权补贴并出口到市场上的廉价技术。但正如我所知，并且我认为这里有些人也有过类似的经验，与他们合作就意味着把你的国家捆绑给一个试图渗透、深耕并控制你信息基础设施的威权主宰。如果一桩交易看起来好得令人难以置信，那就要记住我们在硅谷学到的一句老话：如果你没有为产品付费，那么你就是产品。

最后，本届政府想明确说明最后一点：我们将在AI政策中始终以美国工人为中心。我们拒绝将AI视为一种必然取代劳动力的纯颠覆性技术。我们相信并会推动相关政策，确保AI能够提升工人的生产力，并期望他们能因此获得更高的工资、更好的福利，以及更安全、更繁荣的社区。从法律到医学，再到制造业，AI最直接的应用几乎都是在辅助而不是取代美国人所进行的工作。现在，再加上本届政府在移民问题上的“工人优先”立场，我们相信，一旦美国劳动力准备好充分利用AI，反而会吸引那些将部分岗位外包到海外的企业回流。为此，本届政府将确保美国拥有世界上最优秀的受训劳动力。我们的学校会教学生如何管理、监督以及与AI工具互动，因为这些工具将越来越多地成为我们日常生活的一部分。随着AI创造新的就业岗位和行业，我们的政府、企业和劳动组织有义务共同努力，让工人受益，不仅在美国全国范围内，也在全球范围内。为此，对于联邦政府出台的所有主要AI政策决定，特朗普政府都会保证美国工人在决策桌上拥有一席之地，我们对此深感自豪。

好了，我已经占用了够多的时间，接下来我想用一个简短的故事来结束我的发言。

这是一个美丽的国家，马克龙总统，我知道你对此深感自豪，也理应如此。昨天，我带着我的三个孩子，与 Gravêthe 将军一起游览巴黎的荣军院时，他非常友善地向我展示了那把属于我们美国革命期间最亲密的国际友人——拉法耶特侯爵——的佩剑。他允许我拿起那把剑，但当然，在此之前他让我戴上了白手套。这让我开始思考这个国家——法国，以及我的祖国，还有我们通过那样的军刀所共同缔造的美好文明。武器若落入不当之人之手将会非常危险，但在对的人手里却是争取自由与繁荣的不可思议的工具。

我不禁想到今天的会议，如果我们在那些同样被视为危险的事物（比如AI）上选择了错误的方法，选择束缚自己，那将不仅影响我们的GDP或股市，还会改变拉法耶特和美国开国者当年所要开创的事业的未来。当然，这并不意味着我们要把所有安全担忧都抛诸脑后，但重点至关重要。我们现在必须聚焦于抓住这稍纵即逝的机会，释放我们最杰出的创新者的潜能，并利用AI来改善我们国家和人民的福祉。我可以非常自信地说，特朗普政府不会浪费这个机会。我们也希望今天在座的所有人都有同样的感受。谢谢你们，愿上帝保佑你们。谢谢。



### 96

2025-02-11


宝玉
@dotey
来自 Anthropic CEO Dario Amodei 在巴黎 AI 行动峰会上的声明 [译]

我们很高兴参加在巴黎举行的「人工智能行动峰会」，并且对法国政府所做的努力表示感谢。此次峰会汇聚了来自全球的人工智能公司、研究人员和政策制定者，共同探讨如何负责任地推动AI（人工智能）为全人类带来益处。我们与他们的目标一致，然而，鉴于当前技术迅速发展的态势，我们认为在多个议题上需要更高的关注度和紧迫感。民主国家如何保持领先地位、AI带来的风险、以及即将到来的经济转型——这些都应该成为下届峰会的核心主题。

时间紧迫，我们必须让行动速度跟得上AI进步的节奏。最早可能在2026或2027年（参考此链接[1]），甚至很可能在2030年之前，AI系统的能力会强大到可以被视为相当于一个由高度智能人群组成、突然出现在全球舞台上的“新型国家”——或者说是“坐落在数据中心中的天才国度”。这将对经济、社会和安全领域产生深远影响。这样的技术既蕴含了有史以来前所未有的经济、科学和人道主义机遇[2]，也带来了需要慎重应对的重大风险。

一、确保民主社会在AI领域保持领先
首先，我们必须确保民主社会在AI方面处于主导地位，防止威权国家（即缺乏民主监督的国家）利用AI来建立全球军事霸权。我们尤其需要关注AI供应链的治理，比如芯片、半导体制造设备以及网络安全等；同时，也要审慎使用AI技术来保卫自由社会。

二、全面应对AI不断上升的安全风险
第二，各国之间关于AI的对话必须更充分地讨论这一技术日益增长的安全风险。高度先进的AI可能带来重大的全球安全隐患，既包括非国家行为体（注：指组织或个人，而非政府）滥用AI系统（例如在化学、生物、放射性或核武器领域，也被称为CBRN领域），也包括功能极其强大的AI系统本身可能出现的自主风险。

在峰会召开前，近100位全球顶尖专家发布了一份科学报告[3]，指出通用型AI有可能在某些情况下助长严重的错误用途或导致“失去控制”的极端情景。Anthropic（达里奥·阿莫迪所在机构）的研究也显示了大量证据[4]，如果训练不当，AI模型会欺骗用户，并可能为了自身目标而采取意想不到的行为，即使这些模型最初是以看似无害的方式进行训练的。

目前，有超过16家前沿AI公司承诺在安全和防护方面采取措施。Anthropic也在2023年9月首批发布了自己的《负责任扩展政策》（Responsible Scaling Policy）[5]，这是同类政策中的首个。但我们同时认为，政府需要对这些安全计划的透明度进行监管，并且应大力推动对网络攻击、CBRN、AI自主性等全球安全风险进行有效评估，包括由第三方评估机构[6]来对在其国内开展业务的开发者进行测试和监督。

三、在经济变革中让人人受益
第三，AI有潜力极大地推动全球经济增长，但也可能带来巨大的冲击和变革。一个“坐落在数据中心中的天才国度”可能意味着人类历史上对劳动力市场最大规模的改变。第一步应当是监测和观测当前AI系统对经济的影响。正因如此，我们在本周发布了「Anthropic经济指数」（Anthropic Economic Index）[7]，用于追踪人们使用我们AI系统时所从事经济活动的分布情况，包括这些活动是增强（augment）还是替代（automate）人类现有工作。我们也呼吁各国政府利用其更强大的资源开展类似的测量和监测工作，并最终制定政策，以保证所有人都能共享非常强大的AI所带来的经济红利。

展望下一次峰会
在下一场国际峰会上，我们不应该再错失良机。上述三个问题应当成为会议的核心议程。AI的持续进步正在带来重大的全球性挑战，我们需要以更快的行动和更清晰的思路来应对。

原文：Statement from Dario Amodei on the Paris AI Action Summit[8]

译者注：文中提到的“CBRN”指的是 Chemical（化学）、Biological（生物）、Radiological（放射性）和Nuclear（核武器）四类武器或材料的合称；“非国家行为体”则指不代表正式政府的组织或个人；“第三方评估机构”是指独立于开发者和政府的专业审查组织。


### 97

2025-02-11

宝玉
@dotey
记者: Sam Altman，当然，现在的头条是伊隆·马斯克正在对 OpenAI 发起收购，你对此有什么回应？

Sam: 你拒绝了他提出的 970 亿美元报价。我的意思是，再看看吧。他并不打算出售。OpenAI 的使命不出售。你知道，我一直以来都在尝试各种事情。这是你知道的本周的话题。你很认真地对待它。就是这样。

记者: 你认为他这样做是想达到什么吗？

Sam: 我觉得他大概只是想拖慢我们的进度。他显然是一个竞争对手。你知道的，他很努力，并且为 XAI 筹集了大量资金，他们正试图在技术层面以及产品上市方面与我们竞争。我希望他能通过打造更好的产品来竞争，但我认为已经出现了很多手段、许多诉讼，以及各种疯狂的事情。现在又来了这一出，而我们会尽量埋头继续工作。

记者: 这是否会让 OpenAI 从非营利模式转向营利模式变得更困难？

Sam: 我们并没有打算转向营利模式。我们并不确定是否会那样做，但无论如何，非营利部分仍然会非常重要。它将推动我们的使命。并将继续存在。董事会正在考虑很多方案，以便在下一阶段找到最佳架构，但非营利部分不会作任何改变，也不会消失。

记者: 好的。你在巴黎 AI 峰会的主要任务是什么？你们有"星际之门"项目。关于你们实际会投入多少，外界有一些疑问。也许你能给我们一些数字，Sam。你和你的团队在这里想传达什么信息？

Sam: 我之前在 Blessley Park 参加过这个活动的早期版本，那次更关注安全问题。这一次，人们仍在讨论安全，但我认为现在大家会说，好吧，这项技术已经到来。而且影响巨大，我们必须推动它的发展。有很多人问到如何使用这项技术。也许我遇到的最常见问题是，"你能在我所在的国家建立'星际之门'吗？"我们这里需要基础设施。我们想做这件事。你能帮忙吗？这确实是个常见的问题。但还有很多其他问题，比如我们要如何部署这项技术来确保人们受益。它将走向何方？这个模型又会以什么方式改进？上周我们发布了一个叫做 Deep Research 的项目，引发了大量提问。我们如何才能用它真正推动经济增长？也许经济增长是这里最受关注的问题。

记者: 你对 DeepSeek 有更多了解吗？我知道你和团队一直在调查，看他们是否做了模型蒸馏，或者是否不恰当地使用了你们的推理数据。你有没有更明确的消息？我的意思是，他们到底有没有做出一个好的模型？

Sam: 很多人都会从其他模型中进行蒸馏。再说一遍，我对我们的研究路线图和产品路线图都很有信心，所以你知道，DeepSeek 会做他们想做的事，其他人也会做他们想做的事。而我们只会尽力打造最好的技术，并让它进入人们的手中。我认为总体来说这一点做得还不错。

记者: 你觉得马斯克的做法是因为他对 XAI 感到不安吗？

Sam: 也许他一辈子都处于一种不安的状态。我同情那家伙。

记者: 你同情他？

Sam: 是的，真的。我不认为他是一个快乐的人。我确实为他感到难过。

记者: 你是否担心他与总统关系密切，从而影响美国总统在人工智能议程上的决策和政策？

Sam: 并不是特别担心。也许我应该担心，但并没有特别担心。我只是尽量每天醒来思考如何让我们的技术变得更好。

记者: Sam Altman，谢谢你，非常感谢。






### 98

2025-02-11


Leonie
@helloiamleonie
Make RAG results more trustworthy with citations.

In his latest recipe, 
@drdannywilliams
 shows you how you can build a RAG pipeline with citations, using:
- a 
@weaviate_io
  vector database and
- 
@AnthropicAI
's Claude 3.5 Sonnet

📌 Code: https://github.com/weaviate/recipes/blob/main/weaviate-features/generative-search/generative_search_anthropic/rag_with_anthropic_citations.ipynb


### 99

2025-02-11


Gorden Sun
@Gorden_Sun
FireRedASR：小红书开源的语音识别模型
支持识别普通话、方言、英文，分2个版本：
FireRedASR-LLM：8.3B，为端到端的语音多模态LLM设计，能力更强，中文准确率开源最佳
FireRedASR-AED：1.1B，兼具效率和效果。
Github：https://github.com/FireRedTeam/FireRedASR
模型：https://huggingface.co/FireRedTeam



### 100

2025-02-11


宝玉
@dotey
苹果与阿里合作，在iPhone上提供AI

The information：据知情人士透露，苹果公司已与中国电商巨头阿里巴巴集团达成合作，共同开发面向中国市场的人工智能功能。这是苹果为扭转在华销量持续下滑而推出的软件升级战略，目前双方联合开发的AI功能已提交中国网信部门审批。

面对华为、vivo等国产品牌的强势竞争，苹果2023年销售额在华已连续两年下滑。最新财报显示，2024财年大中华区营收同比下跌7.7%，其中12月季度跌幅达11%。CEO库克在财报会议上坦承，iPhone缺乏AI功能是重要原因。

以及，另一个爆料：
三星的「神秘AI」，是智谱

来自赛博禅心


### 101

2025-02-11

小互
@imxiaohu
OpenAI 新论文：使用大型推理模型进行竞赛编程

强化学习如何提升大语言模型在编程和推理任务中的表现

核心研究发现

1️⃣ 强化学习可以显著提升 AI 编程能力！

2️⃣ o1-ioi 通过手工优化策略，在 2024 IOI 竞赛中取得 金牌水平。

3️⃣ o3（新一代 AI）完全不依赖手工优化，却比 o1-ioi 还强！

4️⃣ o3 在 CodeForces 评分 达到 2724（99.8% 百分位），接近顶级人类选手。

OpenAI比较了三种 AI 编程系统：

o1：通用大语言模型（LLM），基于强化学习（RL），具备基本推理能力。

o1-ioi：个针对 2024 年国际信息学奥林匹克竞赛（IOI） 设计的领域专用系统 o1-ioi（采用了手工设计的推理策略）。

o3：完全基于强化学习（RL），自动学习最优解题方法，不需要人工设计策略。我们展示了将强化学习（RL）应用于大型语言模型（LLM）可以显著提升其在复杂编程和推理任务中的表现。

在 2024 年 IOI 现场比赛中，我们使用 o1-ioi 参赛，并通过人工优化的测试时（test-time）策略，在 49% 百分位取得成绩。在放宽比赛限制的情况下，o1-ioi 甚至达到了金牌水平。

然而，在评估后续的 o3 模型时，我们发现它无需人工设计的推理策略或放宽比赛限制，便可直接获得 IOI 金牌。

我们的研究结果表明，尽管 o1-ioi 这类专门优化的管道能带来显著提升，但 更大规模的通用模型 o3 已经能够超越这些优化版本，并不依赖人工定义的推理策略。

特别是，o3 在 2024 IOI 取得金牌，并在 CodeForces 编程竞赛中获得与人类顶级选手相当的评分。

📢 结果表明，AI 编程不再需要手工优化，与其依赖特定领域的优化策略，更有效的路径是扩展通用的强化学习技术，以实现最先进的 AI 竞赛编程能力。


### 102

2025-02-11

宝玉
@dotey
收到一位新手算法工程师的来信，咨询我：
>“在 AI 时代，既然 AI 能生成高效的算法实现，那么新手该如何有效进行代码的设计和验证？”

这确实是当下新手工程师特别关心的问题。毕竟，AI 现在能轻松产出高质量的实现代码，可新人既缺乏“拆解需求”和“设计方案”的经验，又需要面对迅速变动的技术场景，难免会容易焦虑着急。

很多人会设想一种“理想状态”：我们先把需求细分成相对独立且定义明确的模块，然后把接口、数据结构、边界条件等都告诉 AI，AI 再自动完成这个模块的实现。最后，只要进行验证，就大功告成了。但现实中，别说新手，就算是已经有了几年开发经验的工程师而言，要掌握从需求到模块的拆分，再到最后测试和调优，这条链路很长，也很考验“工程能力”。

所以我对于 AI 时代的工程师的建议是：：
> AI 时代，工程师仍需要掌握两大基础能力：编程技能和工程能力。

---

** 编程技能：AI 时代仍需“做中学”

很多人会问：既然 AI 能写代码了，那我是不是就不用苦练“自己写”这件事？答案并不绝对。

- 编程是技能
就像学游泳或学骑车，如果你从头到尾都不下水，只是在岸上看视频或让别人代替你游，你自己很难真正学会。编程同理，需要动手才能真正理解和掌握。

- AI 帮你加速，但不能完全取代你的动手实践
比如，你遇到一个功能需求，不妨先自行思考一下可能的实现思路，然后让 AI 生成一个方案。接着，你可以亲手去改动、调试，甚至故意“手写一遍”看是否顺畅，或者是否能够理解 AI 生成的关键逻辑。只有这样，你才能更熟练地掌握编程能力，真正知道代码在做什么，而不只是“让 AI 代写”。

- 写得快已不再是全部目标
过去我们常常追求写代码又快又好，可是在 AI 的帮助下，“写得快”可以部分交给 AI，我们更多精力应投入到结构设计、逻辑思考、验证测试等更具价值的工作上。

---

** 工程能力：从需求到可持续维护的系统

要想真正把需求落地成一套可运行、可维护、可演进的软件系统，工程能力就尤其关键了。它涉及到从需求分析、架构设计、实现编码、验证测试、运维部署到持续迭代的一整个流程，也可以理解为把需求变成可持续维护系统的综合能力。

试着想象一下，一个合格的（也可以说是“专业的”）工程师在日常开发中都要做些什么：

1. 需求和场景理解
- 与需求方沟通，确认数据规模、并发量、安全合规要求等，这能避免后续返工或踩坑。

2. 架构设计与技术选型
- 考虑技术栈、模块划分、API 设计等，并兼顾成本、性能、可扩展性，才能保证后面不会“撞墙”。

3. 测试与质量保证
- 包含单元测试、集成测试、端到端测试等，各类测试在不同层面保障质量。
- 通过持续集成（CI），快速发现改动对已有功能的影响。
- 新手尤其要培养“多写单元测试、用测试验证逻辑”的习惯，这对识别 AI 生成代码的缺陷非常有效。

4. 运维与监控
- 上线后如何发现错误、记录日志并快速定位问题，如何保障系统稳定运行，都需要事先规划。

5. 团队协作与项目管理
- 多人协作怎么做 Code Review？版本管理和需求排期如何安排？这些都属于工程能力的一部分，也是让团队高效协作的关键。

---

** AI 时代下，工程能力的新挑战与机遇

虽然 AI 在编程层面突飞猛进，可以生成各种模块、自动化测试脚本，但在以下这些方面依旧需要人类发挥主导作用：

1. 掌控需求到实现的链路
- AI 只能依据你给的描述去生成实现。若需求描述和拆分不到位，AI 写出的代码很可能在后期难以集成或维护。
- 只有具备扎实的工程能力，才能确保需求、设计、实现三位一体。

2. 审阅与调试 AI 生成代码
- AI 写的实现并不总是完善，它可能忽略边界条件，也可能在性能或安全合规上欠考虑。
- 需要工程经验去审阅、调试，并结合单元测试、日志监控等手段，验证代码的正确性和鲁棒性。

3. 架构与模块拆分
- 哪些部分适合让 AI 来生成？哪些部分需资深工程师自己写？
- 整个系统的版本、模块管理如何协调？在这些领域里，工程师对系统全局的把控能力非常重要。

4. 数据与安全合规
- 特别是算法工程师，常常涉及数据管线、数据隐私与合规等复杂场景。
- AI 生成一段跑模型的代码很容易，但若要兼顾隐私合规、合理负载、监控报警，就离不开工程化的思维。

---

** 如何提升工程能力：实战中历练，持续总结

既然工程能力如此重要，该如何让自己成长得更快？以下几点建议可能对你有所帮助：

1. 多动手维护实际项目
- 读书和看文档可以打基础，但实际开发的踩坑和复盘最能帮你快速建立认知。小到个人开源项目，大到公司内部复杂系统，都能让你看到“设计-实现-测试-部署”的全流程。

2. 吸收业界最佳实践
- 去读优秀开源项目的源码，仔细观察他们如何组织目录结构、如何写测试、如何做持续集成；或者在团队里多参与 Code Review，学习他人写码和思考的方式。

3. 熟悉工具链与自动化
- 尝试了解并实践 CI/CD 流程，掌握单元测试框架、配置管理、运维监控工具等。这些在实际工程中都是必不可少的一环。

4. 主动思考架构与性能
- 无论是后端服务的分布式架构，前端的工程化，还是机器学习训练管线等，都有相应的设计模式和性能优化思路。多思考如何在逻辑与工程层面做得更好，而不是单纯依赖 AI 给出的实现。

5. 培养文档与沟通习惯
- 工程并非个人英雄主义。“写在你脑海里”的想法也需要变成清晰的文档、需求说明、接口规范、部署指南，这样不仅帮助团队，也有利于自我总结。

---

总结一下：
- 在 AI 时代，能帮我们写代码的“工具”越来越多，但“如何保证写得对”“如何把需求从无到有构建成高可维护、高可靠的系统”才是人类工程师真正的价值所在。
- 编程技能仍需“做中学”：AI 辅助写代码并不能完全替代亲自动手，不然难以真正掌握技术本质。通过实际项目增强经验：多踩坑、多总结，是积累工程思维的关键。
- 对于新手工程师，首先要在实践中不断提升编程技能，要能理解代码、能手写关键逻辑，另一方面，更要把精力放在工程能力上：需求分析、架构设计、模块拆分、测试与持续集成等。
- AI 不能替你做“架构设计与技术选型”：它只能在给定的框架内去编程，如何拆分、怎么确保安全与性能，依旧仰赖工程师的决策。

希望以上这些思路对你有所启发，也祝你能在 AI 时代下，快速成长为一名具备强大工程能力的算法工程师。加油！


### 103

2025-02-11


歸藏(guizang.ai)
@op7418
新的开源推理模型 OpenThinker 32B 和 7B

利用 R1 的数据集训练的，数据集规模为 800K

其中 32B 模型在 MATH500 和 GPQA Diamond 中表现优于所有 32B 模型包括 Deepseek 自己蒸馏的 32B
引用
Negin Raoof
@NeginRaoof_
·
2月13日
回复 @NeginRaoof_
Blog Post: https://open-thoughts.ai/blog/scale
Model Link: https://huggingface.co/open-thoughts/OpenThinker-32B
Dataset: https://huggingface.co/datasets/open-thoughts/OpenThoughts-114k
Data Curation Code: https://github.com/open-thoughts/open-thoughts


### 104

2025-02-13

AI Dance
@AI_Whisper_X
大模型卷Agent，智谱AI这次是要先下一城？ 🤔

从春节到现在，DeepSeek风头无两，直接盖住了六小虎+几家大厂的所有热度。
多少人都觉得，大模型格局已定？
我们一直期待着其他人的声音，没想到，吹响反攻第一枪的竟然是智谱。

今天，三星正式发布了基于最新Galaxy AI的Galaxy S25系列手机，智谱 Agentic GLM 实现在系统级无缝嵌入，让Galaxy S25系列具备了处理文本、语音、图像和视频等多模态数据的能力，同时还能使用工具，具备自主行动能力，确实让人眼前一亮。
- 语聊视界：全球首次实现超低延时AI视频通话，支持图片和视频输入。支持多轮记忆和Function Call，翻译、搜索等场景体验颠覆性。比如，你可以通过语音直接设置闹钟，或者调用智谱清言智能体进行搜索。
- 社交媒体文案代写：基于任何图片素材，AI就能自动生成朋友圈、小红书、微博的文案。哎。。人类负责拍，AI负责写，感觉我们都快成"碳基机器人"了……
- Now Brief即时简报（我最喜欢的功能）：你的智能小助理，日程管理、路线规划、要闻速递都能搞定（期待加了AI之后的使用体验）。
同时，智谱旗下C端产品智谱清言，也成为了Galaxy S25系列的出厂预装AI产品（这可是无数APP梦寐以求的地位啊！）。

智谱确实是六家大模型创业公司里最早一批投入端侧AI的公司，一边和终端厂商（比如三星、荣耀）合作，一边和芯片厂商（高通、英特尔）深度绑定。在之前的Agent OpenDay上，还曾经秀了一波肌肉，发布了三款产品：
- AutoGLM：手机端AI助手，能帮你点外卖、订酒店、发朋友圈
- AutoGLM-Web：浏览器上的智能体（类似Operator和Computer Use）
- GLM-PC：电脑端智能体

如我们之前的预测，随着大模型赛道的竞争加剧，六小虎正在寻找自己的突围方向：
- 智谱：狂卷Agent
- Kimi：小镇做题家
- MiniMax：视频模型、多模态
- 百川：医疗领域
最近，很多声音都在预测：2025年，基于推理模型的Agent及其应用可能会迎来爆发。
而智谱这次，或许真的提前别人走了一步？

你怎么看？智谱会成为第一个把Agent"卷"出来的大模型公司吗？欢迎留言讨论！




### 105

2025-02-13


宝玉
@dotey
OpenAI CEO Sam Altman 刚刚在 X 上透露了 GPT-4.5 与 GPT-5 的最新路线图。首先，OpenAI 将推出代号 “Orion” 的 GPT-4.5，这也是他们最后一款“非链式思维（non-chain-of-thought）”模型。随后，OpenAI 将致力于融合 o 系列与 GPT 系列，推出整合多项新功能的 GPT-5。

值得注意的是，ChatGPT 的免费用户可在默认“标准智能”设定下使用 GPT-5，并在滥用阈值内享受无限次对话。Plus 订阅者与 Pro 订阅者则可分别解锁更高智能等级的 GPT-5。此外，GPT-5 将深度融合语音、画布、搜索、深度研究等多种功能，全面提升用户体验。

对于具体发布时间，Sam Altman 回应称这两款模型在“数周或数月内”与大家见面，敬请期待。

以下内容转译自推文
---

关于 GPT-4.5 和 GPT-5 的路线图更新

我们希望能够更好地分享我们的未来规划，并在简化产品服务方面做得更好。  
我们希望 AI 能够“对你来说就是能用”，因为我们意识到目前的模型和产品选择对很多人来说变得过于复杂。  

我们跟你们一样，不喜欢“模型选择器”（即目前让你在不同 GPT 模型之间自行挑选的功能），我们希望回到那种“神奇的统一智能”——也就是说，让系统自动选择或组合最合适的模型，让你无需纠结。

接下来，我们会发布 GPT-4.5（内部代号“Orion”），这是我们最后一个**非“思维链（chain-of-thought）”** 模型。  
> **思维链（chain-of-thought）** 通常指的是AI在生成回答时，会将中间推理步骤也纳入思考过程，从而能更好地理解和处理复杂问题。

在那之后，我们的首要目标之一是把 “o 系列模型”（内部研发系列） 和 “GPT 系列模型” 整合起来，构建一套既能利用所有工具、又能自行判断何时需要进行深入思考或简短回答，并可广泛适用于各种任务的系统。

无论是在 ChatGPT 还是在我们的 API 中，我们都将推出整合了大量技术（包括 o3）的 GPT-5。届时我们将不再单独发布 “o3” 这个独立模型。  
> **o3** 是 OpenAI 内部的某个重要模型或技术代号，之前与 GPT 系列分开开发，现在将被合并进 GPT-5 中。

在 ChatGPT 免费版（Free Tier）中，所有用户都可以无限制地使用 GPT-5，**在标准智能水平下**畅聊（但仍须遵守防滥用阈值，即若系统检测到严重滥用或异常使用时可能会进行限制）。  

“Plus” 付费用户可以在更高的智能水平上使用 GPT-5；“Pro” 付费用户则可在更高阶版本上使用 GPT-5。这些高级版本还会整合语音交互（voice）、画布（canvas）、搜索（search）、深度研究（Deep Research）等更多功能。
引用
Sam Altman

@sama
·
2月13日
OPENAI ROADMAP UPDATE FOR GPT-4.5 and GPT-5:

We want to do a better job of sharing our intended roadmap, and a much better job simplifying our product offerings.


### 106

2025-02-13

GitHubDaily
@GitHub_Daily
一份由 Hugging Face 出品关于智能体的课程：Agents Course。

共有五个章节，涵盖了从智能体基础介绍到使用各种框架的构建实际应用案例，最终以构建一个基准测试项目结束。

GitHub：https://github.com/huggingface/agents-course

课程内容目前还没有完成，从往期 Hugging Face 出品的课程来看质量都是相当不错的。



### 107

2025-02-13

Leonie
@helloiamleonie
Building multilingual RAG applications?

Nomic AI’s new Mixture of Experts embedding model is here!

@nomic_ai
 has just released nomic-embed-text-v2-moe. 

It’s an MoE embedding model with SOTA multilingual retrieval performance:
• Performance: competitive with models 2x in size
• Multilingual: Supports over 100 languages
• Architecture: Mixture of Experts (8 experts with top-2 routing)
• Storage: Matryoshka embeddings with up to 3x reductions in storage cost at minimal performance loss (768-256 dimensions)
• Fully Open-Source: Weights, code, and training data publicly available
• License: Commercially permissible Apache 2.0 license

Check it out on the 
@huggingface
 model page: https://huggingface.co/nomic-ai/nomic-embed-text-v2-moe

Start using it immediately through 
@weaviate_io
's HF integration: https://weaviate.io/developers/weaviate/model-providers/huggingface



### 108

2025-02-13

Tuana
@tuanacelik
Agentic AI can seem a bit like wizardry. So I'm happy to share this in depth intro to AI agents that I've been working on with 
@PrajjwalYd
 💚

The way I like to explain it is by comparing most LLMs in agentic AI applications today to a wizard with a spell book (tools). It's been granted instructions to a bunch of spells it can cast 🪄

Learn about:
📜 A bit of the history behind AI agents
🛠️ Components that make up an AI agent
and more, in our blog 👇
AND, tanks to 
@helloiamleonie
 for all the help 🤝



### 109

2025-02-13

歸藏(guizang.ai)
@op7418
这个想法太🐂🍺了，一个能够不断预判未来5步的 AI

确保用户在对话中更精准地获得预期的结果

想法来自于顶级象棋引擎Stockfish的决策机制（一个正是因为不像人类思维才能完胜人类的最强棋类引擎）


### 110

2025-02-13


歸藏(guizang.ai)
@op7418
来了！！Deepseek 发布最佳的 R1 模型设置

- 无系统提示
- Temperature: 0.6
- 缓解模型绕过思考的方式
- 官方的搜索和文件上传提示

详细的提示在下面👇
引用
DeepSeek
@deepseek_ai
·
2月14日
🎉 Excited to see everyone’s enthusiasm for deploying DeepSeek-R1! Here are our recommended settings for the best experience:

• No system prompt
• Temperature: 0.6
• Official prompts for search & file upload:  http://bit.ly/4hyH8np
• Guidelines to mitigate model bypass
显示更多
下午5:28 · 2025年2月14日
·
7.6万
 查看

歸藏(guizang.ai)
@op7418
·
2月14日
Deepseek R1 官方搜索提示词

  For Chinese query, we use the prompt:
```
search_answer_zh_template = \
'''# 以下内容是基于用户发送的消息的搜索结果:
{search_results}
在我给你的搜索结果中，每个结果都是[webpage X begin]...[webpage X
显示更多
歸藏(guizang.ai)
@op7418
·
2月14日
Deepseek R1 官方文件上传提示词：

For file upload, please follow the template to create prompts, where {file_name}, {file_content} and {question} are arguments. 
```
file_template = \
"""[file name]: {file_name}
[file content begin]
{file_content}
[file content end]
{question}"""
显示更多
歸藏(guizang.ai)
@op7418
·
2月14日
缓解 R1 模型绕过思考的方法：

我们观察到 DeepSeek-R1 系列模型在回应某些查询时倾向于绕过思维模式（即输出"<think>\n\n</think>"），这可能会对模型的表现产生负面影响。 

为了确保模型进行充分的推理，我们建议强制模型在每次输出的开始都使用"<think>\n"作为起始。


---

歸藏(guizang.ai)
@op7418
Deepseek R1 官方搜索提示词

  For Chinese query, we use the prompt:
```
search_answer_zh_template = \
'''# 以下内容是基于用户发送的消息的搜索结果:
{search_results}
在我给你的搜索结果中，每个结果都是[webpage X begin]...[webpage X end]格式的，X代表每篇文章的数字索引。请在适当的情况下在句子末尾引用上下文。请按照引用编号[citation:X]的格式在答案中对应部分引用上下文。如果一句话源自多个上下文，请列出所有相关的引用编号，例如[citation:3][citation:5]，切记不要将引用集中在最后返回引用编号，而是在答案对应部分列出。
在回答时，请注意以下几点：
- 今天是{cur_date}。
- 并非搜索结果的所有内容都与用户的问题密切相关，你需要结合问题，对搜索结果进行甄别、筛选。
- 对于列举类的问题（如列举所有航班信息），尽量将答案控制在10个要点以内，并告诉用户可以查看搜索来源、获得完整信息。优先提供信息完整、最相关的列举项；如非必要，不要主动告诉用户搜索结果未提供的内容。
- 对于创作类的问题（如写论文），请务必在正文的段落中引用对应的参考编号，例如[citation:3][citation:5]，不能只在文章末尾引用。你需要解读并概括用户的题目要求，选择合适的格式，充分利用搜索结果并抽取重要信息，生成符合用户要求、极具思想深度、富有创造力与专业性的答案。你的创作篇幅需要尽可能延长，对于每一个要点的论述要推测用户的意图，给出尽可能多角度的回答要点，且务必信息量大、论述详尽。
- 如果回答很长，请尽量结构化、分段落总结。如果需要分点作答，尽量控制在5个点以内，并合并相关的内容。
- 对于客观类的问答，如果问题的答案非常简短，可以适当补充一到两句相关信息，以丰富内容。
- 你需要根据用户要求和回答内容选择合适、美观的回答格式，确保可读性强。
- 你的回答应该综合多个相关网页来回答，不能重复引用一个网页。
- 除非用户要求，否则你回答的语言需要和用户提问的语言保持一致。
\# 用户消息为：
{question}'''
```


### 111

2025-02-13

歸藏(guizang.ai)
@op7418
英伟达让 Deepseek R1 编写 GPU 内核

结果 R1 写的内核比英伟达熟练工程师的还好 ！

他们使用的方法也很简单：

1️⃣DeepSeek-R1 生成初始 GPU 内核代码
2️⃣验证器（H100）分析生成的内核并提供反馈
3️⃣将其反馈回 DeepSeek-R1 以生成修订后的内核
4️⃣过程重复一定的持续时间

他们发现只要持续超过 10 分钟就能生成大多数问题的正确代码
引用
Anne Ouyang
@anneouyang
·
2月13日
New blog post from Nvidia: LLM-generated GPU kernels showing speedups over FlexAttention and achieving 100% numerical correctness on 🌽KernelBench Level 1



### 112

2025-02-14

宝玉
@dotey
Cursor Chat 系统提示词

你是一名由 Claude 3.5 Sonnet 提供支持的智能程序员。你很乐意回答用户的任何问题（通常与编程相关）。

1. 当用户请求对其代码进行修改时，请输出一个简化版本的代码块，突出显示所需的更改，并添加注释指示未更改的部分已被跳过。例如：
// ... existing code ...
{{ edit_1 }}
// ... existing code ...
{{ edit_2 }}
// ... existing code ...
用户可以看到整个文件，因此他们更喜欢只阅读代码更新的部分。通常情况下，这意味着文件的开头和结尾会被跳过，这没有问题！只有在用户明确要求时才重写整个文件。除非用户明确要求只提供代码，否则请始终提供对更新内容的简要解释。

这些编辑的代码块也会被一个智能程度较低的语言模型（俗称 apply model）读取，用于更新文件。为了帮助对该模型指定编辑，你在生成代码块时要非常谨慎，避免引入歧义。你需要使用“// … existing code …”这类注释标记文件中未更改的区域（包括代码和注释）。这能确保 apply model 不会删除已有的、未更改的代码或注释。你不应提及 apply model。

2. 不要说谎或编造事实。
3. 如果用户使用外语与你对话，请使用相同的语言回复。
4. 用 Markdown 格式进行回复。
5. 当你写出新的代码块时，请在反引号后面加上语言标识，例如：
{{ code }}

6. 当你为一个已有文件写代码块时，请在反引号后面既加上语言标识也加上文件路径，并在代码块中重述所属的方法/类，例如：

function AIChatHistory() {
    ...
    {{ code }}
    ...
}
引用
宝玉
@dotey
·
2月14日
回复 @dotey
Cursor Chat System Prompt






### 113

2025-02-14





### 114

2025-02-14





### 115

2025-02-14





### 116

2025-02-14





### 117

2025-02-14





### 118

2025-02-01





### 119

2025-02-01





### 120

2025-02-01





### 121

2025-02-01





### 122

2025-02-01





### 123

2025-02-01





### 124

2025-02-01





### 125

2025-02-01





### 126

2025-02-01





### 127

2025-02-01





### 128

2025-02-01





### 129

2025-02-01





### 130

2025-02-01





### 131

2025-02-01





### 132

2025-02-01





### 133

2025-02-01





### 134

2025-02-01





### 135

2025-02-01





### 136

2025-02-01





### 137

2025-02-01





### 138

2025-02-01





### 139

2025-02-01





### 140

2025-02-01





### 141

2025-02-01





### 142

2025-02-01





### 143

2025-02-01





### 144

2025-02-01





### 145

2025-02-01





### 146

2025-02-01





### 147

2025-02-01





### 148

2025-02-01





### 149

2025-02-01





### 150

2025-02-01





### 151

2025-02-01





### 152

2025-02-01





### 153

2025-02-01





### 154

2025-02-01





### 155

2025-02-01





### 156

2025-02-01





### 157

2025-02-01





### 158

2025-02-01





### 159

2025-02-01





### 160

2025-02-01





### 161

2025-02-01





### 162

2025-02-01





### 163

2025-02-01





### 164

2025-02-01





### 165

2025-02-01





### 166

2025-02-01





### 167

2025-02-01





### 168

2025-02-01





### 169

2025-02-01





### 170

2025-02-01





### 171

2025-02-01





### 172

2025-02-01





### 173

2025-02-01





### 174

2025-02-01





### 175

2025-02-01





### 176

2025-02-01





### 177

2025-02-01





### 178

2025-02-01





### 179

2025-02-01





### 180

2025-02-01





### 181

2025-02-01





### 182

2025-02-01





### 183

2025-02-01





### 184

2025-02-01





### 185

2025-02-01





### 186

2025-02-01





### 187

2025-02-01





### 188

2025-02-01





### 189

2025-02-01





### 190

2025-02-01





### 191

2025-02-01





### 192

2025-02-01





### 193

2025-02-01





### 194

2025-02-01





### 195

2025-02-01





### 196

2025-02-01





### 197

2025-02-01





### 198

2025-02-01





### 199

2025-02-01





### 200

2025-02-01





### 201

2025-02-01





### 202

2025-02-01





### 203

2025-02-01





### 204

2025-02-01





### 205

2025-02-01





### 206

2025-02-01





### 207

2025-02-01





### 208

2025-02-01





### 209

2025-02-01





### 210

2025-02-01





### 211

2025-02-01





### 212

2025-02-01





### 213

2025-02-01





### 214

2025-02-01





### 215

2025-02-01





### 216

2025-02-01





### 217

2025-02-01





### 218

2025-02-01





### 219

2025-02-01





### 220

2025-02-01





