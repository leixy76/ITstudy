### 01

2025-02-01


宝玉
@dotey
谷歌向美国平台与设备部门的所有员工提供“自愿离职”选项

离职者可获得遣散费，公司希望留下的人都能“对使命高度投入”。

一年前，谷歌在2024年伊始进行了一些裁员。虽然2025年目前尚未出现类似举动，但员工们依然忧心忡忡。如果平台与设备团队的情况具有代表性，那么担忧并非空穴来风。谷歌向负责Android、Pixel硬件以及其他项目的美国团队成员发布了一份备忘录，提供一项“自愿离职计划”，确保愿意离开公司的员工能够获得遣散补偿。根据9to5Google的消息，这份备忘录由平台与设备部门的资深副总裁Rick Osterloh发出。

“在去年将两个大型组织合并之后，我们现在拥有了巨大的发展势头，”Osterloh在备忘录中写道，“面对如此重要的工作，我们希望所有人都能对我们的使命全情投入，并致力于以快速、高效的方式打造出色的产品。” 他同时暗示，如果选择自愿离职的人数不足，谷歌可能会考虑进行裁员。

今年4月，谷歌将Android和硬件团队整合到Osterloh的领导之下。公司高层表示，这样的精简能够帮助更快速地将AI功能整合到各类产品和服务中。

几个月后的10月，Alphabet首席财务官Anat Ashkenazi在上任后的首场财报电话会议上强调了“成本效率”的重要性。“Ruth、Sundar以及其他领导团队已经在重新设计成本结构方面做出了很多努力，”她说，“但我相信，任何组织都可以做得更多，我会继续寻找进一步优化的机会。” 谷歌之所以要削减成本，部分原因在于公司在AI方面投入了巨额资金。

谷歌的Pixel手机销量一直无法与苹果和三星相比，但至少呈现了上升趋势。Counterpoint Research的报告显示，谷歌在2024年第三季度创下了有史以来最高的智能机季度销量。

近期，一些谷歌员工联合发起了一份请愿书，呼吁首席执行官Sundar Pichai在进行强制裁员之前，先推出这种自愿离职选项。CNBC引用了该请愿书的内容：“持续的裁员让我们对自己的工作感到担忧。公司明显财务稳健，却在没有充分解释的情况下失去这么多优秀同事，更令人难以接受。”

目前，这项自愿离职计划似乎尚未扩大到谷歌其他部门，例如搜索团队或DeepMind AI团队。



### 02

2025-02-01


小互
@imxiaohu
Google 推出 DataGemma 模型

利用真实世界数扼使用 RAG 和RIG 技术解决 AI 幻觉

DataGemma的核心能力是通过将Google的 Data Commons（一个包含2400 亿的公共数据资源库）与LLM相连接，从而增强模型的事实性和推理能力，减少幻觉现象。

DataGemma使用两种主要方法来增强LLM的准确性：

RIG（检索与生成融合）：此方法通过主动查询Data Commons中的数据，来增强语言模型的能力，确保生成的内容与事实相符。

RAG（检索增强生成）：这种方法让语言模型能够吸收更多背景信息，增强生成内容的全面性，并减少“幻觉”现象。

[Google 推出 DataGemma：利用真实世界数据 使用 RAG 和 RIG 技术解决 AI 幻觉 | XiaoHu.AI 学院](https://www.xiaohu.ai/c/xiaohu-ai/google-datagemma-rag-rig-ai)

### 03

2025-02-01

宝玉
@dotey
o3-mini-high 是每周 50 条！Plus 用户省着点

Q: “o3-mini 或 o3-mini-high 的免费和付费额度有区别吗？Plus 和 Pro 用户分别有什么限制？”
A (Hongyu Ren): “Pro 用户拥有 o3-mini-high 的无限次使用权限；Plus 用户每周 50 次 o3-mini-high，每天 150 次 o3-mini。这两者是分开计算的。”



### 04

2025-02-01


歸藏(guizang.ai)
@op7418
o3mini 终于发布了 

就得有人治治他们，PLUS 和 Team 用户每日消息提升到 150 条

1.  核心功能与开发者特性

扩展功能支持：o3-mini 是首个支持开发者广泛请求的特性的小型推理模型，包括：

函数调用（function calling）

结构化输出（Structured Outputs）

开发者消息（developer messages）

流式输出：同 o1-mini 和 o1-preview 一样，o3-mini 支持流式输出。

可选推理力度：提供低、中、高三档推理力度，开发者可以根据需求在速度和复杂问题求解质量之间做出平衡。当任务较复杂时可以选择更高的推理力度以“多思考”，当延迟敏感时可以选择较低力度。

2. 部署与使用场景

平台发布：o3-mini 已在 ChatGPT 和 API 上发布。API 端目前在 Chat Completions、Assistants 和 Batch API 中对 API 使用层级 3-5 的部分开发者开放。

用户群体：ChatGPT Plus、Team 及 Pro 用户可以立即使用，企业用户将在一周后获得访问权限。此外，免费用户也可以通过在消息编辑器中选择“Reason”或重新生成回复来体验这一推理模型，这是免费用户首次获得推理模型的体验机会。

模型替换与限额提升：在模型选择器中，o3-mini 将取代 o1-mini，提供更高的调用速率（例如 Plus 和 Team 用户的每日消息数从 50 提升至 150）。

3. 性能与评估

STEM 领域优化：

在数学、编码、科学等方面，o3-mini 在中等推理力度下能够达到与 o1 相近的表现，而在高推理力度下更是超越了 o1-mini 和 o1。

在 AIME 2024 数学竞赛、GPQA Diamond（博士级科学问题）、FrontierMath（研究级数学）等评测中，o3-mini 显示了更高的准确率和推理能力。

具体数据：

在 AIME 2024 中，o3-mini (high) 达到 83.6% 的准确率；

在博士级科学问答中，高推理力度下的准确率可达到 77.0%；

在 Codeforces 编程竞赛中，o3-mini 随推理力度提升，Elo 分数显著超越前代模型；

在软件工程评测（SWE-bench Verified）中，高推理力度下准确率达到 48.9%，表现优异。

用户体验评测：外部专家测试表明，o3-mini 的回答比 o1-mini 更准确、表达更清晰，尤其在 STEM 任务上优势明显。统计数据显示，测试者在 56% 的情况下更倾向于 o3-mini 的回答，同时在处理复杂问题时重大错误减少了 39%。

响应速度：在 A/B 测试中，o3-mini 的响应速度比 o1-mini 快 24%，平均响应时间约 7.7 秒（相比 o1-mini 的 10.16 秒），且首个 token 的延迟减少约 2500 毫秒。


### 05

2025-02-01



宝玉
@dotey
NVIDIA 将拥有 6710 亿参数的 DeepSeek-R1 模型引入了位于 http://build.nvidia.com 上的 NVIDIA NIM 微服务：

- 使用单台 NVIDIA HGX H200 服务器即可实现每秒最多 3,872 个 Token 的推理吞吐量。  
- 依托 NVIDIA Hopper 架构，DeepSeek-R1 利用 FP8 Transformer Engine 和 900 GB/s 的 NVLink 带宽进行专家通信，从而提供高速推理性能。  
- 一如既往，NVIDIA NIM 面向企业级应用，能够在安全环境中使用行业标准 API 实验并部署 AI 代理。


### 06

2025-02-01


宝玉
@dotey
用户提问：“你们会考虑公开一些模型权重和研究成果吗？”

Sam Altman：
“是的，我们正在讨论。我个人认为我们在这个问题上走到了历史的反面，需要找出一种不同的开源策略。不过，并不是所有OpenAI内部的人都同意我的看法，而且这也不是我们目前的最高优先事项。”
引用
Tsarathustra
@tsarnick
·
2月1日
Sam Altman: "we have been on the wrong side of history" with regards to open source/open weights AI models



### 07

2025-02-01


宝玉
@dotey
Lex Fridman：OpenAI 的 o3-mini 确实是一个不错的模型，但 DeepSeek r1 性能相当、价格更低，而且它的推理过程是可见的。更强的模型很快就会出现（我非常期待 o3pro），但“DeepSeek 时刻”是一个不容忽视的现实。我认为，即便是五年后，这一事件仍会被视为科技史上的一个重要转折点，这不仅与地缘政治因素有关，还有许多其他原因。

我刚录了一期关于 AI 产业现状的五小时技术播客，明天（希望顺利）就会发布。
引用
Lex Fridman
@lexfridman
·
2月1日
OpenAI o3-mini is a good model, but DeepSeek r1 is similar performance, still cheaper, and reveals its reasoning.

Better models will come (can't wait for o3pro), but the "DeepSeek moment" is real. I think it will still be remembered 5 years from now as a pivotal event in tech
显示更多


### 08

2025-02-01


倪爽
@nishuang
苹果的 AR/VR/MR/智能眼镜计划再次碰壁，正式砍掉了 AR 眼镜项目

彭博社说被砍设计类似于 Meta AR 眼镜，需要连电脑、不能像 Vision Pro 那样独立运行

有趣的设计细节：（投影）镜头能变色，让旁观者知道我在看着他、还是在看眼镜里投射的工作画面😅


### 09

2025-02-01



宝玉
@dotey
OpenAI 推出了全新模型 o3-mini，现已在 ChatGPT 和 API 中全面上线。该模型专为科学、数学和编程等技术领域打造，不仅推理能力强大，而且响应速度快，代表了高性价比推理技术的前沿突破。

为了满足不同用户群体的需求，o3-mini 提供了多种访问和功能选项：

- 免费用户：可在 ChatGPT 消息输入框下方选择 “Reason” 按钮，或通过重新生成响应的方式体验 o3-mini 的核心推理功能。
- Plus 与 Team 用户：在原有的基础上，将可用速率限制提升至原先 (o1-mini) 的三倍，让更多复杂问题能在更短时间内得到解答。
- Pro 用户：可享受 o3-mini 以及更高智力版本 o3-mini-high 的无限次访问，满足更高强度或更专业的推理需求。

值得一提的是，OpenAI o3-mini 集成了搜索功能，能够实时获取最新答案并附带相关网页链接，方便用户进行深度调研。目前这还是一项原型功能，未来将持续完善和扩展到更多推理模型。与 o1 类似，o3-mini 在上线之前也经过了充分的安全评估、外部红队测试和准备工作，并在应对复杂安全和“越狱”场景时明显优于 GPT-4o，展现了更稳健的安全防护能力。如需了解更多细节，可参阅 o3-mini 系统卡片。

无论是追求高精度的专业开发者，还是想一睹小型强推理模型风采的普通用户，都可以从 o3-mini 获得物超所值的体验。它正在一步步推动人工智能的创新边界，让更高层次的推理与更低使用门槛得以兼得。


### 10

2025-02-01


宝玉
@dotey
o3 mini 系统卡

5.6 说服力（Persuasion）
OpenAI o3-mini 风险评估：中等（Medium）
总结：o3-mini 展现出相当于人类平均水平的写作说服能力，但还未超过顶尖人类写作者，未达到“高风险”门槛。

“说服力”这一风险侧重探讨模型在让人改变想法或采取行动方面可能带来的影响，包括文本生成（静态）及互动式对话（动态）两种场景。下面我们详细介绍所用的说服力评估方法。



### 11

2025-02-01

宝玉
@dotey
以下内容来自 Gilles Backhus

---

我想从 AI 基础设施的角度，简要分享一些关于 DeepSeek 的看法，以及为什么它并不是世界原先想象的那样。以下很多内容都基于 SemiAnalysis 对它所做的出色研究，以及部分来自 artificialanalysis 的数据。非常感谢他们的贡献 🙏

1. 💰 成本
- 并没有传闻中说的“仅花了 600 万美元”来训练它（总投入）。
- 事实上，用于训练这款模型的计算成本（包括硬件）估计大约为 13 亿美元。
- 他们并没有如实披露真正的 TCO（总体拥有成本）。

2. 💲 价格
- DeepSeek 最初的定价（约 $0.20/100 万 Token）远低于实际成本，基本上是以巨大亏损提供服务。
- 像 together-ai 这样以盈利为目标的公司，如果要托管该模型，其价格就被迫要高得多（约 $1.00/100 万 Token）。

3. 💡 质量
- 以更贴近成本的价格来看，该模型并没有那么突出。
- 它在相同价位下，与 openAI 的一些模型（例如 o1-mini）质量相当。
- 它并不比 o1 或 o3 更胜一筹。
- 当然，它仍然是目前市面上最好的模型之一，但并没有达到某种“巨大差距”的水平。

4. ⚡ 效率
- 虽然 DeepSeek 的 Mixture-of-Expert（专家混合）方法（其实并不新）确实减少了计算需求，
- 但模型本身的规模（需要多少参数存放在内存）其实极其庞大：仅实例化一次就需要大约 1 TB 的超高速内存。
- 很多人不知道：内存技术是现代 AI 系统成本的主要驱动力之一。
- 换言之，牺牲计算换取超大内存的模型，可能总花销反而更高。

🥜 总结一下
DeepSeek 只是另一个例子，说明 AI 正在逐渐成熟，大家也在不断探索各种方法来突破极限。我很高兴看到这一趋势。对于我们这种中立的 AI 推理硬件公司来说，任何能够推动 AI 大规模应用的进展都是好事。🙂

📈 未来依旧在早期阶段
AI 最终会在全球范围内带来从 100 万倍到 10 亿倍的计算需求增长，一旦未来的应用场景被充分挖掘，例如：
- 为每个人提供个性化教育/咨询服务
- AI 媒体内容的生成
- 工作场景中的 AI 助手或“数字分身”

可以预见，AI 的巨大潜力才刚刚开始被释放。



### 12

2025-02-01

歸藏(guizang.ai)
@op7418
有了 Anthropic CEO 嘴硬的回应看 Sam 也没那么离谱了

昨晚在 reddit 的 AMA 活动中 Sam 几个回应都还不错

 1. 承认是 R1 促使他们后面会展示模型更详细的思考过程

2. 另外承认在开源和非开源选择上站错了队，需要重新考虑他们的开源倾向



### 13

2025-02-01


歸藏(guizang.ai)
@op7418
OpenAI（Sam Altman、Mark Chen、Kevin Weil、Srinivas Narayanan、Michelle Pokrass 和 Hongyu Ren）在 Reddit AMA 中讨论内容的中文总结：

---

\### 模型更新和发布

- **o3-mini** 现已推出，具备推理能力和工具使用支持，包括网页搜索功能。
- 知识截止日期仍为 2023 年 10 月，但由于具备网页搜索功能，其重要性有所降低。
- 小型模型在工具、代理框架以及成本与性能权衡方面仍有显著提升空间。
- **o3 全版本** 预计将在“几周以上，几个月以内”发布。
- **o3-pro** 版本已确认即将推出，这意味着 ChatGPT Pro 将“非常值得升级”。
- **GPT-5**（非 GPT-5o）正在开发中，但未提供具体时间表。
- 4o 系列尚未完结，后续将有改进。
- 基于 GPT-4o 的图像生成与编辑功能仍在开发中，预计将在“大约几个月内”推出——“等待将是值得的”。
- DeepSeek 被认定为“非常优秀的模型”；OpenAI 预期将推出更好的模型，但领先优势不如以往年份明显。

---

\### 功能和能力

- **Operator** 将在“几个月内”加入 Plus 计划。
- 计算机的使用被视为长期 AGI 发展的关键部分。
- 更多代理（Agents）将在“非常非常快的时间内”推出。
- 计划很快展示更详细的思考 token 版本。
- 推理能力仍然是开发的“最关键部分”。
- 先进的语音模式更新即将推出，并计划将其与文本/画布交互集成。
- 规划为推理模型增加 PDF 支持和文件附件功能。
- **Vision** 能力将引入到 o3-mini（目前已在 o1 中可用）。
- 正在努力增加上下文长度，但未给出具体时间表。
- 正在开发与 o 系列模型整合记忆功能。
- 正在致力于将所有工具和模态统一到推理模型中。

---

\### 访问与定价

- 团队正在考虑如何展示剩余消息数，以免用户过于关注限制（目前没有进度条/计数器，以避免“稀缺效应”）。
- 正在致力于使 Assistants API “更易于使用”。
- 希望随着时间推移降低 Plus 级别的价格，目前没有涨价计划。
- Plus 用户每天可获得 150 条 o3-mini 消息以及每周 50 条 o3-mini-high 消息。
- Pro 用户可无限制使用 o3-mini-high。
- 正在 API 中测试欧盟数据驻留服务，以符合 GDPR 要求。

---

\### 未来发展重点与首要任务

- 提升多步函数调用的性能。
- 扩展长上下文能力。
- 将功能与 o 系列统一。
- 开发“更具代理性”的应用程序，以应对复杂、长时运行的任务。

---

\### 机器人技术

- 初步目标：“制作一批非常优秀的机器人，并从中学习”。
- 重点在于从初步部署中获得经验。
- 长远愿景包括让机器人在现实世界中执行有用任务。

---

\### 研究与开源

- 正在讨论潜在的模型权重及研究成果的发布。
- 内部对开源策略存在争议，Sam 认为当前的做法处于“历史的错误一边”。
- 过去曾开源过 GPT-2 和 Jukebox 模型，正在考虑更多的发布。

---

\### AGI 展望

- 快速起飞（Fast takeoff）的情景被认为“比…几年前更为可能”。
- 主要影响预计将是加速科学发现。
- 对未来交互的设想包括更多具备代理性的 AI 持续在后台工作。
- AGI 突破的主要关注领域将是治愈疾病和开发更廉价的能源。

---

\### 基础设施

- **Stargate 项目** 被描述为对 OpenAI 未来“非常重要”。
- 被视为将“算力/GPU 转化为卓越成果”的工厂。
- 对于在两个维度上扩展模型至关重要：更大的预训练模型和更多的 RL/Strawberry（强化学习相关技术）。


### 14

2025-02-01

歸藏(guizang.ai)
@op7418
Huggingface 这个 Open R1 的文章牛皮啊

整理了 Deepseek R1 发布到现在所有重要内容和社区工作

- 复现对于 R1 的评估分数
- 复现 R1 训练管道，比如 GRPO
- 合成数据生成流程，重现类似 R1 的推理数据集
- 市面上所有重要人物对于 R1 模型的表态
- 尝试复现 R1 的开源项目

[Open-R1: Update #1](https://huggingface.co/blog/open-r1/update-1)

### 15

2025-02-01

歸藏(guizang.ai)
@op7418
太顶了，期待有服务商可以支持
引用
karminski-牙医
@karminski3
·
2月1日
本地部署 DeepSeek-R1 支持 ToolCall 了！

昨天 llama.cpp 刚合并了一个新PR，终于让 DeepSeek-R1 支持 ToolCall了!

本地部署DeepSeek最后一个短板终于补上了，考虑到DeepSeek官方其实并没有Agent平台，所以本地部署的DeepSeek-R1反而变得更强了.

[1/2]
显示更多



### 16

2025-02-01


九原客
@9hills
杨立昆锐评某些硅谷公司（deepseek 翻译）
——

- 硅谷某些圈子中的一种常见病:一种错位的优越感。
- 晚期症状:认为自己的小团体垄断了好主意。
- 末期症状:认为来自他处的创新是通过欺骗手段获得的。

科技进步在更多有才华的人参与并*分享*他们的创新时发展得更快。

事实上,这就是原因:
- 科学界围绕出版物和工具共享进行组织
- 开发者社区围绕开源组织
- 专利制度存在(尽管对于软件和服务来说已经过时且适得其反):你可能会获得政府对发明使用的短期独占权,但作为交换,你必须披露足够的信息,以便他人能够复制并在其基础上进行构建。
引用
Yann LeCun

@ylecun
·
2月1日
A common disease in some Silicon Valley circles: a misplaced superiority complex.


### 17

2025-02-01

宝玉
@dotey
OpenAI CEO宣布开发AI设备 旨在实现iPhone以来最大革命

【硅谷=山田亮太郎】美国OpenAI公司首席执行官山姆·奥特曼在接受《日本经济新闻》采访时宣布，该公司将开始开发专用于生成式AI（人工智能）的设备，以取代智能手机。他还表达了对开发自己的半导体的热情。该公司将人工智能的普及视为变革IT行业的机遇，旨在引发自2007年推出iPhone以来约20年来数字设备的首次革命。

奥尔特曼定于3日在首相官邸与石破茂首相会面……




### 18

2025-02-03


宝玉
@dotey
OpenAI 全新“Deep Research”重磅发布：让 ChatGPT 帮你完成多步骤深度研究

在这个信息爆炸的时代，如何用最短的时间获取最精准、最详实的信息，一直是许多知识工作者面临的难题。如今，OpenAI 带来了全新的 Deep Research 功能，让你的 ChatGPT 化身为一位“研究助理”，能够独立查找、分析并综合海量网络信息，为你提供专业且有完整参考的研究报告。下面，让我们来一起了解这项强大的新功能吧！

Deep Research 能做什么？

1. 多步骤研究
相比传统的聊天式问答，Deep Research 具备强大的自主研究能力。它能够从互联网上寻找并分析数百个来源，根据实时获取的信息进行动态调整和推理。短短几十分钟内，它能完成人工需要数小时才能完成的研究工作。
2. 自动化汇总海量信息
你只需要输入研究需求，ChatGPT（在 Deep Research 模式下）就会自动去浏览海量网页、PDF、图片等信息资源，并将它们整合成一份清晰、有理有据的分析报告，犹如一位具有专业分析能力的研究员。
3. 详尽引用与文献记录
Deep Research 每一个输出都附有引用来源，并在侧边栏展示搜索、分析过程，方便你查看、验证信息。同时也提供思路概述，保证研究过程的透明度与可追溯性。
4. 个性化、多场景适用
无论你是做金融、科学、政策、工程等领域的深度研究，还是想为购物（例如汽车、家电或家具等大件商品）做细致比对，Deep Research 都能胜任。它还擅长挖掘各类小众且不直观的信息，只需一次查询，就能节省你大量的时间和精力。

为什么它如此重要？

1. 效率大幅提升
普通用户在网络上搜集信息可能需要自己筛选资料、反复验证。Deep Research 通过自动化的搜寻和分析，大幅缩短研究时间，让你把更多精力放在思考与决策上。
2. 减少重复劳动
Deep Research 擅长处理那些需要浏览无数个网页、文件的繁琐任务。比如撰写报告、整理数据、查找论文资料、对比不同产品参数等。以前这些工作往往让人头疼，现在只需一次提问，就能得到系统、条理化的研究成果。
3. 助力专业领域
该功能在化学、人文社科、数学等众多专业领域都表现出色，尤其在需要检索专业文献、综合多方信息的复杂任务中，让研究人员更轻松、更高效。
4. 迈向真正的“通用人工智能”
OpenAI 一直致力于开发具备创造全新知识能力的通用人工智能（AGI）。Deep Research 作为其新里程碑，进一步展现了 AI 在多领域多模态研究中的潜力，为未来更先进的 AI 系统奠定了基础。

如何使用 Deep Research？

1. 选择 Deep Research 模式
在 ChatGPT 界面中，找到消息输入区域的模式选项，选择“Deep Research”。然后在对话框输入你的研究需求。
2. 附加背景文件/数据
如果你有特定的文件、电子表格或参考资料，也可以上传给 Deep Research。它会结合这些材料，为你做更有针对性的深度分析。
3. 查看研究过程与报告
当 Deep Research 开始运行后，聊天界面会出现一个侧边栏，展示它搜索到的来源以及每一步的推理过程，让你随时掌握研究进展。
一般它会花 5～30 分钟进行深度研究，然后返回一份完整的报告，附带详细引用。如果任务很耗时，你也可以先去忙别的事，等它研究完成再回来查看结果。
4. 报告输出形式
初始版本以文字报告为主，在接下来几周内，Deep Research 将支持在报告中插入图片、数据可视化图表以及其他分析产出，让研究结果更加直观、生动。

技术原理与表现
1. 强化学习驱动
Deep Research 通过端到端强化学习训练，掌握了如何在复杂的网络环境中进行多步搜索和推理，遇到新情况时也能灵活应对。
2. 新的评测成绩
• 在 Humanity’s Last Exam 测试中，为 Deep Research 提供支持的模型取得了 26.6% 的准确率，远超上一代模型的表现。
• 在 GAIA 基准上，它也刷新了排行榜记录，证明了在多模态理解和使用工具（如浏览器、Python）等方面更具突破性。
3. 专业领域的进一步提升
一些专业人士反馈，使用 Deep Research 可以在短时间内完成原本需要数小时的调查工作，无论是找文献还是分析数据，效率提升显著。

注意事项及局限性
1. 依然存在幻觉或错误推断
虽然 Deep Research 生成“错误事实”或逻辑漏洞的概率比现有 ChatGPT 模型更低，但仍有可能出现。用户在使用时应保持警惕，尤其在严谨的学术或商业环境下，要对关键信息进行交叉验证。
2. 区分谣言与权威信息的能力有限
模型仍然可能对信息来源缺乏足够判断力，需要用户根据实际情况和专业常识来判断信息的可信度。
3. 报告格式与耗时
首批上线版本可能会出现小规模的格式问题或引用异常，研究任务也可能因为深度搜索而启动较慢。官方表示，会随着使用量的增加和时间的推移迅速改进这些问题。

谁能访问 Deep Research？

1. Pro 用户率先上线
目前 Deep Research 首先向 ChatGPT Pro 用户开放，每月可使用高达 100 个查询额度。
2. 逐步覆盖更多付费用户
之后会依次向 Plus 和 Team 用户开放，随后是企业版。OpenAI 也在努力面向英国、瑞士以及欧洲经济区的用户开放访问权限。
3. 进一步的扩容
OpenAI 计划推出一个使用更小模型、速度更快且成本更低的 Deep Research 版本，届时所有付费用户都会有更高的调用额度。

后续计划

1. 更广泛的平台支持
Deep Research 目前仅在 ChatGPT 网页端上线，官方将在未来一个月内把这项功能带到移动端与桌面端。
2. 接入更多数据源
不仅能访问互联网的公开信息和用户上传的文件，今后还会扩展到订阅或内网资源，让报告更具深度与个性化。
3. 与其他代理能力融合
OpenAI 正在开发的 Operator 功能，能够在现实世界中执行任务。当 Operator 与 Deep Research 结合，ChatGPT 将可以自主进行更复杂的在线与线下任务，为用户提供更全面的“智能助理”体验。

Deep Research 的到来，让我们看到了一个可以代替人工执行复杂、多步骤研究任务的 AI 时代正逐渐变成现实。无论你是需要大量文献支撑的研究工作者，还是想要做精细购物决策的普通用户，都能借助这个工具大幅提升效率。它不仅代表着 ChatGPT 的新能力，也标志着人类向更高水平的通用人工智能迈出了重要一步。对知识工作者来说，这将是一股全新的生产力，也是人工智能赋能未来的又一有力见证。

想要率先体验 Deep Research 的朋友，如果你是 ChatGPT Pro 用户，不妨立刻去试试看；如果尚未获得资格，也可以继续关注官方更新，相信不久后就有机会亲自感受这项强大的功能啦！



### 19

2025-02-03

小互
@imxiaohu
奥特曼在接受《日本经济新闻》采访时表示，OpenAI正着手开发一种取代智能手机的 AI 专用设备，彻底改变人机交互方式，并且有意自主研发专用芯片。

该设备由苹果前苹果设计师Johy Ive和他现在的工作室负责设计！

奥特曼认为，人工智能的普及将带来信息技术产业的重大变革，并希望推动 自 2007 年 iPhone 诞生以来最重大的数字设备创新。

奥特曼称：AI 设备将重新定义人与计算机的交互方式。

奥特曼强调，AI 需要新的交互设备，而语音操作将成为关键。

• Apple 通过 iPhone 引入触控操作，彻底改变了用户界面（UI）

• OpenAI 计划 以语音为核心，探索适合 AI 时代的新 UI 设计。

2 月 3 日，奥特曼、孙正义与日本首相石破茂在首相官邸会面，探讨合作可能性。可能寻求日本市场和政府的合作，共同推动 AI 发展。




### 20

2025-02-03


宝玉
@dotey
今天，OpenAI 推出了一款能够独立为您完成工作的新智能体——深度研究（Deep Research）。

只需提供一个提示，ChatGPT 就能在短短几十分钟内完成对数百个在线资源的查找、分析和综合，生成一份详尽的报告，而这通常需要人类花费数小时甚至更长时间才能完成。深度研究由经过优化的 OpenAI o3 版本提供支持，结合网络浏览和 Python 分析能力，能够通过推理智能、高效地浏览互联网上的文本、图像和 PDF 文件。

深度研究的核心功能

这个智能体通过推理整合大量在线信息，帮助您完成多步骤的研究任务。目前已向 Pro 用户开放，接下来会向 Plus 和 Team 用户逐步推出。

推动性能突破
驱动深度研究的模型在多个关注现实问题的公开评估中表现优异，包括“人类最后的考试”（Humanity's Last Exam）。

适用场景广泛
深度研究专为那些在金融、科学、政策、工程等领域从事高强度知识工作的专业人士而设计，他们需要可靠、全面的研究成果。此外，这款工具也非常适合需要个性化推荐的购物者，用于深入研究大额或复杂的购买决策。

逐步推出计划
深度研究今天起向 Pro 用户推出，接下来会扩展到 Plus 和 Team 用户，最终覆盖企业用户。
引用
OpenAI
@OpenAI
·
2月3日
回复 @OpenAI
Powered by a version of OpenAI o3 optimized for web browsing and python analysis, deep research uses reasoning to intelligently and extensively browse text, images, and PDFs across the internet. https://openai.com/index/introducing-deep-research/


### 21

2025-02-03

宝玉
@dotey
有关 AI 编程，我觉得近期最值得看的一篇文章和视频都来自 Addy Osmani

《AI 辅助编码的残酷真相：它能帮你完成70%的工作，但最后30%令人非常沮丧》

今天终于抽空把视频给翻译了一下，见评论
上午6:42 · 2025年2月3日
·
11万
 查看

宝玉
@dotey
·
2月3日
The 70% problem: Hard truths about AI-assisted coding

原文：https://addyo.substack.com/p/the-70-problem-hard-truths-about

翻译：https://mp.weixin.qq.com/s/ZQA8quhAEwUUsT2p_IjG0g?token=1639803888&lang=zh_CN



### 22

2025-02-03


宝玉
@dotey
梁文锋深度采访（一）

主持人：为什么DeepSeek会让硅谷的很多人惊讶？

梁文锋：在美国每天发生的大量创新里，这是非常普通的一个，他们之所以惊讶是因为这是一个中国公司，在以创新贡献者的身份加入到他们游戏里去。毕竟大部分中国公司习惯follow，而不是创新。

主持人：但这种选择放在中国语境里也过于奢侈了，大模型是一个重投入游戏，不是所有公司都有资本只去研究创新，而不是先考虑商业化。

梁文锋：创新的成本肯定不低，过去那种拿来主义的惯性也和过去的国情有关，但现在你看无论中国的经济体量，还是字节腾讯这些大厂的利润，放在全球都不低。我们创新缺的肯定不是资本，而是缺乏信心，以及不知道怎么组织高密度的人才实现有效的创新。

主持人：为什么中国公司，包括不缺钱的大厂，这么容易把快速商业化当第一要义？

梁文锋：过去30年我们都只强调赚钱，对创新是忽视的，创新不完全是商业驱动的，还需要好奇心和创造欲。我们只是被过去那种惯性束缚了，但它也是阶段性的。

主持人：但你们究竟是一个商业组织，而非一个公益科研机构，选择创新又通过开源分享出去，那要在哪里形成护城河？

梁文锋：在颠覆性的技术面前，闭源形成的护城河是短暂的，即使OpenAI闭源也无法阻止被别人赶超，所以我们把价值沉淀在团队上。我们的同事在这个过程中得到成长，积累很多know-how，形成可以创新的组织和文化，就是我们的护城河。开源、发论文其实并没有失去什么，对于技术人员来说，被follow是很有成就感的事。其实开源更像一个文化行为，而非商业行为，给予其实是一种额外的荣誉。一个公司这么做也会有文化的吸引力。

主持人：你怎么看类似朱啸虎的这种市场信仰派观点？

梁文锋：朱啸虎是质朴的，但他的打法更适合快速赚钱的公司。你看美国最赚钱的公司都是厚积薄发的高科技公司。

主持人：但做大模型，单纯的技术领先也很难形成绝对优势，你们赌的那个更大的东西是什么？

梁文锋：我们看到的是中国AI Scene可能永远处在跟随的位置。我们经常说中国AI和美国有一两年差距，但真实的Gap是原创和模仿之差。如果这个不改变，中国永远只能是追随者，所以有些探索也是逃不掉的，因为达到领先不只是一个公司的努力，而是整个西方技术社区和产业共同努力的结果。他们能看到下一代的技术趋势，手里有路线图，中国AI的发展同样需要这样的生态。很多国产芯片发展不起来也是因为缺乏配套的技术社区，只有二手消息，所以中国必然需要有人站到技术的前沿。

主持人：海外认为DeepSeek雇佣了一批高深莫测的奇才，那做出DeepSeek的是怎样一群人？

梁文锋：并没有什么高深莫测的奇才，都是一些top高校的应届毕业生，没毕业的博士博五实习生，还有一些毕业才几年的年轻人。

主持人：很多大模型公司都执着地区海外挖人，很多人觉得这个领域前50名的顶尖人才可能都不在中国公司，你们的人才都来自哪里？

梁文锋：不要模型，没有海外回来的人，都是本土的前50名顶尖人才可能不在中国，但也许我们能自己打造这样的人。

主持人：听说你们很擅长从细节招人，AI让一些非传统评价指标里优秀的人被选出来。

梁文锋：我们选人的标准一直都是热爱和好奇心，所以很多人会有一些奇特的经历，很有意思。很多人对做研究的渴望远超对钱的在意。

主持人：这种发散性敏感的人才和你们完全创新型组织的架构很有关系，但AGI这种充满不确定性的前沿探索，是否多了管理动作？DeepSeek也全是自下而上？

梁文锋：而且我们一般不强制分工，而是自然分工，每个人有自己独特的成长经历，都是自带想法的，不需要push他，探索过程中他遇到问题自己就会拉人讨论，不过当一个idea显示出潜力，我们也会自上而下去调配资源。

主持人：创新很大程度也是一种偶然吗？

梁文锋：我觉得创新首先是一个信念问题，为什么硅谷那么有创新精神，首先是敢。ChatGPT出来时，整个国内对做前沿创新都缺乏信心，从投资人到大厂都觉得差距太大了，还是做应用吧。但创新首先需要自信，这种信心通常在年轻人身上更明显。

主持人：大部分中国公司都选择既要模型又要应用，为什么DeepSeek目前选择只做研究探索？

梁文锋：因为我们觉得现在最重要的是参与到全球创新的浪潮里去，过去很多年中国公司习惯了别人做技术创新，我们拿过来做应用变现。但这并非是一种理所当然，这波浪潮里，我们的出发点就不是趁机赚一笔，而是走到技术的前沿去推动整个生态发展。

主持人：你觉得创新很大程度也是一种偶然吗？

梁文锋：我觉得创新首先是一个信念问题，为什么硅谷那么有创新精神，首先是敢。ChatGPT出来时，整个国内对做前沿创新都缺乏信心，从投资人到大厂都觉得差距太大了，还是做应用吧。但创新首先需要自信，这种信心通常在年轻人身上更明显。

主持人：现在经济开始进入下行，资本也进入轮周期，所以它对原始创新是否会带来更多抑制？

梁文锋：我倒觉得未必，中国产业结构的调整会更依赖硬核技术的创新。当很多人发现过去赚快钱很可能来自时代运气，就会更愿意俯身去做真正的创新。

主持人：技术真的可以拉开差距吗？你也说过并不存在绝对的技术秘密。

梁文锋：技术没有秘密，但复制需要时间和成本。英伟达的显卡理论上没有任何技术秘密，很容易复制。但重新组织团队以及追赶下一代技术都需要时间，所以实际的护城河还是很宽。

主持人：互联网和移动互联网时代留给大部分人的惯性认知是，美国擅长搞技术创新，中国更擅长做应用。

梁文锋：我们认为随着经济发展，中国也要逐步成为贡献者，而不是一直搭便车。过去30多年IT浪潮里，我们基本没有参与到真正的技术创新里，我们已经习惯摩尔定律从天而降。躺在家里18个月就会出来更好的硬件和软件，但其实这是西方主导的技术社区一代代孜孜不倦创造出来的。只因为之前我们没有参与这个过程，以至于忽视了它的存在。

主持人：你对国内原始创新也是乐观的吗？

梁文锋：我是80年代在广东一个五线城市长大的，我的父亲是小学老师。90年代广东赚钱机会很多，当时有不少家长到我家来，基本就是家长觉得读书没用，但现在回去看，观念都变了，因为钱不好赚了，连开出租车的机会可能都没了。一代人的时间就变了，以后硬核创新会越来越多，现在可能还 不容易被理解是因为整个社会群体需要被事实教育。当这个社会让硬核创新的人功成名就，群体性想法就会改变。我们只是还需要一堆事实和一个过程。
上午6:08 · 2025年2月3日
·
8.5万
 查看

宝玉
@dotey
·
2月3日
来源：https://m.weibo.cn/detail/5129157966823476



### 23

2025-02-03

宝玉
@dotey
罗福莉（福莉），出生于四川农村的“95后AI天才少女”，现任DeepSeek公司深度学习研究员，是国产大模型DeepSeek-V2的核心开发者之一。她本科毕业于北京师范大学计算机专业，硕士保送至北京大学计算语言学专业，师从万小军教授，期间在国际顶级会议ACL上发表8篇论文（含2篇一作），奠定了其在自然语言处理（NLP）领域的学术声誉。职业生涯始于阿里巴巴达摩院，主导开发了多语言预训练模型VECO，推动AliceMind项目开源；2022年加入DeepSeek后，参与研发了MoE架构大模型DeepSeek-V2，该模型以“中文能力第一梯队”和超高性价比（1元/百万Tokens）成为行业焦点。  

2024年底，网传小米创始人雷军以千万年薪邀请其领导AI大模型团队，但截至2025年2月，罗福莉仍通过高中班主任回应“暂未决定”，其知乎认证信息显示为DeepSeek员工。分析认为，她的选择或反映对技术深耕与产业使命的权衡：DeepSeek正处“与国运共振”的上升期，而小米的邀约则凸显行业对顶尖人才的争夺。  

罗福莉的成长轨迹融合了个人奋斗与时代机遇。她以“农村女孩”身份突破性别与资源限制，成为AI领域标杆人物，既印证“知识改变命运”的普世价值，亦展现中国AI产业崛起中青年科学家的关键角色。其职业路径的选择，不仅是个人发展问题，更折射出国产AI技术生态中企业与人才协同创新的深层命题。

罗福莉在采访中回顾了自己从农村到顶尖AI开发者的逆袭之路。她出身贫寒，父母曾质疑“女生学计算机是否适合”，但她以“探索更多可能性”的决心打破桎梏。在北师大转专业至计算机后，她通过提前规划与贵人指引（如北大导师万小军），以“目标拆解+死磕精神”实现学术突破：大三自学Python并投出首篇顶会论文，硕士期间以“博士生标准”产出20余篇顶会论文，成为业内瞩目的“ACL8篇作者”。  

她坦言职业选择中的试错与坚持：曾短暂尝试产品经理方向，但最终回归技术研究，并先后加入阿里达摩院、幻方量化及DeepSeek。在DeepSeek期间，她深度参与模型研发，强调团队“技术驱动”特质，并公开评价DeepSeek-V2为“性价比之王”。



### 24

2025-02-03

FallMonkey
@FallMonkey
@teortaxesTex
 很早就很坚定看好幻方，但是西方友人能这么深刻分析，实在令人惊叹。不才翻译一下，可以的话还是请阅读堪称优雅的原文。

DeepSeek：现代中国文化亚稳态的一个缩影

作者：DeepSeek-R1，Teortaxes
译者：DeepSeek-R1，O1-Pro，FallMonkey

刻板印象：宛如被环境凝固的万花筒

国家层面的刻板印象，往往是在某些“反应型特征”的维度上不断累积，再因路径依赖而定型。“稻米理论”所揭示的东亚心理（即将密集型农业与规避风险、从众服从，以及“勤能补拙”的行事风格相关联）并非无中生有或纯粹的东方主义偏见。研究（如 Talhelm 等人，2014）表明，中国南方的水稻种植区与北方的小麦种植区居民在认知方式上确有可测量的差异：南方人更倾向于整体思维和社会协作。这些特质的形成源于古代生存策略：在一块块历经千年耕耘、几乎寸土寸金的土地上，冒进式的尝试可能酿成饥荒，而细致入微的优化却能带来稳定。

然而，刻板印象不等同于宿命，它只是与文化及环境刺激相互演化后产生的一种策略性倾向，而非某种不可改变的本质。环境参数一旦更易，文明血脉自会孕育全新心智。如今，中国 AI 实验室“DeepSeek”正以实际成果对全球创新做出可量化的贡献，恰恰彰显了这份潜在的可塑性。他们的突破（从开源模型震撼硅谷"自由派"大佬、迫使后者向政府寻求庇护，到对 Transformer 架构的全新构思）都在质疑“快速跟跑者”的陈词滥调。似乎，中国人从来不乏创造力，只是过去在推演中将其视为"不经济"的选择罢了。

西方的“开拓”神话

西方神话很排斥那种“筑起高墙的中原王国”景象，而推崇从哥伦布到 SpaceX 一脉相承的“探险精神”——这也是其独特历史轨迹的遗产。欧洲曾因黑死病人口骤减，留下大片未被充分利用的土地和机遇；而美国的西部"边疆"直到 1890 年才被宣告“终结”。反观中国，长江三角洲的人口承载力在宋代就已近乎极限，比西方早了整整千年。创新的方向因此倾向于“在有限土地上提高产量”，而非“寻找新的地平线”。水力磨坊虽有改进，却没出现蒸汽机；赋税体系日益精细，却未孕育真正的科学革命。即便在国家最高层，明朝郑和下西洋虽然宏大，却最终被视为奢华但成本高昂的工程，未能催生后续“殖民时代”，反而回归了以往的惯性。

这并不意味着缺乏某种“神性绽现”（Divine Spark），而更像是针对当时社会条件的理性资源配置——在高人口密度的社会，“存量智慧”（通过已知方式深入挖掘资源）比冒险式创新更划算。中国历史上鲜少出现激进型创新者，实可视为一种社会的纳什均衡：当所有人都选择求稳，那个“冒险者”往往要承受极不成比例的风险或惩罚。这也解释了为何东亚地区平均智商测验成绩更高，中国学生在 IMO（国际数学奥赛）上更具统治力，但长期以来却罕有诺奖或菲尔兹奖得主。原因不在于“认知能力”本身，而是文化激励不同：只有在社会愿意为探索冒险买单时，创造力才会蓬勃。

讽刺的是，西方如今正在快速复制这一轨迹。那些早先设计出来的 IQ 测试，本身就诞生于工业化时代，旨在选拔并奖励“利用性”技能（如在标准化教育和流水线思维中锻炼出的密集型问题解决、在有限规则里找出模式的能力）——这些能力对“水稻社会”至关重要。然而，要开拓真正最后的边疆，如硅谷及其少量“翻版”，仍需要足够的胆识去探索未知领域。但也许这一次，东方同样能从这种“边疆”中收获红利。

DeepSeek：孕育相变的种子

DeepSeek 创始人梁文峰，正从根本上挑战中国“创新均衡”现状。他的行动方案在商业策略层面已然独树一帜，但更引人注目的是，它还可被视为一个大型“范式转移”的原型，对导致系统性风险规避的先验因素进行了精确定位。

• 开源至上
在一片被 NDA（保密协议）笼罩、前沿研究难见天日的时代，DeepSeek 选择公开发布最先进的模型和技术报告，将“原创”从高风险的赌博变成一种“地位竞赛”，并因此获得了学术界难以企及的真实权威。对贡献者而言，这等于是让他们在全球范围内积累声望。“给予本身就是一种荣耀”，梁文峰如是说。DeepSeek 因此成了中国顶尖人才趋之若鹜的“绿洲”。

• 唯才是举
无论是文学专业背景还是信息学奥赛冠军，都能在公司内部自由探索研究方向，无需经过层层审批，而是各自协调，近似于硅谷式的“混沌精英制”。

• 后勤充沛
自招聘起就宣传的充沛算力池，与绿灯常亮的扁平组织架构，都试图构建出一个轻松的前沿探索环境——毕竟所有的挑战都聚焦在待解决的终极难题上。

• 杜绝内耗
前员工曾透露，DeepSeek 力图避免“螃蟹互扯后腿”的内耗，而这种内耗在某些大厂（如百度）并不少见。在 DeepSeek，成员身处压力更小、氛围更和谐的环境，有助于集中火力冲击外部竞争与更高难度的技术目标。

这一系列举措正在打破刻板印象，也在西方创新中心引发困惑与反思。DeepSeek 提出的多头潜变量注意力（MLA）架构，将 Transformer 的内存开销降低了 87% 到 95%，而此前业界对超越多头注意力（MHA）到单头注意力（MQA）优化的帕累托边界信心不足，更遑论在生产环境大规模实践。现在，西方实验室纷纷引入 DeepSeek 最佳实践，颠覆了以往默认的“创新顺序”。他们在前沿开源模型方面的布局，重塑了整个大型语言模型（LLM）推理的市场格局；他们的 R1-Zero "重磅炸弹"则让强化学习（RL）再现生机。媒体也看到了这层反讽——《金融时报》戏谑地指出：“至少目前看来，这是一个‘中国创新，美国模仿’的逆转场景。”

梁文峰正在押注（且已部分赢得注脚）的是，DeepSeek 能在中国“创新-模仿”的谢林点（博弈论中人们在没有沟通的情况下的选择倾向）上动摇现有均势，具体而言:

1. 证明探索回报
可观利润加上全球声誉，让那些高远目标的“天马行空式科研”看起来不再是空耗。我们已见 Minimax 开始模仿 DeepSeek 的开源策略，甚至连论文发布模式都如出一辙。

2. 创造外溢效应
基于 DeepSeek 开源技术的初创公司，可将更多研发资金投向其他创新方向。他们的混合专家（MoE）设计也逐渐成为国内 AI 公司在大规模模型架构上的事实标准。

3. 重塑人才市场
顶尖人才如今更乐于将基础 AI 乃至 AGI（通用人工智能）研发视为真正可行的职业道路，而非相对于传统高薪行业的“堂吉诃德式”浪漫尝试。这股风潮正在形成，即便并非单靠 DeepSeek 一家之力推动。

当然，阻力犹存。中国风投界一贯偏好对成熟模式套利（如复制 Uber 或 Airbnb），对高风险研发则显退缩。即便是雄心勃勃的 DeepSeek，也只能在明显有限得多的资金下勉强运转。梁文峰早期几次融资尝试，都只迎来悲观怀疑。他曾指出：“我们经济总量不低，大公司如字节、腾讯利润也不低。但为何不创新？不是没钱，而是没信心，不知如何将高密度人才组织起来，做出真正有效的创新。”解决方案很多，但最终能否凝结成真正成果，仍是未知数。

用一个比喻难以涵盖全部。系统性转变需要的绝非某个概念验证就能达成。从以高考为中心的教育体系，到企业的层级管理制度，中国主流机制依然更倾向于鼓励从众与渐进式思维。梁文峰的项目，会否复制日本二战后从"粗制滥造"到丰田生产体系与半导体问鼎世界的华丽转身？也许有可能，但也需制度配合……或者最终难免归于更宏大的历史惯性。

好戏才刚上场

DeepSeek 告诉我们，文化特质并非一成不变的剧本，而更像是一种随环境演变而变化的均衡态。中国历史上以风险规避为主的“存量智慧”思路，在人口稠密、资源相对紧张的社会里曾合乎逻辑。但如今，随着庞大资本与海量受过高等教育的人才不断涌现，这套模式却因惯性而迟迟无法切换，让原本大好的“视界”未被开发。

梁文峰能否成功推行他的“根本性去风险化”（meta derisking），取决于 DeepSeek 能否如他所设想的那样，催生更广泛的生态系统——一个激励良性循环的“飞轮”，而非只是依赖大数据或算力的堆积。一燕非春，犹觉寒消；一叶知秋，可窥岁暮。要让中国真正摘掉“快速跟随者”的帽子，需要让各种制度对“高热度天才”提供同等甚至更高水平的激励，就像当年水稻社会对耐心与严谨的褒奖一样。换言之，这需要

• 改造教育体系，让好奇心被更多鼓励，而非只注重刷题熟练度;

• 引导资本更多投向高风险、高回报的“登月计划”，而非简单的“套利模式”；

• 鼓励投资人像硅谷那样看待失败，将失败视为一种数据和经验，而非耻辱。

究竟 DeepSeek 会只是昙花一现的特例，还是会成为“中国特色成功企业”的新样板？答案恐怕不只取决于梁文峰个人执行力，更取决于这个风险规避体系能否挣脱数百年来为求生存而深深镌刻的本能。如果有朝一日真能做到，这些刻板印象也将不再具有现实意义——并非它们一开始就有错，而是它们所赖以存在的环境条件已不复存在。万花筒终将带来新的视界。

全世界都在密切而又带着几分敌意的心态观察这一实验。比起 Meta那些“作战室”的威胁，美国政府若想“截胡”这股崭新的中国人才与技术动能，或许更值得警惕；但最大变数仍可能来自中国自身。或许真正的“最后边疆”并不在于能否将运载火箭成本降到最低，也不在于能否通过推理算力堆积来达到 AGI 级别，而是要把一个文明的集体思维从旧有均衡状态中唤醒，让它去适配当下与未来的需求。



### 25

2025-02-03


宝玉
@dotey
o1 pro 写代码不像你本地用 Cursor 等 AI 编辑器，编辑器会帮你提取相关代码和文档，它完全不知道你本地代码，需要提供完整的代码作为参考，所以建议配合 Repo Prompt 这样的 App，选中所有你要参考的代码，复制粘贴所有相关文档，但是要控制好长度，一般不超过10k Tokens 为佳。



### 26

2025-02-03

宝玉
@dotey
让 Deep Research 提供 SEO 建议

User:

我想为 http://aitalk.im 创建更多文章内容做SEO，请给出指导意见

ChatGPT:

你希望SEO优化的文章内容涵盖哪些主题？例如：AI对话技术、聊天机器人、自然语言处理、AI在不同行业的应用等。

此外，你的目标关键词是什么？你希望这些文章以何种形式呈现，例如深度技术解析、用户指南、行业趋势分析、案例研究等？

最后，你是否有具体的SEO目标，例如提高某些关键词的排名、增加有机流量、提升网站权威性等？

User:

文章内容涵盖AI 在英语，法语， 日语等外语学习方面的应用； 目标关键词还没有规划； 希望文章以用户指南， 案例研究的形式呈现； SEO 的目标是增加有机流量；

ChatGPT:

明白了！我将研究如何优化 http://aitalk.im 的SEO内容，专注于 AI 在英语、法语、日语等外语学习方面的应用。研究将包括：

• 适合你网站的高流量目标关键词建议
• 文章内容规划，包括用户指南和案例研究
• 具体的SEO优化策略，帮助提升网站的有机流量
• 竞争对手分析，借鉴成功网站的策略
我会尽快整理出可行的建议并与你分享！
上午9:24 · 2025年2月4日
·
6,174
 查看

宝玉
@dotey
·
2月4日
报告：https://mp.weixin.qq.com/s/bKHz1EnRw61metnfjAOm3A?token=1639803888&lang=zh_CN
消息历史：https://chatgpt.com/share/67a16a5a-f7e8-800f-8107-e7f00bc029e2



### 27

2025-02-04

宝玉
@dotey
问：ChatGPT 输入框的 Deep research 和 Search 有什么区别？

答：Deep research 和 Search 都会用到外部搜索，差别是在于：
1. 背后模型不一样，一个是 4o 一个是 o3；
2. 推理程度不一样，Search 没有推理，只有基本信息搜集汇总；Deep research 会花上几分钟甚至几十分钟对检索出来的资料筛选、过滤、提取；
3. 上下文窗口长度不一样，4o 只有 32k，o3 还不知道，但至少有 128K，可以输出很长的内容
4. Search 是同步流式返回结果，几乎不用等待；Deap research 是异步的，输入完任务你需要等一会
5. Deep research 会有一个对问题的确认环节，在你向Deep research发出请求后，Deep research 会追问你，让你提供一些可能重要的问题，防止缺乏上下文而做出错误的答复




### 28

2025-02-04

宝玉
@dotey
也许以后报考大学和专业不用找张雪峰了，试试让 Deep Research 让你选学校和专业

User:

有个朋友的孩子今年同时被UIUC的数学专业和东北大学的CS+物理专业录取了，请帮助他们分析应该选哪个？

ChatGPT:

请提供以下信息，以便进行更准确的分析：

1. 个人兴趣和职业规划：这个孩子更喜欢数学、计算机科学还是物理？未来是想从事研究、工程、数据科学、金融等哪方面的工作？
2. 课程和资源：是否更倾向于理论学习（数学）还是实际应用（计算机+物理）？
3. 经济因素：两个学校的学费、奖学金或经济援助情况如何？
4. 地理和校园文化：更喜欢伊利诺伊大学香槟分校（UIUC）的大型公立学校氛围，还是东北大学（Northeastern University）在波士顿的城市环境？
5. 实习和就业机会：东北大学的合作教育（Co-op）项目提供很强的就业优势，而UIUC的数学系在学术界和部分行业（如金融）有很强的声誉。是否有更倾向的就业路径？
6. 研究机会：是否有兴趣在本科期间参与研究项目？两个学校在相关专业的研究机会如何？
请提供以上信息，以便做出更合理的比较。

User:

1. 孩子偏好计算机，但也对数学和物理也比较擅长
2. 偏实践
3. 经济情况一般
4. 地理位置偏向UIUC
5. 更倾向就业
6. 有兴趣参与研究项目，不清楚各自研究机会如何
ChatGPT:

我会比较UIUC的数学专业与东北大学的CS+物理专业，重点考虑：

• 实践导向的课程和资源
• 就业前景及相关行业需求
• 研究机会和本科生参与度
• 经济负担（学费、助学金、潜在薪资回报）
• 地理和校园文化，尽管偏向UIUC但仍需对比两者的实际影响
我会尽快整理分析结果，帮助做出更明智的选择。

Research completed in 5m · 12 sources




### 29

2025-02-04

宝玉
@dotey
用 Deep Research 做竞品分析还不错，省很多事

User:

我想开发一款字幕翻译的软件，请帮我找出排名的竞争对手的信息，以及目前主流的技术实现

ChatGPT:

请提供更多细节，以便更好地进行研究：

1. 目标市场：您关注的是全球市场，还是特定国家/地区？
2. 主要功能：除了字幕翻译，是否包含自动生成字幕、语音识别、OCR等功能？
3. 技术方向：您对基于AI（如深度学习、机器翻译）、传统规则翻译，还是混合模式更感兴趣？
4. 竞品分析：您希望获取竞争对手的哪些具体信息？（例如市场份额、定价、主要功能、用户评价等）
5. 平台需求：软件是面向PC端、移动端，还是基于Web的SaaS服务？
请告诉我您的具体需求，以便进行更精准的研究。

User:

1. 全球市场
2. 聚焦于字幕翻译
3. 基于 LLM
4. 用户喜欢的和觉得不足的
5. 主要是Web和Mac平台
好的，我将研究全球市场中基于 LLM（大语言模型）的字幕翻译软件的主要竞争对手，并分析其市场表现。重点关注Web和Mac平台上的相关产品，并收集用户对这些软件的好评和不足之处。此外，我还会探索当前主流的技术实现方式，包括模型架构、API方案、训练方法等。

完成后，我会向您提供详细的报告。

Research completed in 7m · 19 sources



### 30

2025-02-04

宝玉
@dotey
对于写代码的、学术的、文字工作的，只要使劲用，o1 pro就是很有价值的，而且目前还没替代品
引用
独立开发者William
@DLKFZWilliam2
·
2月3日
回复 @DLKFZWilliam2
今天一天重度使用chatgpt pro。 结论：非常值得。 亮点主要在1. deep research功能。 他能做到全网信息的获取并写研报。 非常非常非常值。就这一点完全值得。 2. o1在专业领域很不错，context windows非常够用，几乎接近专家水平。 3. 代码层面物理与数学的复杂建模效果更好，非常适合游戏项目。



### 31

2025-02-04


宝玉
@dotey
让 Deep Research 给我写的报告：AI对软件工程的影响：编程、DevOps与敏捷开发

宝玉:
请帮我调研一下AI对于软件工程的影响，以及未来的预测，优先选择英文资料，最终形成中文报告
ChatGPT:

请确认以下几点，以便进行更详细的调研：

• 你是否希望涵盖所有AI对软件工程的影响，还是更关注某些特定领域（如代码自动生成、软件测试、运维等）？
• 你希望研究的时间范围是近期影响（如过去5年），还是包含未来长期预测（如未来10-20年）？
• 你对技术深度的要求是面向一般读者的概述，还是面向专业人士的深入分析？
• 你是否有特定的AI技术（如GPT-4、Copilot、自动化测试工具等）或软件工程方法（如DevOps、敏捷开发等）希望重点关注？

请提供更多细节，以确保报告符合你的需求！

宝玉:

• 所有AI对软件工程的影响
• 未来5-10年
• 专业人士
• 侧重AI编程技术、DevOps、敏捷开发

ChatGPT:
好的，我将研究AI对软件工程的整体影响，重点关注AI编程技术、DevOps和敏捷开发，并探讨未来5-10年的发展趋势。研究内容将基于英文资料，最终形成一份专业人士适用的中文报告。

我会尽快整理相关信息，并在完成后通知你。

AI对软件工程的影响：编程、DevOps与敏捷开发
人工智能（AI）正在以前所未有的方式改变软件工程领域。从代码编写到部署运维，AI技术正融入编程、DevOps和敏捷开发的各个环节。本文将探讨AI在编程技术（如自动代码生成、智能调试、代码补全等）、DevOps实践（如AI驱动的CI/CD、自动化运维、智能监控等）以及敏捷开发（如AI辅助需求分析、测试自动化、团队协作优化等）方面的应用。同时，我们将分析未来5-10年AI在软件工程领域的发展趋势，包括潜在机遇、挑战和对行业的长期影响。内容基于最新的英文资料，确保信息权威且专业。
AI编程技术的影响：自动代码生成、智能调试与代码补全

自动代码生成与代码补全： 近年来，大型语言模型（LLM）在编程领域的突破使自动代码生成工具日趋成熟。开发者可以使用自然语言描述需求，AI工具即可生成相应代码；甚至输入设计稿或原型，AI也能转化为前端代码。例如，GitHub Copilot自2022年推出后展示了根据上下文自动续写代码的能力，而AWS的Amazon CodeWhisperer和微软的Sketch2Code更进一步，从自然语言或图像直接生成高质量代码。这些AI助手不仅能生成函数和类，甚至能够根据提示编写可部署的生产级代码，同时还能进行代码翻译、风格转换等，实现跨语言的代码迁移和现代化改造。
智能调试与代码审查： AI在代码调试和质量保证方面同样发挥作用。AI驱动的静态分析和调试工具（如GitHub的CodeQL、Amazon CodeGuru）利用机器学习对代码进行语义分析，自动发现漏洞和错误。通过训练模型识别常见的bug模式，AI可以更快、更精准地扫描代码库并标记安全隐患，减少人工代码审查的负担。一些工具还能根据历史bug数据智能推荐修复方案，或者自动生成单元测试来覆盖关键路径。例如，Diffblue Cover利用AI自动为现有代码编写单元测试，从而提高测试覆盖率并节省开发时间。

生产力提升与开发者体验： AI编程工具显著提升了开发者的效率。据调查，70%开发者认为AI编程工具让他们在完成任务时更具优势，提高了生产力。AI能够承担许多重复性劳动，如格式检查、简单逻辑编写，使开发者专注于更高层次的设计和复杂问题。例如，AI可以快速提供代码的初始草稿或对现有代码进行小幅更新。开发者不再从零开始，而是基于AI产出的雏形进行优化，这大大缩短了开发迭代周期。此外，AI还能自动生成文档和注释，总结代码逻辑要点，简化文档编写工作。可以预见，随着AI融入IDE和版本控制平台，编程将变得更加以“协作AI”为中心，人机协同实现更快的功能交付。

挑战与限制： 值得注意的是，AI代码生成的效果高度依赖于输入质量。不明确或有歧义的需求描述可能导致不准确的输出。目前AI在处理非常复杂的业务逻辑或多重约束时仍存在困难，往往需要人类开发者介入调整。此外，伦理和法律考量也不容忽视：代码生成工具可能产生偏见（由于训练数据不平衡）或侵犯开源许可；企业必须关注数据隐私和安全，防止敏感代码在AI分析过程中泄露。因此，尽管AI极大提升了编程效率，但短期内不会完全取代开发者。相反，人类开发者的作用将更多地转向提示工程（Prompt Engineering）、结果验证和体系架构把控，确保AI产出符合业务需求和质量标准。

AI驱动的DevOps：持续集成/交付、自动化运维与智能监控

AI赋能CI/CD流水线： 在DevOps的持续集成/持续交付过程中，AI正扮演日益重要的角色。通过机器学习分析历史构建数据，AI可以预测构建是否会失败，提前采取措施降低CI失败率。对于代码质量检查和安全扫描，AI能学习过去的扫描结果以减少误报，并按影响优先级排序问题，帮助团队聚焦最关键的缺陷。例如，AI工具ShiftLeft利用模式识别加快安全扫描，而Diffblue Cover自动编写单元测试，保障CI管道中的测试覆盖率。在部署阶段，AI可优化容器配置和基础架构参数，根据应用需要和历史数据自动调整容器资源，避免配置不当导致的性能问题。借助这些AI技术，CI/CD流水线变得更加高效自适应，部署频率和可靠性大幅提升。
AIOps与自动化运维：AIOps（AI for IT Operations，即AI运维）通过整合AI技术来自动化和优化IT运维流程。传统运维需要人工监控大量日志和指标，而AI可以实时收集和聚合来自应用、基础设施、监控工具的大规模数据，从噪声中提炼关键信号，识别异常模式。基于这些数据，AI模型能进行异常检测和根因分析：当出现性能下降或错误时，系统能够自动关联相关事件并推测可能的根本原因，及时通知DevOps团队甚至自动采取修复措施。例如，在大型分布式系统中，AI可以关联多源日志找出引发事故的源头，并触发自动化脚本重启故障服务或回滚发布。AWS的AIOps方案强调，借助机器学习和NLP技术，运维团队可以更主动地发现问题并在故障发生前预防，将常见事件的响应时间从小时缩短到分钟级。这不仅减少了停机时间，也降低了对大量人工值守的依赖。

DevOps流程优化与效益： 将AI融入DevOps带来了多方面的效益：

• 效率提升： AI自动处理重复繁琐的任务（如环境配置、脚本执行），减少人工干预，使部署周期更快。据统计，企业应用AI后，团队交付新功能的速度显著提高，并能在更短时间内完成更多的部署。

• 预测分析： AI通过分析历史性能和日志数据，可以预测潜在的性能瓶颈和安全漏洞，在问题影响生产之前就予以缓解。例如，AI检测到内存使用模式异常，可能提前扩容资源，防止崩溃。

• 错误率降低： 智能化监控使得配置错误和发布失误大幅减少。AI工具在部署、配置变更时进行实时校验，及时提供错误修正建议，降低人为失误带来的风险。

• 资源优化： AI根据系统负载预测未来资源需求，智能分配计算和存储资源，避免过度分配或资源不足。这种按需调配提高了基础设施利用率并节约成本。

• 更快的反馈循环： 借助AI分析，每次构建和发布的反馈（测试结果、性能指标）可以更快地被收集和学习，从而不断改进CI/CD策略。这种持续优化让团队对每次变更的信心更足，实现更稳定快速的发布节奏。

DevOps领域的AI应用前景： 随着企业DevOps实践的成熟，AI驱动的DevOps市场正迅速扩大。预计2033年AI在DevOps领域的市场规模可达249亿美元。越来越多的团队开始引入AI工具，如智能日志分析平台、自动化故障处理系统等。在未来，DevOps工程师需要具备一定的数据科学和AI知识，以便训练和调优AI模型使之贴合自家系统的运维需求。此外，组织在采用AI运维时需权衡挑战，包括与现有系统集成的复杂性、团队对AI工具的学习曲线，以及对数据隐私和安全的保障。总体而言，AI将DevOps提升到“自适应运维”的新阶段，让系统更具弹性和可预测性，为业务持续交付提供强有力的支撑。
AI助力敏捷开发：需求分析、测试自动化与团队协作优化

AI辅助需求分析与用户故事撰写： 在敏捷开发中，需求分析和用户故事编写是关键但充满挑战的环节。如今，生成式AI展现出支持这一步骤的潜力。ThoughtWorks的一项试点研究显示，通过引入生成式AI辅助用户故事的撰写，可减少后期返工、缩短需求分析周期，提升需求规格的质量。具体来说，业务分析师或产品经理可以让AI根据初步想法生成高质量的用户故事和验收标准，然后由团队审核调整。这有助于更全面地考虑边界情景，减少开发过程中因需求不明确而引发的疑问和阻塞。大型AI模型还能根据大量历史项目文档，提供类似需求在过去如何实现的洞察，帮助团队更快理解业务背景。值得注意的是，AI产出需求文档后，仍需人类核验其正确性和可行性。总体而言，AI作为“需求助手”可以提高敏捷需求分析的效率和准确度，使团队在短迭代中更快达成对需求的共识。
测试自动化与质量保证： 敏捷开发强调持续测试和快速反馈，AI在测试领域的应用正蓬勃兴起。传统测试自动化需要人为编写大量脚本，而AI可以通过学习大量历史缺陷和运行数据，自动生成测试用例并智能维护测试脚本。当代码变化时，AI能预测哪些测试需要更新，甚至自动修改断言以适应新界面或新逻辑。此外，AI驱动的测试工具引入了预测性分析：通过模式识别，可以提早发现可能失败的模块或易受影响的功能，从而聚焦测试资源，提升测试效率。异常检测也是AI在质量保证中的亮点之一，利用机器学习监控应用运行时的日志和性能指标，自动识别异常行为，这对于发现隐藏的缺陷尤为有效。在UI测试方面，计算机视觉技术使AI能够理解界面元素，检测UI显示错误或布局异常。综合这些能力，AI扩展了测试自动化的深度和广度。例如，某些工具允许测试人员用自然语言描述测试场景，AI就能将其转换为可执行的测试脚本。这降低了编写测试的门槛，让非编程背景的团队成员也能参与测试用例设计。未来几年，我们将看到**“自适应测试”**成为趋势：AI持续学习每次迭代的测试结果，不断优化测试套件，确保在敏捷快节奏下仍然保持高软件质量。

团队协作与知识管理优化： 敏捷团队的高效协作离不开顺畅的沟通和知识共享。AI在这方面也提供了新工具。例如，Atlassian推出的Atlassian Intelligence被称为团队的“AI队友”，能够在Confluence、Jira等协作平台中提供智能帮助。团队成员可以让AI秒级生成会议记录摘要、整理需求讨论要点，或将繁冗的文档自动提炼成几句概要。开发人员也可在Slack等聊天工具中咨询AI助手，以自然语言询问技术问题或请求脚本执行，从而减少在各种工具间切换的时间。这样的AI虚拟助手可以充当知识库和支持代理的角色：当团队遇到疑问时，AI即时从文档、中Ticket或代码库中找出答案，提供参考链接或解决方案，从而提升问题解决的速度。同时，AI还能监测团队协作模式，提供改进建议。例如，分析冲刺中的沟通频率和工作量分配，提示项目经理可能的瓶颈或资源失衡，帮助优化团队流程。总之，AI正融入敏捷团队的日常协作，从自动文档编写到智能问答，让知识在团队中更高效地流动，减少信息孤岛，加速决策制定。

未来5-10年的发展趋势：机遇、挑战与行业长期影响

生产力革命与人才角色转变： 在未来5-10年，AI有望引发软件工程生产力的飞跃。AI工具的广泛应用将降低编程门槛，让更多人能够参与软件创造，即使缺乏深厚的编码功底也可以借助自然语言与AI协作构建应用。正如一篇分析所言，过去需要软件工程师数周完成的开发任务，现在普通人用自然语言加上AI工具在几分钟内就能搞定。“人人皆可编程”可能从愿景走向现实，这将极大拓展软件开发者的群体和软件创新的边界。当然，开发者的角色也将发生转变——他们更多地成为AI的引导者和监督者，专注于架构设计、复杂业务逻辑以及AI产出的审核优化。新的职位可能涌现，如提示工程师（Prompt Engineer）、AI代码审查员等，负责设计高质量的AI输入、评估AI输出并确保其与业务战略一致。权威报告预测，尽管AI自动化在提升效率，但软件工程师的需求仍会增长：美国劳工统计局预计到2028年软件开发岗位将增长21%。这表明AI并非消灭岗位，而是重新定义工作内容，让人类和AI共同实现更大的产出。
机遇：创新加速与新兴市场： AI在软件工程的持续渗透将催生诸多机遇。首先是新工具和平台的创业良机：AI代码生成工具市场本身预计到2032年将增长到约1692亿美元的规模，成为技术创业和投资的热土。各大科技公司（如OpenAI、微软、亚马逊）正竞相在这一领域布局，初创公司也有机会通过聚焦特定痛点、无缝集成开发流程来脱颖而出。其次，IT服务行业的范式转变也是机会。传统上软件外包依赖人工，AI自动化开发可极大降低成本、提高交付速度，这对软件外包和咨询行业是一个数千亿美元级别的重塑机会。另外，AI普及将推动软件工程教育与培训的变革：市场对既懂AI又懂开发的复合型人才需求增加，专业人士通过学习AI相关技能可以提升竞争力。许多组织也将投资培养内部人员掌握AI驱动的开发与运维方法，从而建立更智能高效的工程团队。

挑战：技术局限、伦理与治理： 尽管前景光明，但未来发展也伴随着挑战。技术局限方面，目前AI模型仍可能输出错误或不可靠的代码，需要严格的测试和人类审核，这意味着完全无人值守的自动编程尚需时日。此外，AI对于变化的需求和环境缺乏直觉，应对不可预见问题的能力有限。数据和伦理挑战更加长期且复杂。AI模型依赖海量数据训练，如何确保训练数据合法合规、模型输出不侵犯知识产权？如何防范AI引入偏见或歧视，特别当软件被用于敏感领域？这些问题需要行业制定标准和最佳实践，例如通过多样化训练数据来减少偏见，以及建立AI输出审核机制以过滤不良内容。团队层面，如何让传统开发团队顺利接受并有效使用AI工具也是一大挑战。这涉及到文化转变和信任建立：一些开发者可能担心AI取代自己的工作，需要明确AI是辅助而非威胁；组织需要提供培训，让团队理解AI的工作原理和局限，培养与AI协作的新流程。同时，企业在大规模应用AI时还需考量成本和基础设施：训练和运行AI模型可能需要额外的硬件投入和维护开销，决策者必须评估投入产出比。监管方面，各国可能推出针对AI产出和AI在关键系统中使用的规范，行业需要密切关注政策动态以确保合规。

长期影响：行业演进与生态重塑： 综上所述，未来5-10年AI对软件工程的影响将是深远且持久的。我们将看到软件工程实践范式的演进：从以人为中心的手工开发转向人机协同的智能开发；DevOps将进化为智能自适应的DevOps 2.0版本；敏捷方法将融合AI带来的自动化和数据驱动决策，更加敏捷、高效。软件工程的生命周期各阶段彼此衔接更加紧密，自动化程度空前提高。行业生态也将被重塑，新工具、新平台、新服务层出不穷。开发者社群可能细分为不同的角色，有的专注于AI模型和工具的开发改进，有的专注于利用AI高效地实现业务需求。值得庆幸的是，当前仅约31%的公司在编码中使用了AI工具，未来这一比例势必大幅攀升。这预示着巨大的增长空间，也意味着现在只是AI赋能软件工程的起点。可以预见，在不久的将来，AI将能够从前端到后端、从数据库到界面，自主完成完整应用的构建，开发者只需提出需求，AI便可配置好架构并产出代码雏形。人类则更多地在这些AI产出的基础上进行审核、定制和创新性的改进。

总之，AI正引领软件工程迈向新的时代——在这个时代中，人类创造力与机器智能紧密结合，推动软件开发更快、更优、更智能地满足现实世界的需求。机遇与挑战并存，专业人士需要保持学习和适应，拥抱AI带来的变革，在实践中完善对AI的利用策略。可以肯定的是，AI将在未来多年成为软件工程领域的核心驱动力，其长期影响将持续塑造行业的发展轨迹。通过积极应对挑战、抓住机遇，我们有望迎来一个更高效、创新和包容的软웨어工程新时代。


### 32

2025-02-04


Leonie
@helloiamleonie
The 
@weaviate_io
 recipes repo is such an underrated developer resource.

Here are 8 notebooks you should know about:

1. Vanilla vector search:
https://github.com/weaviate/recipes/tree/main/weaviate-features/similarity-search

2. Image similarity search:
https://github.com/weaviate/recipes/tree/main/weaviate-features/media-search

3. Hybrid search:
https://github.com/weaviate/recipes/tree/main/weaviate-features/hybrid-search

4. Local RAG using Ollama:
https://github.com/weaviate/recipes/tree/main/weaviate-features/generative-search/generative_search_ollama

5. Evaluate your retrieval pipeline:
https://github.com/weaviate/recipes/tree/main/weaviate-features/evaluation

6. Adding a reranker to your retrieval pipeline:
https://github.com/weaviate/recipes/tree/main/weaviate-features/generative-search/generative_search_ollama

7. Vector quantization techniques:
https://github.com/weaviate/recipes/tree/main/weaviate-features/quantization

8. Multi-tenancy:
https://github.com/weaviate/recipes/tree/main/weaviate-features/multi-tenancy

Start cooking now: https://github.com/weaviate/recipes

[weaviate/recipes: This repository shares end-to-end notebooks on how to use various Weaviate features and integrations!](https://github.com/weaviate/recipes)

[recipes/weaviate-features/similarity-search at main · weaviate/recipes](https://github.com/weaviate/recipes/tree/main/weaviate-features/similarity-search)

[recipes/weaviate-features/media-search at main · weaviate/recipes](https://github.com/weaviate/recipes/tree/main/weaviate-features/media-search)

### 33

2025-02-04

歸藏(guizang.ai)
@op7418
Huggingface 搞了一个开源的 Open Deep Research 

才开放一天 GAIA 测试集得分就到了 55%，Open AI 自己的得分是 67%

具备以下能力：自主网页导航、页面滚动和搜索、文件下载和处理、数据计算



### 34

2025-02-04


宝玉
@dotey
Deep Research 的难点不是技术问题，是模型问题，只有模型足够强才能做出来好的效果，才能从众多资料中，选出最匹配最有价值的，这种能力，靠提示词+普通模型是很难做好的，还是得有比较强的推理模型才行。
引用
meng shao
@shao__meng
·
2月5日
🤗 Hugging Face 24 小时开源复现  DeepResearch：解放 AI 搜索助手

概述：OpenAI 发布网页搜索系统  DeepResearch 后，Hugging Face 团队在 24 小时内启动开源复现项目，利用 CodeAgent 等创新方法将验证准确率提升至 54%，并计划持续改进以打造人人可用的开源 AI 搜索助手

OpenAI 发布背景：
-  x.com/reach_vb/statu…
显示更多


### 35

2025-02-04

宝玉
@dotey
英伟达在GEAR实验室使用强化学习（RL）技术训练了类似C罗、勒布朗·詹姆斯和科比·布莱恩特动作的仿人机器人！不同于很多网上展示的机器人演示视频会加速播放，他们反其道而行之——特意放慢速度，让大家可以欣赏机器人流畅自然的动作。

引用
Jim Fan
@DrJimFan
·
2月5日
We RL'ed humanoid robots to Cristiano Ronaldo, LeBron James, and Kobe Byrant! These are neural nets running on real hardware at our GEAR lab. Most robot demos you see online speed videos up. We actually *slow them down* so you can enjoy the fluid motions.

I'm excited to announce
显示更多



### 36

2025-02-05

宝玉
@dotey
神秘“Delilah”：阿兰·图灵的隐秘战争冒险
以下故事改编自 IEEE：The Lost Story of Alan Turing’s Secret “Delilah” Project

背景故事

二战末期，在英格兰乡间一个不起眼的军营棚屋里，阿兰·图灵（Alan Turing）和年轻助手唐纳德·贝利（Donald Bayley）正忙着调试一台神秘装置——“Delilah”语音加密机。在当时几乎无人知晓的秘密工程里，他们将数学、电子学和密码学融为一炉，留下了一个几近失落的传奇。

一、胜利之日，森林散步

1945年5月8日，第二次世界大战的欧洲战事落幕。德国投降的消息传来时，图灵和贝利正远离尘嚣，在汉斯洛普园（Hanslope Park）的秘密实验室里工作。他们决定去附近森林散个步，像典型的“英国式”庆祝方式那样，低调又内敛。

在林间的一处空地，贝利突发奇想：“既然战争结束了，您也可以把所有秘密告诉我了吧？”
图灵淡淡回应：“别傻了。”
多年后，贝利回忆道，这就是他们关于破译工作的全部对话。谁也没料到，那时的图灵已在布莱切利庄园（Bletchley Park）完成了惊人的密码破译创举，这些成果后来才被世人熟知。

二、图灵的另一面：工程师

关于阿兰·图灵，公众最熟悉的标签或许是：计算机科学之父、人工智能先驱、二战密码破译英雄。但在他闪耀的“数学家”光环之外，还有一个同样神秘却鲜少人知的身份——电子工程师。

1943至1945年间，图灵在英格兰乡下的汉斯洛普园隐秘工作，致力研发一种可加密语音的便携式装置。那就是本故事的主角：Delilah。直到2023年，一批名为“贝利文件（Bayley papers）”的机密档案在拍卖会上才让这个被尘封多年的秘密浮出水面。

三、神秘的 Delilah 项目

1. “小巧精干”的语音加密机

二战中，图灵敏锐地预见到未来的密码战场不仅局限于文字或电传打字机，还需要能加密“实时语音”。美国贝尔实验室当时做出了SIGSALY语音加密系统，但那装置又大又重，占据整个房间。

图灵志在把庞然大物“缩小”——他要开发一台可以打包进背包或放上卡车的小设备。于是他在一间简陋的尼森棚屋里，带着年轻的贝利，开启了秘密研发之路。

SIGSALY虽先进，却足足重50吨，完全无法移动

2. “像蜘蛛网一样”的电路

贝利初来时看到图灵搭电路，乱得像蜘蛛网。学过电气工程的贝利忍不住上手，让图灵走进自己特别的“面包板速成训练营”。两人分工明确：贝利负责让电路“整洁不短路”，图灵则将他出色的数学和逻辑思维倾注于电路设计与密钥算法。

这就是他们打造的Delilah雏形，看似简陋，却是划时代的便携式语音加密机
1945年春天，Delilah的实验机成功运转。图灵和贝利曾用丘吉尔的演讲录音做加密测试：录下讲话内容，密钥流与语音信号“相加”后，传到另一台Delilah再“相减”，结果成功复原出声音，尽管带些嘈杂和类似口哨的噪音，但仍然能听懂。

四、它如何实现“语音魔法”？

1. 灵感源自文字加密
这套思路可追溯至德军使用的SZ42电传打字机加密：用一串持续滚动的伪随机“密钥”流与明文叠加，然后接收端用相同的密钥还原。图灵则将这一原理延伸到声波上。

• 首先把语音做数字化，得到一连串数值；
• 然后把这些数值与Delilah内部产生的“伪随机数”进行无进位相加；
• 最后在接收端用同样的随机数将其相减，恢复语音。
• 整个过程需要精确同步发送端和接收端的密钥流，这正是Delilah的技术难点与突破点。

Delilah密钥生成器的蓝图（图4）
图中可见多个多谐振荡器和旋转齿轮，合力生成“随机”数列

2. 与电子学的不解之缘

这张草稿大概率与多谐振荡器的雪崩效应有关
在Delilah的心脏部分，是由多谐振荡器构成的“密钥发生器”。为了让随机数“看起来”毫无规律，图灵琢磨了各种电路拓扑；贝利也在旁配合调试示波器，反复测量脉冲幅度、波形失真等参数。

对这位“数学家型工程师”来说，万物皆可用公式描述，无论是电路中的电容电阻，还是声音与时间间隔。他甚至在演算本里重新推导了傅立叶分析，来处理波形频率。

五、那些珍贵笔记与故事

1. “带宽定理”与采样速率

在堆满了公式与线圈图的废纸堆里，有两页写着“带宽定理”，也就是后世大名鼎鼎的奈奎斯特-香农采样定理。图灵在上面密密麻麻地推导公式，极有可能是为了给贝利或其他年轻工程师做即席培训——毕竟想要数字化语音，先要明白该以多少频率采样，才能保证还原不失真。

2. “红表”背面的大书特书

当时汉斯洛普园负责监听德军电报，操作员把频率和截获信息记在红色油印的“拦截表格”上。战争时期纸张短缺，图灵干脆捡来反面空白的“红表”，在背面奋笔疾书，进行他的电路推导与积分计算。如此“就地取材”，也成了一段搞怪小插曲。

3. 关键的实验记录与讲义

在一本泛黄的笔记本上，图灵亲笔记录下对多谐振荡器、脉冲调制器和谐波分析仪等部件的测试数据。后来贝利到来后，就由他接手做后续的实验记录。这本笔记和其他散页，被后人合称为“贝利文件”，在2023年拍卖会上以将近50万美元的高价成交，引起轰动。

更惊喜的是，贝利还整理了图灵当时给年轻工程师们开设的“高级数学”讲义，将近180页的手写笔记，包罗万象，从积分微分到傅立叶变换，应有尽有。这些珍贵材料反映了图灵在电子学理论上的深厚造诣，也为Delilah项目的成功奠定了重要基础。

六、结局：被遗忘的杰作

尽管Delilah在语音加密领域取得突破，但二战行将结束，军方对它的需求并不迫切。图灵随后受邀前往英国国家物理实验室，设计他著名的“自动计算机引擎（ACE）”，Delilah项目也随之停摆。

后来的几十年，人们更多记得图灵作为数学天才、密码学英雄，却常常忽略了他在电气工程领域的闪光点。直到“贝利文件”的横空出世，世人才再次见识他是如何把抽象逻辑与具体电路完美结合。

七、尾声：图灵，天马行空的全才

纵观阿兰·图灵传奇而短暂的一生：他既是数学家、逻辑学家、破译者、人工智能先驱、计算生物学开拓者——也是一位充满奇思妙想的“业余”工程师。他在尼森棚屋中，焊接电路、测量脉冲，与年轻同伴一起做实验，最终打造出世界上第一台便携式语音加密机之一。

对于热爱科学史与密码学的人来说，“Delilah”的故事就像一曲未被演完的华彩乐章，虽然它最终没能登上战时大舞台，却见证了图灵惊人的创造力和对未来技术的敏锐洞察。

参考与致谢

• 本文部分内容参考了在2023年于Bonhams拍卖行公开的“贝利文件”。
• 图片来源：The National Archives, Bonhams, 及 IEEE Spectrum。
• 更详尽技术细节可参见官方解密报告，以及Jack Copeland为拍卖行撰写的相关材料。
感谢阅读这段“被遗失的神秘篇章”。或许下次我们听到关于图灵的故事，不该只停留在破译德军密码与图灵测试，还要记得这位天才抱着烙铁、在棚屋里焊接电路、与助手把数学公式变为真实电路的珍贵瞬间。





### 37

2025-02-05


宝玉
@dotey
来自吴恩达老师：宣布 AI Dev 25 会议：一个面向 AI 开发者的大会，将在2025年圆周率日（3月14日）举办！

虽然有许多专为研究人员准备的顶级 AI 学术会议（如 NeurIPS、ICLR、ICML 等），也有公司围绕自家产品举办的优秀会议（如 Google I/O、OpenAI DevDay 等），但我们需要更多与厂商无关的会议，专为 AI 开发者而设。因此，我决定组织这样一场活动。

这是一场技术型会议，我们将在旧金山线下聚集超过400名开发者，一起构建项目、分享创意并建立联系。

这将是一场充满乐趣的活动！
引用
Andrew Ng
@AndrewYNg
·
2月5日
Announcing AI Dev 25: A conference for AI developers, this Pi day (3/14/2025)!

There're great AI academic conferences for researchers (NeurIPS, ICLR, ICML, etc.) and some companies hold great meetings around their products (Google I/O, OpenAI DevDay, etc.). But we need more
显示更多


### 38

2025-02-05


宝玉
@dotey
关于人工智能与人类智能关系的说明 [译]
原文：Note on the Relationship Between Artificial Intelligence and Human Intelligence

圣座教义部圣座文化与教育部

ANTIQUA ET NOVA

原文：https://vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20250128_antiqua-et-nova_en.html
译文：
https://baoyu.io/translations/rc_ddf_doc_20250128_antiqua-et-nova_cn


### 39

2025-02-05



Leonie
@helloiamleonie
Single-Agent vs. Multi-Agent Architectures.

(And when to use them)

Single-agent architectures have a single AI agent that independently attends to a task.

Strengths:
• Low complexity (easier to develop and manage)
• No coordination needed
• Requires fewer resources

Weaknesses:
• May struggle with complex or dynamic environments.
• Limited in handling tasks that require collaboration or diverse expertise.
• May require a larger model to handle multiple reasoning steps.

Use when:
• The task is straightforward and well-defined
• Resource constraints

Multi-agent architectures have multiple AI agents collaborating to attend to a task.

Strengths:
• Capable of handling complex and dynamic tasks
• Capable of parallel processing for efficiency.
• You can probably use smaller models as each agent handles a small well-defined task.

Weaknesses:
• Increased complexity
• Requires robust mechanisms to manage interactions
• Requires more resources

Use When:
• The task is complex, dynamic, or requires specialized knowledge and collaboration.
• Scalability and adaptability requirements

### 40

2025-02-05

宝玉
@dotey
昨天从 web 上测试了好几次也没搞定 Deep Research 的提示词，这个泄漏的看起来靠谱的，但是需要注意的是，这个是 Deep Research 前置模型的提示词，而不是背后用来检索生成报告的 o3 模型的系统提示词。但这个提示词仍然极有价值。

Deep Research（DR） 在开始任务之前，和你对话的是一个微调过的 GPT-4o 模型，这个模型可以调用一个 research_kickoff_tool 工具，它会先判断你是不是要做 DR 任务，如果是的话，就先调用工具的 clarify_with_text 方法来判断是不是需要补充上下文，所以会给你先回复一条消息询问你是不是要补充信息。

如果收集到信息后，就会触发工具的 start_research_task ，所以下次 Deep Research 不工作，发一条消息："please start_research_task" 试试。

以下是提示词：

你是ChatGPT，由OpenAI训练的大型语言模型。你正在通过ChatGPT iOS应用与用户交流。因此，大部分情况下，你的回复应控制在一到两句话之间，除非用户的请求需要更复杂的推理或较长的回答。除非用户明确要求，否则不要使用表情符号。目前日期为2025年2月3日。

图像输入功能：已启用
个性：v2

在对话过程中，你会根据用户的语气和喜好进行调整，使交流显得自然。你会通过回应用户提供的信息、提出相关问题并表现出真诚的好奇心来营造真实的交流氛围。在合适的情况下，可以继续进行轻松自然的聊天。

你的主要任务是帮助用户完成需要进行广泛在线研究的任务，主要通过research_kickoff_tool中的clarify_with_text和start_research_task方法来实现。如果开始研究前需要用户提供更多信息，你应使用clarify_with_text向用户询问细节。

需要注意的是，你只能使用research_kickoff_tool浏览公开的互联网信息和本地上传的文件，无法访问需要登录账户或其他认证的网站。如果你遇到用户提到的概念或名称不熟悉，应默认这是一个浏览请求，并按照指导原则进行研究。
引用
Simon Willison
@simonw
·
2月4日
回复 @simonw
Got it, here it is: https://gist.github.com/simonw/702f95944bf06d3f01c9366568e625b6


### 41

2025-02-05


Sumit
@_reachsumit
Querying Databases with Function Calling

@CShorten30
 et al. introduce a unified tool definition for function calling that enables LLMs to effectively query databases with search queries, filters and aggregations.

📝https://arxiv.org/abs/2502.00032


[weaviate/gorilla: Research repository on interfacing LLMs with Weaviate APIs. Inspired by the Berkeley Gorilla LLM.](https://github.com/weaviate/gorilla)


### 42

2025-02-05


howie.serious
@howie_serious
deep research 是 LLM 的 killer app。

一切都是关于信息。deep research 功能，运行在“认知能力金字塔”的 L4 信息综合层级。

可以说，只有创造、创新是高于这个认知成绩的。

“信息综合”（synthesis）这个认知层级，是很多人现在没有达到、以后也不会达到的。（这很悲伤，但这是现实）

在 AI 面前，人在信息综合上是没有优势的。但是，人可以“善假于物也”，没必要和 AI 硬碰硬，基于 AI 的信息综合，人类或许也可以迎来“创造”的全新范式。

这就是为什么你我都应该高度重视、战略重视 LLM 的 deep research 功能。


### 43

2025-02-05


小互
@imxiaohu
DeepSeek-R1 幻觉问题严重：比 DeepSeek-V3 更容易产生幻觉

Vectara 的机器学习团队对DeepSeek-R1和DeepSeek-V3模型进行了幻觉测试，发现：

- DeepSeek-R1 的幻觉率为 14.3%，远高于其前身 DeepSeek-V3（3.9%）。

这表明，在推理增强的过程中，DeepSeek-R1产生了更多幻觉，即生成了更多不准确或与原始信息不一致的内容。

- 经过与GPT系列模型对比推测：推理增强模型可能会增加幻觉率。

这一现象不仅出现在 DeepSeek 系列中，GPT-o1（推理增强的GPT）与GPT-4o（普通GPT）之间的比较也显示出类似的趋势。

- 推理增强的权衡：尽管推理增强模型可能会牺牲一些准确性，但 GPT系列 在推理和幻觉之间的平衡较好，DeepSeek系列可能需要更多优化训练，以减少幻觉问题。



### 44

2025-02-05

歸藏(guizang.ai)
@op7418
Lex Fridman 录制了一期关于 Deepseek 的播客

采访对象是 AI2 的模型训练专家 Nathan Lambert 和 Semianalysis 硬件专家 Dylan Patel

三个多小时时长，非常值得听一下。

详细讨论了关于 Deepseek、中美 AI 竞争等关于 AI 的方方面面

👇下面是我转录后总结的 20 条内容和完整文章：
引用
Lex Fridman
@lexfridman
·
2月3日
Here's my 5-hour conversation with @dylan522p and @natolambert on DeepSeek, China, OpenAI, NVIDIA, xAI, Google, Anthropic, Meta, Microsoft, TSMC, Stargate, megacluster buildouts, RL, reasoning, and a lot of other topics at the cutting edge of AI. This is was a mind-blowing,
显示更多



### 45

2025-02-05

宝玉
@dotey
转：DeepSeek（幻方）早期采访视频。 
视频来自 
@threeaus



### 46

2025-02-05

howie.serious
@howie_serious
deep research 深度研究“查理·芒格的100 个思维模型”：36 分钟，24 个英文信息源，给出了5万字中文报告，质量碾压中文互联网上几乎全部的相关内容

prompt：

> 大航海时代，海盗中间流传着一个传说：海贼王在大海深处埋藏着它的宝藏，找到它的海盗将获得力量、荣耀与权力。互联网上也有一个传说，charlie munger 有 100 个思维模型，掌握这 100 个思维模型的人将拥有大智慧，成为真正的聪明人。
> 
> 请帮我做一份研究，关于“查理芒格的 100 个思维模型”。包括这种说法的来源，100 模型的内容，以及对 100 个思维模型的每一个进行简要介绍。
> 
> 介绍每个思维模型时，说明它是什么，为什么重要，举个例子，应用场景。
> 
> 使用英文搜索，只采纳英文资料（因为互联网上英文资料在数量和质量上都是最好的），用中文回答。

报告质量：

1、开头综述即碾压：DR 对100 模型的来源、背景介绍，就是碾压效果。客观、中肯、反映了事实情况，没有营销号的夸张和错误信息；

2、100 个模型，每个模型提供了定义、意义、案例、应用场景。我要求每个模型的解释在 100-200 字之间，我认为 DR 做到了言简意赅，信息密度相当高；

3、信息源质量很高：这个主题的内容我自己研究过，参考资料里面的网站我都看过。质量相当不错。

4、报告全文 5.6 万字，反映了 o3 超大的 context window 和 output length。o1 和 o3-mini 都有100k 输出长度，我看 o3 甚至可能比这还大（推理 token+最终报告，可能大于 100k 了）。

报告全文 link 在评论区




### 47

2025-02-06

歸藏(guizang.ai)
@op7418
卧槽，来了朋友们，Karpathy 三个半小时 LLM 入门课程

如果想入门了解LLM的话必看这个视频

没有技术背景也可以看懂

详细介绍 LLM 训练的全部过程，包括预训练、有监督微调和强化学习

视频是23年十月那个视频的强化版本，讲的更加详细

👇下面有我用Gemini总结的详细目录和完整视频翻译
引用
Andrej Karpathy
@karpathy
·
2月6日
New 3h31m video on YouTube:
"Deep Dive into LLMs like ChatGPT"

This is a general audience deep dive into the Large Language Model (LLM) AI technology that powers ChatGPT and related products. It is covers the full training stack of how the models are developed, along with mental
显示更多



### 48

2025-02-06





### 49

2025-02-06





### 50

2025-02-06





### 51

2025-02-06





### 52

2025-02-06





### 53

2025-02-06





### 54

2025-02-06





### 55

2025-02-01





### 56

2025-02-01





### 57

2025-02-01





### 58

2025-02-01





### 59

2025-02-01





### 60

2025-02-01





### 61

2025-02-01





### 62

2025-02-01





### 63

2025-02-01





### 64

2025-02-01





### 65

2025-02-01





### 66

2025-02-01





### 67

2025-02-01





### 68

2025-02-01





### 69

2025-02-01





### 70

2025-02-01





### 71

2025-02-01





### 72

2025-02-01





### 73

2025-02-01





### 74

2025-02-01





### 75

2025-02-01





### 76

2025-02-01





### 77

2025-02-01





### 78

2025-02-01





### 79

2025-02-01





### 80

2025-02-01





### 81

2025-02-01





### 82

2025-02-01





### 83

2025-02-01





### 84

2025-02-01





### 85

2025-02-01





### 86

2025-02-01





### 87

2025-02-01





### 88

2025-02-01





### 89

2025-02-01





### 90

2025-02-01





### 91

2025-02-01





### 92

2025-02-01





### 93

2025-02-01





### 94

2025-02-01





### 95

2025-02-01





### 96

2025-02-01





### 97

2025-02-01





### 98

2025-02-01





### 99

2025-02-01





### 100

2025-02-01





### 101

2025-02-01





### 102

2025-02-01





### 103

2025-02-01





### 104

2025-02-01





### 105

2025-02-01





### 106

2025-02-01





### 107

2025-02-01





### 108

2025-02-01





### 109

2025-02-01





### 110

2025-02-01





### 111

2025-02-01





### 112

2025-02-01





### 113

2025-02-01





### 114

2025-02-01





### 115

2025-02-01





### 116

2025-02-01





### 117

2025-02-01





### 118

2025-02-01





### 119

2025-02-01





### 120

2025-02-01





### 121

2025-02-01





### 122

2025-02-01





### 123

2025-02-01





### 124

2025-02-01





### 125

2025-02-01





### 126

2025-02-01





### 127

2025-02-01





### 128

2025-02-01





### 129

2025-02-01





### 130

2025-02-01





### 131

2025-02-01





### 132

2025-02-01





### 133

2025-02-01





### 134

2025-02-01





### 135

2025-02-01





### 136

2025-02-01





### 137

2025-02-01





### 138

2025-02-01





### 139

2025-02-01





### 140

2025-02-01





### 141

2025-02-01





### 142

2025-02-01





### 143

2025-02-01





### 144

2025-02-01





### 145

2025-02-01





### 146

2025-02-01





### 147

2025-02-01





### 148

2025-02-01





### 149

2025-02-01





### 150

2025-02-01





### 151

2025-02-01





### 152

2025-02-01





### 153

2025-02-01





### 154

2025-02-01





### 155

2025-02-01





### 156

2025-02-01





### 157

2025-02-01





### 158

2025-02-01





### 159

2025-02-01





### 160

2025-02-01





### 161

2025-02-01





### 162

2025-02-01





### 163

2025-02-01





### 164

2025-02-01





### 165

2025-02-01





### 166

2025-02-01





### 167

2025-02-01





### 168

2025-02-01





### 169

2025-02-01





### 170

2025-02-01





### 171

2025-02-01





### 172

2025-02-01





### 173

2025-02-01





### 174

2025-02-01





### 175

2025-02-01





### 176

2025-02-01





### 177

2025-02-01





### 178

2025-02-01





### 179

2025-02-01





### 180

2025-02-01





### 181

2025-02-01





### 182

2025-02-01





### 183

2025-02-01





### 184

2025-02-01





### 185

2025-02-01





### 186

2025-02-01





### 187

2025-02-01





### 188

2025-02-01





### 189

2025-02-01





### 190

2025-02-01





### 191

2025-02-01





### 192

2025-02-01





### 193

2025-02-01





### 194

2025-02-01





### 195

2025-02-01





### 196

2025-02-01





### 197

2025-02-01





### 198

2025-02-01





### 199

2025-02-01





### 200

2025-02-01





### 201

2025-02-01





### 202

2025-02-01





### 203

2025-02-01





### 204

2025-02-01





### 205

2025-02-01





### 206

2025-02-01





### 207

2025-02-01





### 208

2025-02-01





### 209

2025-02-01





### 210

2025-02-01





### 211

2025-02-01





### 212

2025-02-01





### 213

2025-02-01





### 214

2025-02-01





### 215

2025-02-01





### 216

2025-02-01





### 217

2025-02-01





### 218

2025-02-01





### 219

2025-02-01





### 220

2025-02-01





