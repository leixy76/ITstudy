### 01

2025-03-01


小互
@imxiaohu
OpenAI首席研究官Mark Chen谈GPT-4.5发布

OpenAI首席研究官Mark Chen接受了Big Technology 的访谈，详细聊了OpenAI最新发布的GPT-4.5。

- 为何此次发布的版本被命名为 GPT-4.5，而不是 GPT-5？

- 对于大规模 AI 模型是否已遇到“扩展壁垒”（Scaling Wall）？

- GPT-4.5 更适用什么任务？

- 大模型 vs. 小型专用模型？

-OpenAI 是不是因为在传统Benchmark上没法做到特别抢眼，就转向宣传情绪识别或情感交流？？


### 02

2025-03-01


宝玉
@dotey
英伟达（Nvidia）CEO 黄仁勋：DeepSeek 事件凸显了 AI 计算需求的巨大增长

Jensen Huang（黄仁勋），英伟达 CEO，在公司发布季度报告后，与 CNBC 的 Jon Fortt 进行了一次特别对话。

---

主持人 Jon Fortt
呃，你也提到了指引超出预期。说到需求，今天早些时候，我和亚马逊 CEO Andy Jassy 聊过。他告诉我，眼下如果他能获得更多用于提供 AWS 服务的 AI 资源，他就能卖出更多。这其实就是你在电话会议中提到的短期需求信号。能否为我们多谈谈那些投资者应该关注的中期信号？是什么让你对这种需求的持续性保持信心？也就是说，数据中心的规模扩张、AI 工厂的建设，与过往情况相比有何不同？

---

黄仁勋
短期的需求信号，主要来自我们的采购订单（PO）以及预测。另外，还有一些预测之外的新创公司正在涌现，有些公司相当有名。为了避免落下任何一家，我就不具体点名了，但它们确实非常出色。它们之所以能够出现，是因为新的推理型 AI 能力以及所谓“通用人工智能”有了突破。
这些创业公司中，有一些专注于“Agentic AI”（具备代理功能的 AI），也有一些与物理世界相关的 AI，它们都需要额外的计算能力。正如 Andy 提到的，这些公司都希望立刻去 AWS 获取更多的算力。这些需求是建立在我们已知的采购订单和预测之外的。
谈到中期需求，可以看到今年数据中心的资本支出与去年相比明显增大。而去年已经是相当大的规模了，对于我们来说也是非常好的一年。有了 Blackwell（指英伟达新一代 GPU 架构）以及更多新数据中心上线，今年也会相当不错。
从长期看，让人兴奋的是，我们正处于“推理型 AI”时代的开端。所谓推理型 AI，指的是在回答问题之前会先进行内部思考，而不是直接生成答案。它会先推理、分步思考，或者在自己的“思维”中搜索，然后才生成一个更聪明的答案。完成这一推理的计算量比以前要大得多，可能是过去的百倍。想想看，

---

主持人 Jon Fortt
我们原本就觉得去年需要的计算量已经相当庞大了。突然之间，“推理型 AI”兴起，比如 DeepSeek 就是一个例子，Chat GPT40 也是一个例子，Groc 3 reasoning 也是一个例子。所有这些推理型的 AI 模型对算力的需求，比以往都要高出很多。那么，让我打断一下，因为有些人对于 DeepSeek 的理解恰好相反，认为它能用更少的算力完成更多事情。但你却说 DeepSeek 事实上意味着算力需求会增大，能否为我们拆解一下？

---

黄仁勋
通常来说，AI 开发主要分三个阶段：
1. 预训练（Pre-training）：就像我们上高中那样，学习基础数学、基础语言、基础知识，这些通用的人类知识储备是后续阶段的基础。
2. 后训练（Post-training）：这一阶段可能会进行人类反馈（Human Feedback），就像老师带着你学习，我们称之为“强化学习：人类反馈”（RLHF）。也可能进行自我练习或推理实验，简称“强化学习”。有时会用“可验证奖励反馈”（Verifiable Reward Feedback），也就是用 AI 来教 AI，让 AI 变得更好。后训练阶段，尤其针对推理型模型的优化，是目前创新最活跃的地方，而这里的算力需求可能比预训练阶段高 100 倍。
3. 推理（Inference）：模型实际为你“思考”和回答问题时的过程。现在的推理不再是单纯地接受输入后马上吐出答案，而是会进行推理——它会想如何回答问题，分步思考，甚至反思生成多个版本，并选择最佳答案后再呈现给你。这意味着推理时所需的计算量，比我们在 ChatGPT 刚出现时的需求高出 100 倍。

因此，结合这些新思路——强化学习、生成式数据以及推理，这些都让算力需求急剧提升。简单来说，DeepSeek 的案例只是进一步证明了推理型 AI 会推动算力需求飙升，而非减少。所有这一切都在推动对 AI 计算资源的极度渴求。



### 03

2025-03-01

宝玉
@dotey
推荐阅读：AI 正在“扼杀”某些公司，却也让另一些公司蓬勃发展 ——让我们一起看看数据

来自 WebMD、Quora、Stack Overflow、Chegg、G2、CNET、Reddit、Wikipedia 和 Substack 的流量趋势
人工智能（AI）正悄悄地颠覆着各大内容网站的商业模式。过去依赖搜索引擎优化（SEO）和广告收入的平台（如 WebMD、G2 和 Chegg），因为 AI 驱动的搜索和聊天机器人可以快速给出即时答案，其流量正在流失。用户不再需要点击多页内容，当 AI 可以在几秒内总结好所有信息。Brian Balfour 将这一现象称为 Product-Market Fit Collapse，认为这是下一波科技领域的重大变革。

推动这一变革的关键里程碑包括：

📅 2022 年 11 月 30 日 – ChatGPT 上线
📅 2023 年 3 月 14 日 – GPT-4 发布
📅 2024 年 5 月 14 日 – Google 推出 AI 概览（AI Overviews）
❗免责声明：我只是从外部角度观察流量走势，并不清楚背后的具体原因。虽然时间节点和 AI 的出现吻合，但和任何商业一样，可能还有多重因素，每家公司的情况也各不相同。

→ 下文数据来源于 SEMRush。
谁的流量在下滑？
WebMD：那个“所有症状都指向癌症”的网站。他们目前正经历严重下滑，而且时间点与主要的 AI 发布相吻合。如果他们不（马上）推出自己的 AI 产品，恐怕会陷入更大麻烦。不过话说回来，他们每月依然有大约 9000 万的访问量。

Quora：曾经是用户提问、专家解答和各种“神回复”并存的平台，如今也在苦苦挣扎。这并不令人意外，因为 AI 可以更快、更可靠（通常）地输出答案。不过即使如此，Quora 依然每月有近 10 亿 次访问。

Stack Overflow：这个程序员问答平台，如今似乎直接面临 ChatGPT 的竞争，后者可以瞬间生成和调试代码。随着 AI 的普及，Stack Overflow 社区正在慢慢降温，但每月依然有大约 2 亿次访问。

Chegg：学生们常用的平台，如今却被 AI 狠狠“教育”了一番。他们最近因为 AI 摘要而起诉 Google，但看起来结果不妙……毕竟 Google 掌握着流量来源，这就是过度依赖第三方渠道的风险。

G2：这个软件评测平台的流量下滑非常严重，跌幅巨大。

CNET：这家科技新闻和测评网站的流量相比四年前下降了 70%。不过他们每月依然有 5000 万 访问量，虽然距曾经的 1.5 亿还差不少。

但也不全是坏消息！
看看 Reddit。很多人说它受到影响，但实际流量数据并没有这么显示——它依然大放异彩。或许因为人们更想要“真实的内容”和社区归属感吧。我每天都要刷一遍 Reddit（光是 /r/LinkedInLunatics 就值得刷）。而且看看他们的纵坐标：访问量可是“数十亿”级别！

Wikipedia 也继续坚守阵地（虽然随着 AI 工具在研究领域的应用，它可能会受到冲击）。不过每月 50 亿的访问量仍然让人叹为观止。

还有一个正在增长的——Substack。用户生成内容才是王道啊。



### 04

2025-03-01


宝玉
@dotey
Google联合创始人Sergey Brin：工程师应每周在办公室工作60小时以开发可能取代他们的AI技术

Google联合创始人Sergey Brin近日表示，对于从事人工智能（AI）的工程师来说，每周在办公室工作60小时是生产力的“最佳状态”。他呼吁工程师们每周五天回到办公室，以加速开发AI技术，而这些技术未来可能会复制甚至取代他们的工作。

Sergey Brin，这位低调的亿万富翁，在OpenAI推出ChatGPT后开始重返Google位于Mountain View的总部。当时，ChatGPT的成功让Google在AI领域的领先地位受到挑战，引发了人们对其技术落后的担忧——尤其讽刺的是，这项技术最初正是由Google内部研发，却被外部竞争对手抢先利用。

如今，Brin正试图在员工中灌输一种紧迫感。他在发给Gemini项目（Google的AI模型和应用代号）工程师的一份备忘录中写道：“竞争已经极大地加速，通向人工通用智能（AGI）的最终竞赛已经开始。”这份备忘录被《纽约时报》曝光。他强调：“我认为我们拥有赢得这场竞赛的所有要素，但我们必须加倍努力。”他进一步指出，每周60小时的工作时间是生产力的最佳状态。

Brin还建议工程师们利用Google自家的AI模型来辅助编写代码。他认为，这样做将使他们成为“世界上最高效的程序员和AI科学家”。


### 05

2025-03-01

Shengyi Wang
@txyyss
四年过去了，最近王虹和合作者 Joshua Zahl 发布了一篇 127 页的 arXiv 预印本论文，宣称解决了三维情况下的挂谷猜想。陶哲轩做了论文解读： https://terrytao.wordpress.com/2025/02/25/the-three-dimensional-kakeya-conjecture-after-wang-and-zahl/

如果通过同行评议，这就是个非常了不起的工作啊。有好事者觉得凭此王虹获得菲尔兹奖也是有可能的。
引用
Shengyi Wang
@txyyss
·
2021年9月10日
突破奖基金会公布了 2022 年科学突破奖的获奖名单 https://breakthroughprize.org/News/65 。其中颁给早期职业女性数学家的 Maryam Mirzakhani 新前沿奖有两位华裔数学家，MIT 的王艺霖 https://yilwang.weebly.com 和 UCLA 的王虹 https://sites.google.com/view/hongwang/home 恭喜她们！好棒！



### 06

2025-03-01

Weaviate • vector database
@weaviate_io
Here are the LEGO blocks of AI agents.

Let’s build some 𝗮𝗴𝗲𝗻𝘁𝗶𝗰 𝗮𝗿𝗰𝗵𝗶𝘁𝗲𝗰𝘁𝘂𝗿𝗲𝘀 with them!

Our new (and FREE!) eBook covers:

•  Single vs multi-agent systems
•  Patterns in multi-agent systems
•  6 examples of agentic architectures 
…and much more!

📌 Download it here: https://weaviate.io/ebooks/agentic-architectures?utm_source=x_twitter&utm_medium=social&utm_campaign=agentic_architectures&utm_content=honeypot_post



### 07

2025-03-01

宝玉
@dotey
公司内推广 AI 编程这种事从外面找可能会适得其反，因为没有解决本质问题，从外面找外包，最终还是要公司内部人继续维护，不想用总有理由拒绝的，还是得从内部解决才能治标治本。

程序员抵制 AI 编程蛮正常的，但原因可能有多方面，需要先搞清楚原因。

原因一：不愿意接受新事物，习惯了旧的轨迹。有一部人是比较容易呆在自己熟悉和习惯了的舒适区，很难打破。

原因二：利益冲突，知道 AI 编程好，但是对自己没好处，如果是自己的项目可能早就用了或者已经用了，但是公司项目做得快只会更多活，搞不好还要裁员，何必呢，最佳策略就是偷偷用但是不让老板知道，干活快了还不用多加活。

原因三：提升效果有限，并非所有场景都能提升 AI 效率，一些公司内部陈旧代码，或者复杂的内核代码，并不见得真的能提升多少效率，当然能用 AI 编程提升一点点效率，但是如果老板期望太高那还不如不用。

如果知道原因，那么就可以针对性想想方案：

如果是团队拒绝接受，主程不接受可以找其他愿意接受的先用起来，有人用起来了，有经验了慢慢好推广。

当然这过程中少不了帮员工花点钱请人给他们培训，或者买点课，好过去外面找外包用，员工情绪上也更容易接受一些。

利益冲突上这种需要老板自己做出表率，给员工信心：
一方面你不要有不切实际的预期，以为用了就能提效几倍，这根本不现实，现阶段就算团队都用 Cursor  普通团队正常可能最多也就提效 20%-30%的样子，除非都是原型项目，这事没那么神，项目中代码之外的烂事太多了，还得架构好一点，否则只是屎山代码继续堆💩，短期快了未来还得还债；

另一方面也要和员工之间建立信任，不要因此压工期、裁人，用了 AI 也还是得让开发人员自己给出工期，觉得不合理可以让他们拆细了说清楚理由就好了。

像这种去外面找外包团队就是一种容易摧毁信任的行为。用人不疑、疑人不用，觉得人不好就换掉，选择了就要相信人家。

如果项目比较特殊，并不能提升多少效率，那也要接受现实，但可以保持观望，现在不行不代表未来不行，AI 进化速度还是很快的。

归根结底，还是要建立信任，让员工觉得用 AI  你是为了他们好，不是为了替代他们，正常人还都是愿意进步的，不愿意进步的也不要太纠结，该淘汰还是得淘汰。

当然这只是我一家之言，随手写的一点不一定多严谨，也欢迎留言分享讨论。
引用
AI进化论-花生
@AlchainHust
·
2月28日
非常有趣和有代表性的技术进步拐点的案例。

一家软件公司的老板看到了AI编程能力的进展和对应的重要性，但是在自己公司推进了遇到了巨大的排斥和阻力。



### 08

2025-03-01


Andrej Karpathy
@karpathy
Okay so I didn't super expect the results of the GPT4 vs. GPT4.5 poll from earlier today 😅, of this thread:
https://x.com/karpathy/status/1895213020982472863

✅ Question 1: GPT4.5 is A; 56% of people prefer it.
❌Question 2: GPT4.5 is B; 43% of people prefer it.
❌Question 3: GPT4.5 is A; 35% of people prefer it.
❌Question 4: GPT4.5 is A; 35% of people prefer it.
❌Question 5: GPT4.5 is B; 36% of people prefer it.

TLDR people prefer GPT4 in 4/5 questions awkward.

To be honest I found this a bit surprising, as I personally found GPT4.5 responses to be better in all cases. Maybe I'm just a "high-taste tester" ;). The thing to look for is that GPT4 more often says stuff that on the face of it looks fine and "type checks" as making sense, but if you really think about it longer and more carefully you will more often catch it saying things that are a bit of an odd thing to say, or are a little too formulaic, a little too basic, a little too cringe, or a little too tropy.

Slightly reassuringly a number of people noted similar surprise in the replies, e.g. the few I noticed as an example:

For the roast (Q2), 4.5 is "punchier"
https://x.com/Danielledeco/status/1895218052276584489

For the story (Q3), with 4.5 "narrative jumped in, had dialogue and hinted at a unique story line. b was a bit more schematic"
https://x.com/MitjaMartini/status/1895231918775640432

For the poem (Q4), 4.5 "is obviously way better. The rhyme scheme and meter of B are so unsophisticated, A has to be 4.5. The voters have poor taste."
https://x.com/CNicholson1988/status/1895287323719540903

So... yeah. Either the high-taste testers are noticing the new and unique structure but the low-taste ones are overwhelming the poll. Or we're just hallucinating things. Or these examples are just not that great. Or it's actually pretty close and this is way too small sample size. Or all of the above. So we'll just wait for the larger, more thorough LM Arena results. But at least from my last 2 days of playing around, 4.5 has a new, deeper charm, it's more creative and inventive at writing, and I find myself laughing more at its jokes, standups and roasts. To be continued :)

翻译帖子
引用
Andrej Karpathy
@karpathy
·
2月28日
GPT 4.5 + interactive comparison :)

Today marks the release of GPT4.5 by OpenAI. I've been looking forward to this for ~2 years, ever since GPT4 was released, because this release offers a qualitative measurement of the slope of improvement you get out of scaling 


### 09

2025-03-01


九原客
@9hills
最近两三周给很多客户反复提及的忠告：

用模型一定要用最好的那个，如果想省钱，请在你的场景下微调，而不是用一个低能力的通用模型，然后试图靠 Prompt 或者工程努力去拯救它。

比如 DeepSeek 的那一堆蒸馏模型是很好的场景级推理模型的Base，但是不要直接用，真的很差。


### 10

2025-03-01

歸藏(guizang.ai)
@op7418
还记得当时 Deepseek R1 火的时候英伟达自己把推理速度推到 3800 Token 每秒都拿出来吹。

就可以对比 Deepseek 自己优化到的 1.4 万 Token 有多离谱。
引用
歸藏(guizang.ai)
@op7418
·
3月1日
没想到 Deepseek 周六还有货

分享了DeepSeek-V3/R1 的推理系统概述

他们的在线服务通过这个系统每个 h800 节点每秒达到了离谱的 1.4 万 Token 输出



### 11

2025-03-01


hristo
@hristoHeli
帮我生成一个美观的 svg 卡片， 使用小红书风格的色彩和背景，要求清晰表达对话过程和信息摘要，展示逻辑和沟通过程。信息源头来自下面采访和交谈：xxxx


### 12

2025-03-01


九原客
@9hills
DeepSeek 这个速度是在 Prefill-Decode 分离 + 大规模专家并行的条件下才能实现。

就是说需要大量的机器才可以，单台机器就很难达到这个速度。

H100 单机 NVIDIA 给的输出 tokens 应该是 800多。考虑prefill 我们就算成 1K（很粗糙哈）

而DeepSeek H800 单机 decode 平均 15K。分布式和极致优化直接让性能提升了 15倍。
引用
DeepSeek
@deepseek_ai
·
3月1日
🚀 Day 6 of #OpenSourceWeek: One More Thing – DeepSeek-V3/R1 Inference System Overview

Optimized throughput and latency via:
🔧 Cross-node EP-powered batch scaling


### 13

2025-03-01


小互
@imxiaohu
兄弟们，这个全新的语音模型很厉害

已经无法分辨了

Sesame： “跨越语音“恐怖谷” ，像真人说话一样的语音模型

当人工合成的语音接近真实人声但仍然存在微小差异时，人类会感到奇怪或不适，这就是所谓的“恐怖谷效应”。

Sesame 公司展示了其最新的语音合成模型CSM， 它在个性、记忆、表达能力和恰当性上表现出了非常惊人的能力。



### 14

2025-03-01


Rainier
@mtrainier2020
我觉得他们是想让行业透明吧。而且用这个办法直接让所有竞争对手面对极大的融资压力。
他们第一波开源，直接把几个小虎小龙中实力差点的，直接清场了。这就是baseline，你闭源的干不过他们，就别干了。
现在这波直接把成本打出来，又是一场血雨腥风。
别的公司的估值，成本，都会受到巨大的冲击。
你为啥成本比别人高这么多？为啥比DS高这么多？
你的估值到底多少倍？为啥比DS还高？
所以，又是一轮大逃杀。
引用
Xiaowen
@ixiaowenz
·
3月1日
把 Profit Margin 这种东西写到 overview 里是啥意思呢。

这种系数，是公司估值的核心参数，margin 大一点，未来的估值就大几倍。

DeepSeek 公布自己的算法并公布自己的 margin，真的是在直接打击现有的模


### 15

2025-03-02

宝玉
@dotey
彭博社：人工智能将颠覆企业组织方式的基本假设

经济体系长期以来建立在这样的观念之上：专业知识稀缺且昂贵。而人工智能即将让这种专业知识变得丰富且几乎免费。

在人类大部分历史中，要雇佣十几位拥有博士学位的专家，往往需要庞大的预算和长达数月的准备时间。如今，只需在聊天机器人中输入几个关键词，就能瞬间获得这些“大脑”的智慧。

当智能的成本变得更低、速度变得更快，支撑我们社会制度的基本假设——“人类洞察力稀缺且昂贵”——将不复存在。当我们可以随时调用十几个专家的见解，公司组织结构会如何变化？我们的创新方式会如何演进？我们每个人又该如何对待学习与决策？摆在个人与企业面前的问题是：当智能本身随处可得且几乎不需成本时，你将如何行动？

智慧“降价”的历史进程

历史上，我们曾不止一次见证知识成本大幅下降、传播途径急速扩张的过程。15世纪中叶印刷机的出现，就极大降低了书面资料的传播成本。在此之前，文本往往由僧侣等专业人士手工誊写，既费钱又费时。

当这道瓶颈被打破后，欧洲迎来了深刻的社会变革：新教改革在宗教层面引发了巨大冲击；识字率迅速上升（为普及初等教育奠定了基础）；科学研究借助印刷出版物蓬勃发展。荷兰和英国等商业导向的国家因此获益匪浅，荷兰进入“黄金时代”，而英国则在随后的数个世纪继续在全球舞台上扮演重要角色。

随着时间的推移，大众识字与公共教育普及，让社会总体智慧得以提升，这也为工业化打下了基础。工厂岗位日益专业化，更复杂的劳动分工推动了经济增长。18世纪末，男性识字率较高的国家率先实现工业化；到了19世纪末，技术最发达的经济体也往往是识字率最高的国家。人们掌握新的技能，催生出更多专业岗位，从而形成延续至今的良性循环。

互联网的出现更是把这一趋势推向新高度。童年时，如果我想研究一个新话题，需要带着笔记去图书馆搜索书目，光是这一步就能耗掉大半天。那时，获取知识既昂贵又不易。

而今，人工智能接过了这条持续千年的“降低智慧成本”的接力棒，为我们的经济与思维方式开启了全新的篇章。

我与 ChatGPT 的“顿悟时刻”

我在 2022 年 12 月第一次使用 ChatGPT 时，就感到这是一个里程碑的产品。起初，我只是用它做些“数字把戏”，比如让 AI “用 Eminem 的风格改写《独立宣言》”（它写出的改编词大概是“Yo, 我们要大声说出来，这里的人绝不会被打倒”，诸如此类）。

事后回想，这就像让一位蓝带厨师为你烤芝士三明治，实在太过大材小用。直到 2023 年 1 月的某个下午，我和 12 岁的女儿花了几小时，借助 ChatGPT 一起设计了一款全新的桌面游戏，才真正意识到这类工具的力量。

当时，我先告诉 AI 我们喜欢哪些桌游、不喜欢哪些，并请它分析其中的共性。它发现，我们喜欢能够“铺设路径”“管理资源”“收集卡牌”“制定战略”且“胜负悬念较大”的游戏机制，同时不喜欢某些常见于《Risk》或《大富翁》的模式。

我要求它在这些元素的基础上构思一些不那么显而易见、但又重要的游戏创意，并希望有一定历史背景。ChatGPT 便想出了一个名为 “Elemental Discoveries” 的游戏：玩家扮演 18~19 世纪的化学研究者，通过收集和交易资源来进行实验、获得分数，并可相互干扰破坏。

然后，我让它进一步细化资源、玩法、游戏机制以及适合玩家扮演的角色。它提出了“炼金术师”“破坏者”“商人”“科学家”等定位，还为他们匹配了历史上的化学家形象，例如拉瓦锡、约瑟夫-路易·盖-吕萨克、玛丽·居里、卡尔·威廉·舍勒等。

借助当时还比较“初级”的 ChatGPT，我们仅用两三小时就制作出了一款虽然粗糙但还算可玩的桌游。最后，我不得不停下来，一方面是时间不够，另一方面我也已经精疲力竭。那次经历让我亲身体会到，AI “合作者”可以将原本需要数周的研发流程，压缩到短短几小时。想想如果把它用于产品开发、市场分析，甚至企业战略，会带来多么巨大的潜力？

在这个过程中，我看到的 ChatGPT 并不仅仅是在复读或堆砌事实；它的表现展现出类比和概念性思维能力，能够联结点子与现实参考，真正地在需求下输出具有创造力的解决方案。

从“随机鹦鹉”到“深度思考者”

一万亿这个数量级已经很惊人了。支撑 ChatGPT 的大型语言模型动辄拥有数十亿、数千亿甚至上万亿个参数，其复杂程度令人咋舌。

我们至今也不完全明白这些模型为什么、又是如何发挥作用。当它们在过去七年屡屡取得突破时，有些理论学者坚持认为它们做不出真正的新东西——2021 年，一些研究者甚至提出 “随机鹦鹉”（stochastic parrots） 这一带有贬义的说法。因为大型语言模型基本是根据训练数据的统计规律来预测文本，仿佛鹦鹉随机重复话语。

然而，对于那些持续体验并赞叹这些工具的人而言，很难相信它们只是在复读。尤其是在过去半年里，这种观点显得更加站不住脚。

最初的大型语言模型，更像是“凭直觉发言”，既缺少“反省”能力，也无所谓“自我意识”。用诺贝尔经济学奖得主丹尼尔·卡尼曼的话来说，人类大多时候依靠系统 1（直觉性、快速反应）的思维，但真正需要深入思考时，我们会切换到系统 2（缓慢、谨慎且更不易出错）。前期版本的 ChatGPT 及其竞品多数只具备类似于系统 1 的表现，没有系统 2 的推理流程。

这种状况在 2024 年 9 月时开始改变，OpenAI 发布了一个名为 o1 的推理模型，它可以对多步的复杂逻辑问题进行分解、验证中间结论（必要时还能回溯修正），从而更好地得出最后结果。相较于传统的大型语言模型仅能依赖记忆或表层模式匹配，新的推理模型逐步具备了拆解问题、审慎推敲的能力。有些测试显示，这种推理模型在专门领域的测验中已能与博士级专家相媲美，甚至更胜一筹。

自 o1 发布后，短短六个月里，AI 又取得了惊人的进展。目前最火热的话题是如何将这些推理模型变成 “自主研究助手”。它们的表现真是令人惊艳。

最近，我让一个研究机器人为我进行一项分析，主题是“对 F1 赛车、科切拉音乐节、迪士尼乐园、拉斯维加斯赌场、医院、大型动物园等大型活动或运营项目进行综合环境影响评估”。AI 花了 73 分钟，查阅了 29 个独立来源，并给出了详细的结果表格和 1,916 字的文字说明。虽然质量仍有提升空间，大约相当于让一位研究生花几天写出的报告水准，但它却为我节省了数日的时间。

仅在 18 个月前，我的 AI 系统只能为我解决一些半小时以内的小任务；而现在，它已经足以应对更复杂、更耗时的研究工作。

认知“生产线”的出现

我们一直在见证与“知识使用”和“认知劳动”相关的一连串演变。从最初寺庙和学者垄断智慧，到印刷术让知识变得可传播，再到互联网让信息本身变得触手可得，问题也逐步转向了“如何理解信息”。现在，那些我们曾认为稀缺且复杂的任务，也变得近在咫尺、且成本低廉。

不过，当我与大企业管理层沟通时，发现他们大多只在一些琐碎领域使用 AI，比如客服自动化来节约成本。Salesforce 的首席执行官曾在去年 12 月表示，他们每周 36,000 条客户支持咨询中，有 86% 是由 AI 回答的；瑞典金融科技公司 Klarna 则声称其三分之二的客服对话由 AI 处理，单是这一措施就为公司带来了 4,000 万美元的利润。然而，纯粹通过客服削减 10% 成本并不足以让企业获得质的飞跃，还没有哪家伟大企业仅凭降低成本而取得成功。

因此，大多数企业先从相对低端的任务着手，用 AI 处理每小时 50 美元的工作（如客服聊天），虽然有用，但远非转型。可事实上，AI 同样胜任每小时“价值”高达 5,000 美元的任务——比如研发、战略规划或者专业咨询。为什么目前只有少数公司把 AI 投入到这些关键环节？

一个原因在于人们很难想象，“必须依靠资深管理者或顶尖专家”才能完成的工作，居然可以（或者部分可以）由机器来承担。正因为卓越人才稀缺，那些高价值任务才显得格外珍贵。我们的组织结构便是在“真正的高智商人才供给有限”这一认知下设计的。

以制药行业为例，一款重磅新药往往能左右企业成败。瓶颈在于把药物推进到昂贵且耗时的审批流程中——通常需要 10~15 年的时间和超过 10 亿美元的投入，而且往往几千个候选分子里只有一个最终上市。与此同时，一家大型制药公司里，市场人员的数量可能比顶尖研发人员多好几千倍，因为真正的资深研究专家极为稀缺。

现阶段，大多数企业领导人仍处在“尝试接受 AI”而非“真正相信 AI”的阶段。他们习惯于认为有些问题太难或太昂贵，能躲就躲。可随着 AI 的出现，约束不再是“我们是否能想出解决办法”，而更是“我们能多快把好想法落地验证”。

这一切都将带来深远影响。当每个企业都能随时调用数位“博士级 AI 专家”时，创新速度自然会大幅加快。就像亨利·福特的汽车流水线让生产过程能迅速迭代、改进一样，AI 可以让思想和解决方案得到持续打磨更新，公司也能更快试错、更快学习、迅速转向。

当然，如果企业并没有能力落实那些由 AI “智囊团”提出的想法，那么再高明的点子也无济于事。能否顺畅地执行与集成，才是真正拉开差距的关键。

我与 AI 共处的日常

过去 18 个月，我逐渐建立起一个“AI 生态系统”为我工作服务。比如，在 2024 年 6 月某天，我一天里调用这些 AI 系统 38 次，累计交互字数达到 7.9 万字，用于研究。

到 2025 年 1 月，我已经不再去统计交流字数了。但在没有对方（真人）反对的情况下，我几乎每次会议都会带一个 AI 做会议记录。日常研究中，我也经常使用好几个不同的 AI 工具。就在写这篇文章的一周内，我向各种大型语言模型发出了至少 144 次查询——这还不包括录音转写（26 次）和代码助理工具的使用。我现在用新一代 AI 工具的次数，比用 Google 搜索还要多。

令人意外的是，虽然我处理的工作量增加、速度更快，但我在电脑屏幕前耗费的时间却比前几年更少了，这对我来说是个非常开心的收获。

当智慧的成本几近于零时，真正的瓶颈已不再是“如何获取大脑”，而是“我们如何善加利用”。那些能提出好问题、客观评估答案并果断行动的个人和组织，将成为大赢家。他们也需要思考：手里的时间多了，该拿它来做什么？

作者 Azeem Azhar 为 Exponential View 专栏作者，同时也是初创企业投资人。





### 16

2025-03-02


宝玉
@dotey
WJS: 中国要求其人工智能领军者因安全考量避免前往美国

北京愈发从国家安全角度审视尖端技术，对企业高管施加更严格的监管

北京——据知情人士透露，中国政府正在指示顶尖的人工智能企业家和研究人员避免前往美国，反映出北京将该技术视作经济和国家安全的优先领域。

当局担心中国的 AI 专家出国旅行时会泄露有关该国技术进展的机密信息，也担忧这些高管可能被拘留并成为中美谈判的筹码，就像特朗普第一任期时，美国曾请求加拿大拘押华为高管的事件。

AI 已成为中美之间的最新技术角力场，以 DeepSeek 和阿里巴巴等中国公司的 AI 模型为代表，对阵美国的 OpenAI、谷歌等行业领军者。北京正日益向前沿领域的企业家施压，要求他们与国家利益保持紧密一致。

此举进一步加深了两国科技界的隔阂。此前，美国在拜登政府期间对半导体出口实施了限制，还沿用了特朗普政府时期开始的关税措施。

在地缘政治紧张局势加剧的背景下，中国希望建立起所谓的“经济堡垒”，要求科技行业在关键领域实现更高程度的自给自足。

科技界人士表示，目前并没有明确的出境禁令，但在上海、北京以及与上海相邻、汇聚了阿里巴巴和 DeepSeek 等公司的浙江等主要科技中心，当局对 AI 等战略敏感领域的龙头企业高管发出了非紧急不出国的“指导意见”。

据这些人士称，如果高管确有紧急需要前往美国及其盟友国家，则须在离境前向当局申报，回国后也要向当局汇报行程内容及会见对象。

知情人士透露，DeepSeek 创始人梁文峰曾拒绝赴巴黎参加 2 月举办的一场 AI 峰会邀请；而在去年，另一家大型中国 AI 创企的创始人在接到北京方面的指示后，也取消了前往美国的计划。

2 月 17 日，北京召集国内最知名的一批企业家与中国领导人习近平举行会面。习近平在会上提醒与会者，在发展技术的同时要牢记“国家使命感”。参加会议的企业家包括 DeepSeek 的梁文峰，以及人形机器人制造商宇树科技（Unitree Robotics）的创始人王星星。

对中国企业家而言，一旦与美国或美国知名人士走得过近，可能会引起政府的审查或不满，被视为“与官方政策相悖”。

阿里巴巴联合创始人马云的经历就是一个例子：2017 年初，他在特朗普就任美国总统之前与其在纽约会面。特朗普当时称马云为“伟大的企业家”。由于会面发生在中国高级官员尚未与当选总统见面之前，这在中国国内引发了一些不满。几年后，北京对马云及其科技帝国展开了强力整顿。

然而，在很多科技领域，中美企业之间的接触仍在继续。包括宇树科技在内的多家中国公司都出现在今年 1 月于拉斯维加斯举行的年度消费电子展（CES）上。

欧亚集团（Eurasia Group）专门研究新兴技术的分析师吕晓萌（Xiaomeng Lu）认为，中国当局可能担心本土技术被美国企业收购或通过授权流失，另一个担忧是人才外流。近年来，许多富裕的中国人移居海外，这对技术领域而言尤其严重。

“对于科技行业来说，人才流失可能带来毁灭性影响，”她说，“这传递出的初步信号是：‘留在这里，不要离开。’”

今年夏天，中国将举办自己的 AI 峰会，届时或能检验中外在 AI 领域还能保持多大程度的交流。中国外交部长王毅曾表示，欢迎世界各国人士来华参与这一活动。




### 17

2025-03-02

小互
@imxiaohu
兄弟们，你们梦寐以求的语音版Photoshop来了

哈哈哈 😅

只要说话就能画图、修图，还能生成视频

Y Combinator 孵化的一个项目：Awen 

它允许用户通过 语音或文本描述 来直接生成和修改图像

例如：“画一个瑞士山湖。现在变成日落。加一条船。再把它动画化。”

Awen 仍处于 测试阶段




### 18

2025-03-02


宝玉
@dotey
很多受欢迎的AI工具中有不少存在安全隐患，包括目前热门的ollama、comfyui，以及企业中常使用的Triton、ray等等。影响包括算力窃取和文件泄漏甚至rce漏洞。腾讯安全团队朱雀实验室的 AI-infra-guarde 工具可以一键检测功能检测这些问题。对安全上有顾虑的同学可以看看。
引用
w8ay
@w8ay1
·
3月3日
腾讯混元安全团队-朱雀实验室发布了AI-infra-guard大模型基础设施评估工具，检测AI系统潜在安全风险。
目前已在GitHub开源，支持检测30种AI组件，200+安全漏洞数据库，包含朱雀实验室发现的Nvidia Triton，Pytorch，ComfyUI与Ray等知名AI组件漏洞。
https://github.com/Tencent/AI-Infra-Guard/


### 19

2025-03-02


張小珺 Xiaojùn
@zhang_benita
2025的AI应用会很热闹。

本集最打动我的一句话：“世界不是线性外推，让自己成为博弈中的重要变量。”

Red说，听到最后片尾曲，听哭了。
xiaoyuzhoufm.com
95. 对Manus创始人肖弘的3小时访谈：世界不是线性外推，做博弈中的重要变量

### 20

2025-03-02



宝玉
@dotey
Claude 设计能力确实好，但要说让前端和设计师合流，可能部分能替代或者提效，但合流可能短期还不现实。交互的魅力在于细节，AI 是在抽卡，偶有惊艳之作，但大部分时候都需要调整细节，而 AI 恰恰最难以掌控的就是细节。

早在网页制作初代，就有工具让设计师把设计图切成网页页面，很多网页设计师也要兼职切图，但是一旦涉及交互细节就很复杂了，需要编程作为支撑。 AI 交互细节的调整，同样也要编程知识作为支撑。
引用
歸藏(guizang.ai)
@op7418
·
3月3日
Claude 3.7 这个前端能力和设计能力真的太顶了

基本上一次就能生成完整的一个应用的完整交互

设计师和前端这个职业合流不需要太久了


### 21

2025-03-02



Jintao Zhang 张晋涛
@zhangjintao9020
刚看到热门的向量数据库 Chroma 现在新版本用 Rust 重写了核心，快了 4 倍。

这可以说是 Rust 的大胜利？ 🦀

不过近年 infra 的部分这个趋势还是会持续，能用 Rust 重写/优化的都会被重写


### 22

2025-03-02


宝玉
@dotey
GPT 4.5 帮你解读推文：这是一段来自推特的交流，主要是关于GPT-4.5发布后，业内人士对大语言模型（LLM）性能评估标准的思考。这里涉及了两位推特用户：

Zvi Mowshowitz：他是一位关注AI发展的分析人士，正在征集大家对于GPT-4.5的看法。

Andrej Karpathy：著名的人工智能专家，曾任特斯拉AI负责人、OpenAI早期成员之一。他在AI圈内极具影响力。

Karpathy在回应Zvi的邀请时，提出了他对于当前大语言模型评测（Evaluation）问题的看法。核心问题是：目前评估LLM的标准变得不清晰，已有的评测方式正逐渐失效或者变得局限。

中文翻译：

Zvi Mowshowitz（发推者）：
GPT-4.5发布后的反馈时间到了！请大家畅所欲言吧。任何你觉得我不该错过的观点，或者你自己的第一反应，都欢迎分享。

Andrej Karpathy（回复者）：

我的第一反应是，现在LLM存在一种评估危机。我其实已经不知道该用什么指标来评估模型了。

过去几年用的比较多的评测指标是MMLU，当时它的确是个不错且实用的标准，但现在早就过时了。

另一个评测标准是SWE-Bench Verified（专注于真实、实际、并经过验证的软件开发问题），我个人非常喜欢，但它的应用范围太窄了。

再比如Chatbot Arena（一个在线的模型对话对比平台），这个平台获得了太多关注（部分是我的原因？），导致各大LLM实验室开始过度拟合于它。

具体表现为实验室开始：
- 大量从API请求中“挖掘”优化提示词（prompt mining）
- 使用内部评测大规模地反复训练
- 更糟糕的是，直接把该平台的模型排名用作训练的监督信号

我觉得Chatbot Arena目前依然算“还行”，因为现在确实还缺乏更好的替代品，但它的信号价值已经在下降。

现在也有一些私有评测指标逐渐涌现，把这些指标组合起来进行评估，也许是一种比较有希望的前进方向。

在缺乏全面、优质评测标准的情况下，我曾尝试通过“感觉（Vibe Checks）”来判断模型的表现，但我现在开始担心这种方式也会产生误导，容易受确认偏差的影响，样本量太少，可靠性低，总之效果并不好。

总结一下我的想法：
我现在真的搞不清楚这些大语言模型究竟有多好了。
引用
Andrej Karpathy
@karpathy
·
3月3日
回复 @TheZvi
My reaction is that there is an evaluation crisis. I don't really know what metrics to look at right now. 
MMLU was a good and useful for a few years but that's long over.
SWE-Bench Verified (real, practical, verified problems) I really like and is great 


### 23

2025-03-02

Gorden Sun
@Gorden_Sun
olmOCR：可能是目前最好的开源OCR模型
基于微调后的7B视觉语言模型，微调数据为260000页PDF页面，完全开源，包括模型权重、数据和训练代码、推理代码，4090可以本地运行。
Github：https://github.com/allenai/olmocr
模型：https://huggingface.co/collections/allenai/olmocr-67af8630b0062a25bf1b54a1
在线使用：https://olmocr.allenai.org



### 24

2025-03-02

歸藏(guizang.ai)
@op7418
提示词和输入图：

帮我实现这样的卡片交互动画，鼠标向下拖动一个卡片时，后面会有卡片补上，让卡片维持相同的数量，而且卡片的颜色跟卡片内图片的颜色要和谐。

注意视觉细节
为卡片加上unsplash的图片
顶部的卡片需要能够拖动，达到一定的距离再消失
为卡片加上大面积的与主题色类似的弥散阴影



### 25

2025-03-02

歸藏(guizang.ai)
@op7418
非常牛批的一个玩法

SRT字幕当成提示进行实时讲故事或创作

1️⃣TTS会将每一个时间戳的字幕读出来
2️⃣同时模型会将字幕润色为图像提示词
3️⃣用可以实时生成图片的模型在TTS阅读时生成图片




### 26

2025-03-04

歸藏(guizang.ai)
@op7418
没想到第一个内置 AI Agents 的浏览器是 Opera

可以通过自然语言让浏览器操作不同网页完成任务

可能就是展示一下？没找到怎么用





### 27

2025-03-04


宝玉
@dotey
Agent搭环境很好使，比如新项目添加单元测试的支持 https://x.com/xicilion/statu/xicilion/status/1896510382686286189



### 28

2025-03-04


宝玉
@dotey
Google Colab 集成了 Data Science Agent

Google Colab 是一个免费、云端托管的 Jupyter Notebook 环境，您可以直接在浏览器中编写并运行 Python 代码。它免费提供对 Google Cloud GPU 和 TPU 的访问权限，这对运行 AI 模型来说是一个革命性的改变，也让项目协作变得更加简化。

去年 12 月，Google 分享了 Colab 中的 Data Science Agent 如何借助 Gemini 为受信任的测试者自动创建笔记本，省去了导入库、加载数据以及编写模板代码等繁琐操作。受信任的测试者对 Data Science Agent 反响热烈，认为它让工作流程更流畅，并能比以往更快地发现洞察。

如今，Google 宣布将 Data Science Agent 推广至年满 18 岁的 Colab 用户以及部分国家和语言地区。Google 也在扩展与大学的合作，希望通过将简单的自然语言描述转换成完整且可运行的 Colab 笔记本，帮助研究实验室在数据处理和分析方面节省时间。

Data Science Agent 的工作原理如下：
1. 从空白开始： 打开一个空白的 Colab 笔记本。
2. 添加数据： 上传您的数据文件。
3. 描述目标： 在 Gemini 侧边栏中描述您想进行的分析或需要的原型（例如，“可视化趋势”、“构建并优化预测模型”、“填充缺失值”、“选择最佳统计方法”）。
4. 见证 Data Science Agent 的自动化过程： 静待生成必要的代码、导入库以及可在 Colab 中执行的分析结果。
视频演示示例：Data Science Agent 从理解数据到在 Colab 笔记本中呈现洞察的自动化分析过程（序列已简化，仅作演示之用。Data Science Agent 可能会出现错误。）

Data Science Agent 带来的益处
• 完整的可运行 Colab 笔记本： 不仅仅是代码片段，而是可以直接执行的完整笔记本。
• 可修改的解决方案： 轻松定制和扩展生成的代码，以满足您的特定需求。
• 可共享的结果： 借助 Colab 标准分享功能，与团队成员进行协作。
• 节省时间： 将更多精力集中在从数据中获取洞察，而不是在环境设置和模板代码上浪费时间。

同时，Google 的 Data Science Agent 在 HuggingFace 的 DABStep 基准测试（DABStep: Data Agent Benchmark for Multi-step Reasoning） 中取得了第 4 名，表现优于基于 GPT 4.0 的 ReAct agents、Deepseek、Claude 3.5 Haiku 和 Llama 3.3 70B 等模型。

立即开始体验 Data Science Agent
只需上传一些数据，然后在 Gemini 侧边栏中概述您的数据分析目标即可轻松上手。您可以在 Kaggle 或 Data Commons 上探索数据集，以下是一些示例数据和提示供您参考：

• Stack Overflow 年度开发者调查：可以尝试询问“可视化最受欢迎的编程语言”
• Iris 鲜花数据集：可以尝试询问“计算并可视化数据集中 Pearson、Spearman 和 Kendall 的相关性”
• Glass Classification：可以尝试询问“在此数据集上训练一个随机森林分类器”

Google 希望这能彻底改变您的数据分析工作流程。
引用
Google AI Developers

@googleaidevs
·
3月4日
Accelerate data science workflows with Google Colab's new Data Science Agent. This agent uses Gemini to act as your coding partner: upload your data, define your analysis goals, and watch a Colab notebook take shape. Now available for all Colab users → https://goo.gle/41DD7IF




### 29

2025-03-04




### 30

2025-03-04





### 31

2025-03-04





### 32

2025-03-04





### 33

2025-03-04





### 34

2025-03-01





### 35

2025-03-01





### 36

2025-03-01





### 37

2025-03-01





### 38

2025-03-01





### 39

2025-03-01





### 40

2025-03-01





### 41

2025-03-01





### 42

2025-03-01





### 43

2025-03-01





### 44

2025-03-01





### 45

2025-03-01





### 46

2025-03-01





### 47

2025-03-01





### 48

2025-03-01





### 49

2025-03-01





### 50

2025-03-01





### 51

2025-03-01





### 52

2025-03-01





### 53

2025-03-01





### 54

2025-03-01





### 55

2025-03-01





### 56

2025-03-01





### 57

2025-03-01





### 58

2025-03-01





### 59

2025-03-01





### 60

2025-03-01





### 61

2025-03-01





### 62

2025-03-01





### 63

2025-03-01





### 64

2025-03-01





### 65

2025-03-01





### 66

2025-03-01





### 67

2025-03-01





### 68

2025-03-01





### 69

2025-03-01





### 70

2025-03-01





### 71

2025-03-01





### 72

2025-03-01





### 73

2025-03-01





### 74

2025-03-01





### 75

2025-03-01





### 76

2025-03-01





### 77

2025-03-01





### 78

2025-03-01





### 79

2025-03-01





### 80

2025-03-01





### 81

2025-03-01





### 82

2025-03-01





### 83

2025-03-01





### 84

2025-03-01





### 85

2025-03-01





### 86

2025-03-01





### 87

2025-03-01





### 88

2025-03-01





### 89

2025-03-01





### 90

2025-03-01





### 91

2025-03-01





### 92

2025-03-01





### 93

2025-03-01





### 94

2025-03-01





### 95

2025-03-01





### 96

2025-03-01





### 97

2025-03-01





### 98

2025-03-01





### 99

2025-03-01





### 100

2025-03-01





### 101

2025-03-01





### 102

2025-03-01





### 103

2025-03-01





### 104

2025-03-01





### 105

2025-03-01





### 106

2025-03-01





### 107

2025-03-01





### 108

2025-03-01





### 109

2025-03-01





### 110

2025-03-01





### 111

2025-03-01





### 112

2025-03-01





### 113

2025-03-01





### 114

2025-03-01





### 115

2025-03-01





### 116

2025-03-01





### 117

2025-03-01





### 118

2025-03-01





### 119

2025-03-01





### 120

2025-03-01





### 121

2025-03-01





### 122

2025-03-01





### 123

2025-03-01





### 124

2025-03-01





### 125

2025-03-01





### 126

2025-03-01





### 127

2025-03-01





### 128

2025-03-01





### 129

2025-03-01





### 130

2025-03-01





### 131

2025-03-01





### 132

2025-03-01





### 133

2025-03-01





### 134

2025-03-01





### 135

2025-03-01





### 136

2025-03-01





### 137

2025-03-01





### 138

2025-03-01





### 139

2025-03-01





### 140

2025-03-01





### 141

2025-03-01





### 142

2025-03-01





### 143

2025-03-01





### 144

2025-03-01





### 145

2025-03-01





### 146

2025-03-01





### 147

2025-03-01





### 148

2025-03-01





### 149

2025-03-01





### 150

2025-03-01





### 151

2025-03-01





### 152

2025-03-01





### 153

2025-03-01





### 154

2025-03-01





### 155

2025-03-01





### 156

2025-03-01





### 157

2025-03-01





### 158

2025-03-01





### 159

2025-03-01





### 160

2025-03-01





### 161

2025-03-01





### 162

2025-03-01





### 163

2025-03-01





### 164

2025-03-01





### 165

2025-03-01





### 166

2025-03-01





### 167

2025-03-01





### 168

2025-03-01





### 169

2025-03-01





### 170

2025-03-01





### 171

2025-03-01





### 172

2025-03-01





### 173

2025-03-01





### 174

2025-03-01





### 175

2025-03-01





### 176

2025-03-01





### 177

2025-03-01





### 178

2025-03-01





### 179

2025-03-01





### 180

2025-03-01





### 181

2025-03-01





### 182

2025-03-01





### 183

2025-03-01





### 184

2025-03-01





### 185

2025-03-01





### 186

2025-03-01





### 187

2025-03-01





### 188

2025-03-01





### 189

2025-03-01





### 190

2025-03-01





### 191

2025-03-01





### 192

2025-03-01





### 193

2025-03-01





### 194

2025-03-01





### 195

2025-03-01





### 196

2025-03-01





### 197

2025-03-01





### 198

2025-03-01





### 199

2025-03-01





### 200

2025-03-01





### 201

2025-03-01





### 202

2025-03-01





### 203

2025-03-01





### 204

2025-03-01





### 205

2025-03-01





### 206

2025-03-01





### 207

2025-03-01





### 208

2025-03-01





### 209

2025-03-01





### 210

2025-03-01





### 211

2025-03-01





### 212

2025-03-01





### 213

2025-03-01





### 214

2025-03-01





### 215

2025-03-01





### 216

2025-03-01





### 217

2025-03-01





### 218

2025-03-01





### 219

2025-03-01





### 220

2025-03-01





### 221

2025-03-01





### 222

2025-03-01





### 223

2025-03-01





### 224

2025-03-01





### 225

2025-03-01





### 226

2025-03-01





### 227

2025-03-01





### 228

2025-03-01





### 229

2025-03-01





### 230

2025-03-01





### 231

2025-03-01





### 232

2025-03-01





### 233

2025-03-01





### 234

2025-03-01





### 235

2025-03-01





### 236

2025-03-01





### 237

2025-03-01





### 238

2025-03-01





### 239

2025-03-01





### 240

2025-03-01





### 241

2025-03-01





### 242

2025-03-01





### 243

2025-03-01





### 244

2025-03-01





### 245

2025-03-01





### 246

2025-03-01





### 247

2025-03-01





### 248

2025-03-01





### 249

2025-03-01





### 250

2025-03-01





