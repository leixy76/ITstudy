## 20250307Run-Finetune-QwQ-32B-with-Bug-Fixes

[Run & Finetune QwQ-32B with Bug Fixes](https://unsloth.ai/blog/qwq-32b)

[Tutorial: How to Run QwQ-32B effectively | Unsloth Documentation](https://docs.unsloth.ai/basics/tutorial-how-to-run-qwq-32b-effectively)

è¿è¡Œä¸å¾®è°ƒ QwQ-32Bï¼Œå¹¶ä¿®å¤ Bug

Mar 7, 2025

By Daniel & Michael

Qwen released QwQ-32B, a powerful reasoning model with performance comparable to DeepSeek-R1 across multiple benchmarks. You may have encountered issues such as infinite loops, repetitions, <think> token errors, and fine-tuning challenges, which do not reflect the modelâ€™s true quality. We hope this blog will help debug and fix most issues! [View Tutorial](https://unsloth.ai/blog/qwq-32b#Tutorial%20QwQ)

Qwen å‘å¸ƒäº† QwQ-32Bï¼Œè¿™æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ¨ç†æ¨¡å‹ï¼ˆreasoning modelï¼‰ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œå…¶æ€§èƒ½å¯ä»¥ä¸ DeepSeek-R1 ç›¸åª²ç¾ã€‚æ‚¨å¯èƒ½é‡åˆ°è¿‡ä¸€äº›é—®é¢˜ï¼Œæ¯”å¦‚æ— é™å¾ªç¯ã€é‡å¤ã€<think> Token é”™è¯¯ä»¥åŠå¾®è°ƒæ–¹é¢çš„é—®é¢˜ï¼Œä½†è¿™äº›å¹¶ä¸èƒ½å®Œå…¨å±•ç° QwQ-32B çš„çœŸå®æ°´å¹³ã€‚æˆ‘ä»¬å¸Œæœ›è¿™ç¯‡åšå®¢èƒ½å¸®åŠ©æ‚¨è°ƒè¯•å¹¶è§£å†³å¤§éƒ¨åˆ†é—®é¢˜ï¼[æŸ¥çœ‹æ•™ç¨‹](https://unsloth.ai/blog/qwq-32b#Tutorial%20QwQ)

Our model uploads include bug fixes and work for fine-tuning, vLLM and Transformers, however if you're using llama.cpp and engines that use llama.cpp as backend you might have experienced issues. To solve the issues follow our tutorial below or read our detailed guide + analysis in our [docs here](https://docs.unsloth.ai/basics/tutorial-how-to-run-qwq-32b-properly). 

æˆ‘ä»¬ä¸Šä¼ çš„æ¨¡å‹åŒ…æ‹¬é”™è¯¯ä¿®å¤ã€å¾®è°ƒå·¥ä½œï¼Œä»¥åŠå¯¹ vLLM å’Œ Transformers çš„æ”¯æŒã€‚ä½†æ˜¯ï¼Œå¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ llama.cpp æˆ–ä»¥ llama.cpp ä¸ºåç«¯çš„å¼•æ“ï¼Œåˆ™å¯èƒ½é‡åˆ°é—®é¢˜ã€‚è¦è§£å†³è¿™äº›é—®é¢˜ï¼Œè¯·æŒ‰ç…§æˆ‘ä»¬ä¸‹é¢çš„æ•™ç¨‹è¿›è¡Œæ“ä½œï¼Œæˆ–é˜…è¯»æˆ‘ä»¬è¯¦ç»†çš„æŒ‡å—åŠåˆ†æï¼Œè¯·å‚é˜…æˆ‘ä»¬çš„æ–‡æ¡£ï¼š[docs here](https://docs.unsloth.ai/basics/tutorial-how-to-run-qwq-32b-properly)ã€‚

See all Unsloth fixed QwQ-32B uploads including [GGUF](https://huggingface.co/unsloth/QwQ-32B-GGUF)& dynamic 4-bit on [here](https://huggingface.co/collections/unsloth/qwen-qwq-32b-collection-676b3b29c20c09a8c71a6235). 

[Tutorial: How to Run QwQ-32B effectively | Unsloth Documentation](https://docs.unsloth.ai/basics/tutorial-how-to-run-qwq-32b-effectively)

[unsloth/QwQ-32B-GGUF Â· Hugging Face](https://huggingface.co/unsloth/QwQ-32B-GGUF)

[Qwen QwQ-32B Collection - a unsloth Collection](https://huggingface.co/collections/unsloth/qwen-qwq-32b-collection-676b3b29c20c09a8c71a6235)

ç‚¹å‡» [è¿™é‡Œ](https://huggingface.co/collections/unsloth/qwen-qwq-32b-collection-676b3b29c20c09a8c71a6235)ï¼ŒæŸ¥çœ‹æ‰€æœ‰ Unsloth ä¿®å¤çš„ QwQ-32B æ¨¡å‹ä¸Šä¼ ï¼ŒåŒ…æ‹¬ [GGUF](https://huggingface.co/unsloth/QwQ-32B-GGUF)æ ¼å¼ä»¥åŠåŠ¨æ€ 4 ä½é‡åŒ–ï¼ˆdynamic 4-bitï¼‰ç‰ˆæœ¬ã€‚

### QwQ-32B Bug Fixes 

QwQ-32B ç¼ºé™·ä¿®å¤

We found a few issues as well specifically impacting finetuning! The EOS token is correct, but the PAD token should probably rather be "<|vision_pad|>" We updated it in here.

æˆ‘ä»¬å‘ç°äº†ä¸€äº›é—®é¢˜ï¼Œå°¤å…¶ä¼šå½±å“æ¨¡å‹çš„å¾®è°ƒï¼å¥æœ« Tokenï¼ˆEOS Tokenï¼‰æ˜¯æ­£ç¡®çš„ï¼Œä½†å¡«å…… Tokenï¼ˆPAD Tokenï¼‰åº”è¯¥ä¸ºã€Œ<|vision_pad|>ã€ã€‚æˆ‘ä»¬å·²åœ¨æ­¤å¤„æ›´æ–°ï¼š

"eos_token": "<|im_end|>",
"pad_token": "<|endoftext|>",

### Official Recommended Settings 

å®˜æ–¹æ¨èè®¾ç½®

According to Qwen, these are the recommended settings for inference:

æ ¹æ® Qwen å®˜æ–¹å»ºè®®ï¼Œä»¥ä¸‹æ˜¯æ¨ç†æ—¶æ¨èä½¿ç”¨çš„è®¾ç½®ï¼š

[Qwen/QwQ-32B Â· Hugging Face](https://huggingface.co/Qwen/QwQ-32B)

1 Temperature of 0.6

Top_K of 40 (or 20 to 40)

Min_P of 0.0

Top_P of 0.95

æ¸©åº¦ï¼ˆTemperatureï¼‰è®¾ç½®ä¸º 0.6ï¼ŒTop_K è®¾ç½®ä¸º 40ï¼ˆæˆ– 20 åˆ° 40ï¼‰ï¼ŒMin_P è®¾ç½®ä¸º 0.0ï¼ŒTop_P è®¾ç½®ä¸º 0.95ã€‚

2 Repetition Penalty of 1.0. (1.0 means disabled in llama.cpp and transformers)

é‡å¤æƒ©ç½šï¼ˆRepetition Penaltyï¼‰è®¾ç½®ä¸º 1.0ï¼ˆåœ¨ llama.cpp å’Œ transformers ä¸­ï¼Œ1.0 è¡¨ç¤ºç¦ç”¨è¯¥åŠŸèƒ½ï¼‰ã€‚

3 Chat template: <|im_start|>user\nCreate a Flappy Bird game in Python.<|im_end|>\n<|im_start|>assistant\n<think>\n

èŠå¤©æ¨¡æ¿ï¼š<|im_start|>user\n ç”¨ Python åˆ›å»ºä¸€ä¸ª Flappy Bird æ¸¸æˆã€‚<|im_end|>\n<|im_start|>assistant\n<think>\n

### Recommended settings for llama.cpp 

llama.cpp ä¼˜åŒ–å»ºè®®

We noticed many people use a Repetition Penalty greater than 1.0. For example 1.1 to 1.5. This actually interferes with llama.cpp's sampling mechanisms. The goal of a repetition penalty is to penalize repeated generations, but we found this doesn't work as expected.

æˆ‘ä»¬å‘ç°è®¸å¤šç”¨æˆ·åœ¨ä½¿ç”¨å¤§äº 1.0 çš„é‡å¤æƒ©ç½šã€‚ä¾‹å¦‚ï¼Œ1.1 åˆ° 1.5ã€‚ä½†å®é™…ä¸Šï¼Œè¿™ä¼šå½±å“ llama.cpp çš„é‡‡æ ·æœºåˆ¶ã€‚é‡å¤æƒ©ç½šï¼ˆRepetition Penaltyï¼‰çš„ç›®çš„æ˜¯ä¸ºäº†é¿å…æ¨¡å‹é‡å¤ç”Ÿæˆå†…å®¹ï¼Œä½†å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§æ–¹å¼å¹¶æ²¡æœ‰è¾¾åˆ°é¢„æœŸçš„æ•ˆæœã€‚

Turning off Repetition Penalty also works (ie setting it to 1.0), but we found using it to be useful to penalize endless generations.

è™½ç„¶å…³é—­é‡å¤æƒ©ç½šï¼ˆè®¾ç½®ä¸º 1.0ï¼‰ä¹Ÿèƒ½é¿å…é‡å¤ç”Ÿæˆï¼Œä½†æˆ‘ä»¬å‘ç°ï¼Œé€‚å½“ä½¿ç”¨é‡å¤æƒ©ç½šæ¥é¿å…æ— é™ç”Ÿæˆæ˜¯æœ‰å¸®åŠ©çš„ã€‚

To use it, we found you must also edit the ordering of samplers in llama.cpp to before applying Repetition Penalty, otherwise there will be endless generations. So add this:

ä¸ºäº†è¾¾åˆ°æœ€ä½³æ•ˆæœï¼Œæ‚¨è¿˜éœ€è¦è°ƒæ•´ llama.cpp ä¸­é‡‡æ ·å™¨çš„é¡ºåºï¼Œç¡®ä¿åœ¨åº”ç”¨é‡å¤æƒ©ç½šä¹‹å‰å®Œæˆé‡‡æ ·ã€‚å…·ä½“æ¥è¯´ï¼Œæ·»åŠ ä»¥ä¸‹å‚æ•°ï¼š

--samplers "top_k;top_p;min_p;temperature;dry;typ_p;xtc"

By default, llama.cpp uses this ordering:

é»˜è®¤æƒ…å†µä¸‹ï¼Œllama.cpp ä½¿ç”¨çš„é‡‡æ ·å™¨é¡ºåºä¸ºï¼š

--samplers "dry;top_k;typ_p;top_p;min_p;xtc;temperature"

We reorder essentially temperature and dry, and move min_p forward. This means we apply samplers in this order:

æˆ‘ä»¬è°ƒæ•´äº† temperature å’Œ dry çš„é¡ºåºï¼Œå¹¶å°† min_p æå‰ã€‚è°ƒæ•´åçš„é‡‡æ ·é¡ºåºå¦‚ä¸‹ï¼š

top_k=40
top_p=0.95
min_p=0.0
temperature=0.6
dry
typ_p
xtc

### Tutorial: Run QwQ-32B with Fixes 

æ•™ç¨‹ï¼šä¿®å¤ QwQ-32B æ¨¡å‹è¿è¡Œé—®é¢˜

#### 1. For llama.cpp & engines that use llama.cpp:

1 é€‚ç”¨äº llama.cpp åŠå…¶ç›¸å…³å¼•æ“ï¼š

You can read our complete guide in our docs here. Obtain the latest llama.cpp at: github.com/ggml-org/llama.cpp. You can follow the build instructions below as well. Change -DGGML_CUDA=ON to -DGGML_CUDA=OFF if you don't have a GPU or just want CPU inference.

æ‚¨å¯ä»¥åœ¨æˆ‘ä»¬çš„æ–‡æ¡£ä¸­æ‰¾åˆ°å®Œæ•´æŒ‡å—ï¼š[å®Œæ•´æŒ‡å—](https://unsloth.ai/blog/qwq-32b)ã€‚è®¿é—® [github.com/ggml-org/llama.cpp](https://github.com/ggml-org/llama.cpp) è·å–æœ€æ–°ç‰ˆæœ¬çš„ llama.cppã€‚æ‚¨ä¹Ÿå¯ä»¥å‚è€ƒä¸‹é¢çš„æ„å»ºæ­¥éª¤ã€‚å¦‚æœæ‚¨æ²¡æœ‰ GPUï¼Œæˆ–è€…åªæƒ³ä½¿ç”¨ CPU è¿›è¡Œæ¨ç†ï¼Œè¯·å°† `-DGGML_CUDA=ON` ä¿®æ”¹ä¸º `-DGGML_CUDA=OFF`ã€‚

[ggml-org/llama.cpp: LLM inference in C/C++](https://github.com/ggml-org/llama.cpp)

`apt-get update
apt-get install build-essential cmake curl libcurl4-openssl-dev -y
git clone https://github.com/ggerganov/llama.cpp
cmake llama.cpp -B llama.cpp/build \
 -DBUILD_SHARED_LIBS=ON -DGGML_CUDA=ON -DLLAMA_CURL=ON
cmake --build llama.cpp/build --config Release -j --clean-first --target llama-quantize llama-cli llama-gguf-split
cp llama.cpp/build/bin/llama-* llama.cpp`

#### 2. Download the model + Test

2 ä¸‹è½½æ¨¡å‹å¹¶è¿›è¡Œæµ‹è¯•å®‰è£…

Download the model via (after installing pip install huggingface_hub hf_transfer ). You can choose Q4_K_M, or other quantized versions (like BF16 full precision). Other variants: huggingface.co/unsloth/QwQ-32B-GGUFThen run Unsloth's Flappy Bird test, which will save the output to Q4_K_M_yes_samplers.txt

`pip install huggingface_hub hf_transfer` åï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¸‹è½½æ¨¡å‹ã€‚å¯ä»¥é€‰æ‹© `Q4_K_M`ï¼Œæˆ–è€…å…¶ä»–é‡åŒ–ç‰ˆæœ¬ï¼ˆå¦‚ `BF16` å…¨ç²¾åº¦ï¼‰ã€‚æ›´å¤šæ¨¡å‹å˜ä½“è¯·è®¿é—®ï¼š[huggingface.co/unsloth/QwQ-32B-GGUF](https://huggingface.co/unsloth/QwQ-32B-GGUF)ã€‚ä¸‹è½½å®Œæˆåï¼Œè¿è¡Œ Unsloth æä¾›çš„ Flappy Bird æµ‹è¯•è„šæœ¬ï¼Œæµ‹è¯•ç»“æœå°†ä¿å­˜åˆ° `Q4_K_M_yes_samplers.txt` æ–‡ä»¶ä¸­ã€‚

[unsloth/QwQ-32B-GGUF Â· Hugging Face](https://huggingface.co/unsloth/QwQ-32B-GGUF)

`# !pip install huggingface_hub hf_transfer
import os
os.environ["HF_HUB_ENABLE_HF_TRANSFER"] = "1"
from huggingface_hub import snapshot_download
snapshot_download(
 repo_id = "unsloth/QwQ-32B-GGUF",
 local_dir = "unsloth-QwQ-32B-GGUF",
 allow_patterns = ["*Q4_K_M*"], # For Q4_K_M
)`

#### 3. Test/Evaluate

3 æµ‹è¯•ä¸è¯„ä¼°

Edit --threads 32 for the number of CPU threads, --ctx-size 16384 for context length, --n-gpu-layers 99 for GPU offloading on how many layers. Try adjusting it if your GPU goes out of memory. Also remove it if you have CPU only inference.We use --repeat-penalty 1.1 and --dry-multiplier 0.5 which you can adjust.

æ ¹æ®æ‚¨çš„ CPU çº¿ç¨‹æ•°ã€ä¸Šä¸‹æ–‡é•¿åº¦å’Œ GPU æ˜¾å­˜å¤§å°ï¼Œè°ƒæ•´ä»¥ä¸‹å‚æ•°ï¼š`--threads 32`ï¼ˆCPU çº¿ç¨‹æ•°ï¼‰ï¼Œ`--ctx-size 16384`ï¼ˆä¸Šä¸‹æ–‡é•¿åº¦ï¼‰ï¼Œ`--n-gpu-layers 99`ï¼ˆç”¨äº GPU åŠ é€Ÿçš„å±‚æ•°ï¼‰ã€‚å¦‚æœ GPU æ˜¾å­˜ä¸è¶³ï¼Œè¯·å°è¯•å‡å° `--n-gpu-layers` çš„å€¼ã€‚å¦‚æœåªä½¿ç”¨ CPU è¿›è¡Œæ¨ç†ï¼Œåˆ™ç§»é™¤æ­¤å‚æ•°ã€‚å»ºè®®ä½¿ç”¨ `--repeat-penalty 1.1` å’Œ `--dry-multiplier 0.5`ï¼Œæ‚¨å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè¿›è¡Œè°ƒæ•´ã€‚

`./llama.cpp/llama-cli \
 --model unsloth-QwQ-32B-GGUF/QwQ-32B-Q4_K_M.gguf \
 --threads 32 \
 --ctx-size 16384 \
 --n-gpu-layers 99 \
 --seed 3407 \
 --prio 2 \
 --temp 0.6 \
 --repeat-penalty 1.5 \
 --repeat-penalty 1.1 \
 --dry-multiplier 0.5 \
 --min-p 0.0 \
 --top-k 40 \
 --top-p 0.95 \
 -no-cnv \
 --samplers "top_k;top_p;min_p;temperature;dry;typ_p;xtc" \
 --prompt "<|im_start|>user\nCreate a Flappy Bird game in Python. You must include these things:\n1. You must use pygame.\n2. The background color should be randomly chosen and is a light shade. Start with a light blue color.\n3. Pressing SPACE multiple times will accelerate the bird.\n4. The bird's shape should be randomly chosen as a square, circle or triangle. The color should be randomly chosen as a dark color.\n5. Place on the bottom some land colored as dark brown or yellow chosen randomly.\n6. Make a score shown on the top right side. Increment if you pass pipes and don't hit them.\n7. Make randomly spaced pipes with enough space. Color them randomly as dark green or light brown or a dark gray shade.\n8. When you lose, show the best score. Make the text inside the screen. Pressing q or Esc will quit the game. Restarting is pressing SPACE again.\nThe final game should be inside a markdown section in Python. Check your code for errors and fix them before the final markdown section.<|im_end|>\n<|im_start|>assistant\n<think>\n" \
 2>&1 | tee Q4_K_M_yes_samplers.txt`
 
See example final Python output here. The full input is:
 
æœ€ç»ˆ Python ä»£ç ç¤ºä¾‹å¦‚ä¸‹ã€‚å®Œæ•´çš„ Prompt å†…å®¹å¦‚ä¸‹ï¼š

[Tutorial: How to Run QwQ-32B effectively | Unsloth Documentation](https://docs.unsloth.ai/basics/tutorial-how-to-run-qwq-32b-effectively)

`<|im_start|>user
Create a Flappy Bird game in Python. You must include these things:
1. You must use pygame.
2. The background color should be randomly chosen and is a light shade. Start with a light blue color.
3. Pressing SPACE multiple times will accelerate the bird.
4. The bird's shape should be randomly chosen as a square, circle or triangle. The color should be randomly chosen as a dark color.
5. Place on the bottom some land colored as dark brown or yellow chosen randomly.
6. Make a score shown on the top right side. Increment if you pass pipes and don't hit them.
7. Make randomly spaced pipes with enough space. Color them randomly as dark green or light brown or a dark gray shade.
8. When you lose, show the best score. Make the text inside the screen. Pressing q or Esc will quit the game. Restarting is pressing SPACE again.
The final game should be inside a markdown section in Python. Check your code for errors and fix them before the final markdown section.<|im_end|>
<|im_start|>assistant
<think>`
	
When running it, we get a runnable game!

è¿è¡Œåï¼Œæ‚¨å°†å¾—åˆ°ä¸€ä¸ªå¯ä»¥æ­£å¸¸è¿è¡Œçš„ Flappy Bird æ¸¸æˆï¼

#### 4. Try without our Fixes:

4 ä¸ä½¿ç”¨ä¿®å¤æ–¹æ¡ˆè¿›è¡Œå°è¯•ï¼š

Now try the same without our fixes! So remove --samplers "top_k;top_p;min_p;temperature;dry;typ_p;xtc" This will save the output to Q4_K_M_no_samplers.txt

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°è¯•åœ¨ä¸åº”ç”¨ä¸Šè¿°ä¿®å¤æ–¹æ¡ˆçš„æƒ…å†µä¸‹è¿è¡Œç›¸åŒçš„æµ‹è¯•ï¼ç§»é™¤ `--samplers"top_k;top_p;min_p;temperature;dry;typ_p;xtc"`å‚æ•°ï¼Œå¹¶å°†è¾“å‡ºä¿å­˜åˆ°`Q4_K_M_no_samplers.txt`æ–‡ä»¶ä¸­ã€‚

./llama.cpp/llama-cli \
 --model unsloth-QwQ-32B-GGUF/QwQ-32B-Q4_K_M.gguf \
 --threads 32 \
 --ctx-size 16384 \
 --n-gpu-layers 99 \
 --seed 3407 \
 --prio 2 \
 --temp 0.6 \
 --repeat-penalty 1.5 \
 --repeat-penalty 1.1 \
 --dry-multiplier 0.5 \
 --min-p 0.1 \
 --top-k 40 \
 --top-p 0.95 \
 -no-cnv \
 --prompt "<|im_start|>user\nCreate a Flappy Bird game in Python. You must include these things:\n1. You must use pygame.\n2. The background color should be randomly chosen and is a light shade. Start with a light blue color.\n3. Pressing SPACE multiple times will accelerate the bird.\n4. The bird's shape should be randomly chosen as a square, circle or triangle. The color should be randomly chosen as a dark color.\n5. Place on the bottom some land colored as dark brown or yellow chosen randomly.\n6. Make a score shown on the top right side. Increment if you pass pipes and don't hit them.\n7. Make randomly spaced pipes with enough space. Color them randomly as dark green or light brown or a dark gray shade.\n8. When you lose, show the best score. Make the text inside the screen. Pressing q or Esc will quit the game. Restarting is pressing SPACE again.\nThe final game should be inside a markdown section in Python. Check your code for errors and fix them before the final markdown section.<|im_end|>\n<|im_start|>assistant\n<think>\n" \
 2>&1 | tee Q4_K_M_no_samplers.txt
 
You will get some looping, but problematically incorrect Python syntax and many other issues. For example the below looks correct, but is wrong! Ie line 39 pipes.clear() ### <<< NameError: name 'pipes' is not defined. Did you forget to import 'pipes'? See our example which shows totally incorrect results here

æ‚¨ä¼šå‘ç°æ¨¡å‹ç”Ÿæˆçš„å†…å®¹å­˜åœ¨å¾ªç¯ï¼Œä»¥åŠä¸æ­£ç¡®çš„ Python è¯­æ³•å’Œå…¶ä»–é—®é¢˜ã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹ä»£ç ç‰‡æ®µçœ‹èµ·æ¥æ­£ç¡®ï¼Œä½†å®é™…ä¸Šå­˜åœ¨é”™è¯¯ï¼åœ¨ç¬¬ 39 è¡Œï¼Œ`pipes.clear()`ä¼šæŠ›å‡º `NameErrorï¼šname 'pipes' is not defined` é”™è¯¯ã€‚è¿™æ˜¯å› ä¸ºä»£ç ä¸­ç¼ºå°‘ `import pipes` è¯­å¥ã€‚æ›´å¤šé”™è¯¯ç¤ºä¾‹è¯·å‚è€ƒ [é“¾æ¥]ã€‚

[Tutorial: How to Run QwQ-32B effectively | Unsloth Documentation](https://docs.unsloth.ai/basics/tutorial-how-to-run-qwq-32b-effectively)

If you use --repeat-penalty 1.5, it gets even worse and more obvious, with actually totally incorrect syntax.

å¦‚æœæ‚¨ä½¿ç”¨`--repeat-penalty 1.5`ï¼Œé—®é¢˜ä¼šæ›´åŠ ä¸¥é‡ï¼Œæ¨¡å‹ä¼šç”Ÿæˆå®Œå…¨æ— æ•ˆçš„è¯­æ³•ã€‚

You might be wondering maybe it's Q4_K_M? B16 ie full precision should work fine right? Incorrect - the outputs again fail if we do not use our fix of --samplers "top_k;top_p;min_p;temperature;dry;typ_p;xtc" when using a Repetition Penalty.

ä¹Ÿè®¸æ‚¨ä¼šè®¤ä¸ºé—®é¢˜å‡ºåœ¨`Q4_K_M`é‡åŒ–æ¨¡å‹ä¸Šï¼Ÿä½¿ç”¨`BF16`å…¨ç²¾åº¦æ¨¡å‹åº”è¯¥æ²¡é—®é¢˜å§ï¼Ÿç­”æ¡ˆæ˜¯å¦å®šçš„ã€‚å¦‚æœä¸ä½¿ç”¨ `--samplers "top_k;top_p;min_p;temperature;dry;typ_p;xtc"` ä¿®å¤æ–¹æ¡ˆï¼Œå³ä½¿æ˜¯å…¨ç²¾åº¦æ¨¡å‹ä¹Ÿä¼šç”Ÿæˆé”™è¯¯çš„è¾“å‡ºã€‚

### <think> token not shown? 

å…³äº `<think>` Token æ˜¾ç¤ºé—®é¢˜çš„è¯´æ˜

Some people are reporting that because <think> is default added in the chat template, some systems are not outputting the thinking traces correctly. You will have to manually edit the Jinja template from:

æœ‰ç”¨æˆ·æŠ¥å‘Šè¯´ï¼Œç”±äºèŠå¤©æ¨¡æ¿é»˜è®¤æ·»åŠ äº† `<think>`ï¼Œå¯¼è‡´æŸäº›ç³»ç»Ÿæ— æ³•æ­£ç¡®æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹ã€‚æ‚¨éœ€è¦æ‰‹åŠ¨ä¿®æ”¹ Jinja æ¨¡æ¿ï¼Œåˆ é™¤ä»¥ä¸‹ä»£ç æ®µä¸­çš„ `<think>\n`ï¼š

`{%- if tools %} {{- '<|im_start|>system\n' }} {%- if messages[0]['role'] == 'system' %} {{- messages[0]['content'] }} {%- else %} {{- '' }} {%- endif %} {{- "\n\n# Tools\n\nYou may call one or more functions to assist with the user query.\n\nYou are provided with function signatures within <tools></tools> XML tags:\n<tools>" }} {%- for tool in tools %} {{- "\n" }} {{- tool | tojson }} {%- endfor %} {{- "\n</tools>\n\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n<tool_call>\n{\"name\": <function-name>, \"arguments\": <args-json-object>}\n</tool_call><|im_end|>\n" }} {%- else %} {%- if messages[0]['role'] == 'system' %} {{- '<|im_start|>system\n' + messages[0]['content'] + '<|im_end|>\n' }} {%- endif %} {%- endif %} {%- for message in messages %} {%- if (message.role == "user") or (message.role == "system" and not loop.first) %} {{- '<|im_start|>' + message.role + '\n' + message.content + '<|im_end|>' + '\n' }} {%- elif message.role == "assistant" and not message.tool_calls %} {%- set content = message.content.split('</think>')[-1].lstrip('\n') %} {{- '<|im_start|>' + message.role + '\n' + content + '<|im_end|>' + '\n' }} {%- elif message.role == "assistant" %} {%- set content = message.content.split('</think>')[-1].lstrip('\n') %} {{- '<|im_start|>' + message.role }} {%- if message.content %} {{- '\n' + content }} {%- endif %} {%- for tool_call in message.tool_calls %} {%- if tool_call.function is defined %} {%- set tool_call = tool_call.function %} {%- endif %} {{- '\n<tool_call>\n{"name": "' }} {{- tool_call.name }} {{- '", "arguments": ' }} {{- tool_call.arguments | tojson }} {{- '}\n</tool_call>' }} {%- endfor %} {{- '<|im_end|>\n' }} {%- elif message.role == "tool" %} {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != "tool") %} {{- '<|im_start|>user' }} {%- endif %} {{- '\n<tool_response>\n' }} {{- message.content }} {{- '\n</tool_response>' }} {%- if loop.last or (messages[loop.index0 + 1].role != "tool") %} {{- '<|im_end|>\n' }} {%- endif %} {%- endif %} {%- endfor %} {%- if add_generation_prompt %} {{- '<|im_start|>assistant\n<think>\n' }} {%- endif %}`

to another by removing the <think>\n at the end. The model will now have to manually add <think>\n during inference, which might not always succeed. DeepSeek also edited all models to default add a <think> token to force the model to go into reasoning model.

So change {%- if add_generation_prompt %} {{- '<|im_start|>assistant\n<think>\n' }} {%- endif %} to {%- if add_generation_prompt %} {{- '<|im_start|>assistant\n' }} {%- endif %} ie remove <think>\nSee full jinga template with removed <think>\n part here.

ä¹Ÿå°±æ˜¯è¯´ï¼Œç§»é™¤`<think>\n`ã€‚ä¿®æ”¹åï¼Œæ¨¡å‹éœ€è¦åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ‰‹åŠ¨æ·»åŠ `<think>\n`ï¼Œä½†è¿™å¯èƒ½ä¸ä¼šæ€»æ˜¯æˆåŠŸã€‚DeepSeek ä¿®æ”¹äº†æ‰€æœ‰æ¨¡å‹ï¼Œé»˜è®¤æ·»åŠ `<think>`Tokenï¼Œä»¥å¼ºåˆ¶æ¨¡å‹è¿›å…¥æ¨ç†æ¨¡å¼ã€‚æŸ¥çœ‹å·²ç§»é™¤`<think>\n` çš„å®Œæ•´ Jinja æ¨¡æ¿ [é“¾æ¥]ã€‚

[Tutorial: How to Run QwQ-32B effectively | Unsloth Documentation](https://docs.unsloth.ai/basics/tutorial-how-to-run-qwq-32b-effectively)

### Experimental Results + Notes 

å®éªŒç»“æœä¸æ³¨æ„äº‹é¡¹

We first thought maybe:

æœ€åˆï¼Œæˆ‘ä»¬è®¤ä¸ºé—®é¢˜å¯èƒ½å‡ºåœ¨ï¼š

1 QwQ's context length was not natively 128K, but rather 32K with YaRN extension. We tried overriding llama.cpp's YaRN handling, but nothing changed. For example in the QwQ-32B readme file we see the below:

{
  ...,
  "rope_scaling": {
    "factor": 4.0,
    "original_max_position_embeddings": 32768,
    "type": "yarn"
  }
}

QwQ çš„ä¸Šä¸‹æ–‡é•¿åº¦å¹¶éåŸç”Ÿæ”¯æŒ 128Kï¼Œè€Œæ˜¯é€šè¿‡ YaRN æ‰©å±•åœ¨ 32K çš„åŸºç¡€ä¸Šå®ç°çš„ã€‚æˆ‘ä»¬å°è¯•ä¿®æ”¹ llama.cpp ä¸­å…³äº YaRN çš„å¤„ç†æ–¹å¼ï¼Œä½†æ²¡æœ‰äº§ç”Ÿæ•ˆæœã€‚ä¾‹å¦‚ï¼Œåœ¨ QwQ-32B çš„ readme æ–‡ä»¶ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¦‚ä¸‹ä¿¡æ¯ï¼š

2 We also thought maybe the RMS Layernorm epsilon was wrong - not 1e-5 but maybe 1e-6. For example this has rms_norm_eps=1e-06, whilst this has rms_norm_eps=1e-05 . We also overrided it, but it did not work:

æˆ‘ä»¬è¿˜æ€€ç–‘å¯èƒ½æ˜¯ RMS Layernorm çš„ epsilon å€¼ï¼ˆRMS Layernorm epsilonï¼‰è®¾ç½®æœ‰è¯¯ï¼Œæœ¬åº”ä¸º 1e-5 å´è¢«è®¾ç½®ä¸ºäº† 1e-6ã€‚ä¾‹å¦‚ï¼Œè¿™ä¸ªæ¨¡å‹æ–‡ä»¶çš„ `rms_norm_eps` å‚æ•°å€¼ä¸º 1e-06ï¼Œè€Œå¦ä¸€ä¸ªæ¨¡å‹æ–‡ä»¶çš„è¯¥å‚æ•°å€¼ä¸º 1e-05ã€‚æˆ‘ä»¬å°è¯•ä¿®æ”¹è¿™ä¸ªå€¼ï¼Œä½†é—®é¢˜ä¾æ—§æ²¡æœ‰è§£å†³ï¼š

3 We also tested if tokenizer IDs matched between llama.cpp and normal Transformers courtesy of @kalomaze. They matched, so this was not the culprit. We provide our experimental results in our docs.

æ­¤å¤–ï¼Œåœ¨ @kalomaze çš„å¸®åŠ©ä¸‹ï¼Œæˆ‘ä»¬è¿˜æµ‹è¯•äº† llama.cpp å’Œæ ‡å‡†çš„ Transformer æ¨¡å‹ä¹‹é—´ï¼Œtokenizer çš„ ID æ˜¯å¦ä¸€è‡´ã€‚ç»“æœæ˜¾ç¤ºå®ƒä»¬æ˜¯åŒ¹é…çš„ï¼Œå› æ­¤å¯ä»¥æ’é™¤ tokenizer çš„é—®é¢˜ã€‚è¯¦ç»†çš„å®éªŒç»“æœè¯·å‚è€ƒæˆ‘ä»¬çš„æ–‡æ¡£ã€‚

### Dynamic 4-bit Quants 

åŠ¨æ€ 4 ä½é‡åŒ–ï¼ˆDynamic 4-bit Quants)

We also uploaded dynamic 4-bit quants which increase accuracy vs naive 4-bit quantizations! We uploaded dynamic 4-bit quants to here. We attached the QwQ quantization error plot analysis for both activation and weight quantization errors below:

æˆ‘ä»¬ä¸Šä¼ äº†åŠ¨æ€ 4 ä½é‡åŒ–ç‰ˆæœ¬ï¼Œç›¸æ¯”äºç®€å•çš„ 4 ä½é‡åŒ–ï¼Œå®ƒèƒ½å¤Ÿæ˜¾è‘—æé«˜æ¨¡å‹ç²¾åº¦ã€‚ç‚¹å‡» [é“¾æ¥] å³å¯è·å–æˆ‘ä»¬ä¸Šä¼ çš„åŠ¨æ€ 4 ä½é‡åŒ–æ¨¡å‹ã€‚ä¸‹æ–¹æ˜¯æˆ‘ä»¬å¯¹æ¿€æ´»å’Œæƒé‡è¿›è¡Œ QwQ é‡åŒ–åçš„è¯¯å·®åˆ†æå›¾ï¼š

[Unsloth - Dynamic 4-bit Quantization](https://unsloth.ai/blog/dynamic-4bit)

[unsloth/QwQ-32B-unsloth-bnb-4bit Â· Hugging Face](https://huggingface.co/unsloth/QwQ-32B-unsloth-bnb-4bit)

Since vLLM 0.7.3 (2025 Feb 20), vLLM now supports loading Unsloth dynamic 4-bit quants!

è‡ª vLLM 0.7.3ï¼ˆ2025 å¹´ 2 æœˆ 20 æ—¥ï¼‰èµ·ï¼ŒvLLM å¼€å§‹æ”¯æŒåŠ è½½ Unsloth çš„åŠ¨æ€ 4 ä½é‡åŒ–æ¨¡å‹ï¼

[Release v0.7.3 Â· vllm-project/vllm](https://github.com/vllm-project/vllm/releases/tag/v0.7.3)

### Finetuning QwQ-32B

QwQ-32B1xL4 24GB13xlonger context
QwQ-32B1xL4 24GB2xfaster
QwQ-32B1xL4 24GB>70%less VRAM

QwQ-32B finetuning fits with Unsloth in under 20GB of VRAM! Itâ€™s also 2x faster, and default uses our dynamic 4-bit quants for superior accuracy for QLoRA. 

ä½¿ç”¨ Unsloth è¿›è¡Œ QwQ-32B å¾®è°ƒï¼Œä»…éœ€ä¸åˆ° 20GB çš„æ˜¾å­˜ï¼é€Ÿåº¦è¿˜èƒ½æå‡ 2 å€ã€‚å¹¶ä¸”ï¼Œä¸ºäº†ä¿è¯ QLoRA çš„ç²¾åº¦ï¼Œæˆ‘ä»¬é»˜è®¤ä½¿ç”¨äº†åŠ¨æ€ 4 ä½é‡åŒ–ã€‚

Due to the model size, unfortunately the model does not fit on free Google Colab 16GB VRAM GPUs so you will need a GPU with at least 20GB VRAM. To view the rest of our notebooks and model uploads, please visit our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks). 

ç”±äºæ¨¡å‹ä½“ç§¯è¾ƒå¤§ï¼Œè¯¥æ¨¡å‹æ— æ³•åœ¨å…è´¹çš„ Google Colab æä¾›çš„ 16GB VRAM GPU ä¸Šè¿è¡Œï¼Œå› æ­¤æ‚¨éœ€è¦è‡³å°‘ 20GB VRAM çš„ GPUã€‚è¦æŸ¥çœ‹æˆ‘ä»¬çš„å…¶ä»– notebook ç¤ºä¾‹å’Œä¸Šä¼ çš„æ¨¡å‹ï¼Œè¯·è®¿é—®æˆ‘ä»¬çš„ [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)ã€‚

[Unsloth Notebooks | Unsloth Documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)

### Performance benchmarks

| Model | VRAM | ğŸ¦¥Unsloth speed | ğŸ¦¥VRAM reduction | ğŸ¦¥Longer context | ğŸ¤—Hugging Face+FA2 |
|---|---|---|---|---|---|
| QwQ-32B | 24GB | 2x | 70% | 13x longer | 1x |

We tested using the Alpaca Dataset, a batch size of 2, gradient accumulation steps of 4, rank = 32, and applied QLoRA on all linear layers (q, k, v, o, gate, up, down). 

æˆ‘ä»¬ä½¿ç”¨ Alpaca Dataset è¿›è¡Œäº†æµ‹è¯•ï¼Œæ‰¹é‡å¤§å°ï¼ˆbatch sizeï¼‰ä¸º 2ï¼Œæ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆgradient accumulation stepsï¼‰ä¸º 4ï¼Œç§©ï¼ˆrankï¼‰ä¸º 32ã€‚æˆ‘ä»¬å¯¹æ‰€æœ‰çº¿æ€§å±‚ï¼ˆqã€kã€vã€oã€gateã€upã€downï¼‰åº”ç”¨äº† QLoRA æŠ€æœ¯ã€‚